{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# Amazon stock market\n",
    "ticker = \"GRWG\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 9s 555ms/step - loss: 0.0097 - mean_absolute_error: 0.0716 - val_loss: 0.0027 - val_mean_absolute_error: 0.0429\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00270, saving model to results/2021-03-25_GRWG-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 3s 345ms/step - loss: 0.0023 - mean_absolute_error: 0.0390 - val_loss: 0.0027 - val_mean_absolute_error: 0.0358\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00270\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.0015 - mean_absolute_error: 0.0294 - val_loss: 0.0025 - val_mean_absolute_error: 0.0349\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00270 to 0.00247, saving model to results/2021-03-25_GRWG-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.0015 - mean_absolute_error: 0.0292 - val_loss: 0.0023 - val_mean_absolute_error: 0.0332\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00247 to 0.00228, saving model to results/2021-03-25_GRWG-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 4s 346ms/step - loss: 0.0014 - mean_absolute_error: 0.0295 - val_loss: 0.0025 - val_mean_absolute_error: 0.0376\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00228\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.0014 - mean_absolute_error: 0.0288 - val_loss: 0.0022 - val_mean_absolute_error: 0.0330\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00228 to 0.00220, saving model to results/2021-03-25_GRWG-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 0.0013 - mean_absolute_error: 0.0287 - val_loss: 0.0022 - val_mean_absolute_error: 0.0337\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00220 to 0.00218, saving model to results/2021-03-25_GRWG-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.0013 - mean_absolute_error: 0.0291 - val_loss: 0.0032 - val_mean_absolute_error: 0.0407\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00218\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 4s 363ms/step - loss: 0.0020 - mean_absolute_error: 0.0373 - val_loss: 0.0028 - val_mean_absolute_error: 0.0393\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00218\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.0014 - mean_absolute_error: 0.0341 - val_loss: 0.0021 - val_mean_absolute_error: 0.0363\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00218 to 0.00207, saving model to results/2021-03-25_GRWG-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=\"logs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 55.28$\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5c0048ce34b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# printing metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{LOSS} loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Absolute Error:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'figsize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-596775213e1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot true/pred prices graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-b8bc0c2c0131>\u001b[0m in \u001b[0;36mplot_graph\u001b[0;34m(test_df)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Price\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Actual Price\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Predicted Price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'figsize'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   open         high          low        close     adjclose  \\\n",
      "2020-12-31  3275.000000  3282.919922  3241.199951  3256.929932  3256.929932   \n",
      "2021-01-04  3270.000000  3272.000000  3144.020020  3186.629883  3186.629883   \n",
      "2021-01-08  3180.000000  3190.639893  3142.199951  3182.699951  3182.699951   \n",
      "2021-01-15  3123.020020  3142.550049  3095.169922  3104.250000  3104.250000   \n",
      "2021-01-25  3328.500000  3363.889893  3243.149902  3294.000000  3294.000000   \n",
      "2021-02-01  3242.360107  3350.260010  3235.030029  3342.879883  3342.879883   \n",
      "2021-02-05  3319.000000  3377.000000  3302.709961  3352.149902  3352.149902   \n",
      "2021-02-10  3314.000000  3317.949951  3254.000000  3286.580078  3286.580078   \n",
      "2021-02-12  3250.000000  3280.250000  3233.310059  3277.709961  3277.709961   \n",
      "2021-02-24  3166.750000  3171.229980  3125.379883  3159.530029  3159.530029   \n",
      "\n",
      "             volume ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
      "2020-12-31  2957200   AMZN  3187.500732       3294.000000  -69.429199   \n",
      "2021-01-04  4411400   AMZN  3192.338867       3326.129883    5.708984   \n",
      "2021-01-08  3537700   AMZN  3197.424805       3342.879883   14.724854   \n",
      "2021-01-15  4244000   AMZN  3198.699707       3322.939941   94.449707   \n",
      "2021-01-25  3749800   AMZN  3188.595703       3268.949951    0.000000   \n",
      "2021-02-01  4160200   AMZN  3188.805908       3194.500000    0.000000   \n",
      "2021-02-05  3613600   AMZN  3185.829834       3146.139893    0.000000   \n",
      "2021-02-10  3151600   AMZN  3187.892578       2977.570068    0.000000   \n",
      "2021-02-12  2329300   AMZN  3189.521484       2951.949951    0.000000   \n",
      "2021-02-24  3011300   AMZN  3194.023682       3135.729980    0.000000   \n",
      "\n",
      "            sell_profit  \n",
      "2020-12-31     0.000000  \n",
      "2021-01-04     0.000000  \n",
      "2021-01-08     0.000000  \n",
      "2021-01-15     0.000000  \n",
      "2021-01-25   105.404297  \n",
      "2021-02-01   154.073975  \n",
      "2021-02-05   166.320068  \n",
      "2021-02-10    98.687500  \n",
      "2021-02-12    88.188477  \n",
      "2021-02-24   -34.493652  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
