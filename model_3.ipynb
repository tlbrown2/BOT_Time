{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 500\n",
    "# Amazon stock market\n",
    "ticker = \"AMZN\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "75/75 [==============================] - 23s 267ms/step - loss: 0.0045 - mean_absolute_error: 0.0379 - val_loss: 1.8744e-04 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00019, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - 22s 295ms/step - loss: 4.0530e-04 - mean_absolute_error: 0.0140 - val_loss: 2.0523e-04 - val_mean_absolute_error: 0.0111\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00019\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 3.8490e-04 - mean_absolute_error: 0.0146 - val_loss: 2.5045e-04 - val_mean_absolute_error: 0.0106\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00019\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 5.2995e-04 - mean_absolute_error: 0.0159 - val_loss: 2.9043e-04 - val_mean_absolute_error: 0.0101\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00019\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - 24s 314ms/step - loss: 3.3553e-04 - mean_absolute_error: 0.0131 - val_loss: 1.9051e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00019\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 4.3896e-04 - mean_absolute_error: 0.0142 - val_loss: 1.7432e-04 - val_mean_absolute_error: 0.0099\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00019 to 0.00017, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - 24s 317ms/step - loss: 3.1974e-04 - mean_absolute_error: 0.0126 - val_loss: 2.9683e-04 - val_mean_absolute_error: 0.0143\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00017\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - 24s 314ms/step - loss: 5.4769e-04 - mean_absolute_error: 0.0169 - val_loss: 1.6708e-04 - val_mean_absolute_error: 0.0091\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00017 to 0.00017, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - 24s 321ms/step - loss: 3.3140e-04 - mean_absolute_error: 0.0124 - val_loss: 1.6637e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00017 to 0.00017, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - 25s 327ms/step - loss: 4.9777e-04 - mean_absolute_error: 0.0166 - val_loss: 1.6945e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00017\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - 25s 329ms/step - loss: 3.4528e-04 - mean_absolute_error: 0.0126 - val_loss: 1.8062e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00017\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - 24s 316ms/step - loss: 3.3730e-04 - mean_absolute_error: 0.0127 - val_loss: 1.6259e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00017 to 0.00016, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - 24s 323ms/step - loss: 3.4167e-04 - mean_absolute_error: 0.0128 - val_loss: 1.8199e-04 - val_mean_absolute_error: 0.0103\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00016\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - 25s 328ms/step - loss: 3.1994e-04 - mean_absolute_error: 0.0128 - val_loss: 1.7594e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00016\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - 24s 323ms/step - loss: 3.8911e-04 - mean_absolute_error: 0.0133 - val_loss: 1.8452e-04 - val_mean_absolute_error: 0.0105\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00016\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - 26s 349ms/step - loss: 2.9176e-04 - mean_absolute_error: 0.0127 - val_loss: 2.1189e-04 - val_mean_absolute_error: 0.0103\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00016\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - 26s 345ms/step - loss: 2.6630e-04 - mean_absolute_error: 0.0117 - val_loss: 2.3049e-04 - val_mean_absolute_error: 0.0103\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00016\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - 25s 338ms/step - loss: 2.6498e-04 - mean_absolute_error: 0.0115 - val_loss: 1.6170e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00016 to 0.00016, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - 24s 326ms/step - loss: 3.2381e-04 - mean_absolute_error: 0.0125 - val_loss: 1.5562e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00016 to 0.00016, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - 25s 330ms/step - loss: 2.6310e-04 - mean_absolute_error: 0.0117 - val_loss: 1.9656e-04 - val_mean_absolute_error: 0.0097\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00016\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 3.4357e-04 - mean_absolute_error: 0.0137 - val_loss: 1.5293e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00016 to 0.00015, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 3.5807e-04 - mean_absolute_error: 0.0133 - val_loss: 2.4834e-04 - val_mean_absolute_error: 0.0098\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00015\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - 25s 328ms/step - loss: 3.5632e-04 - mean_absolute_error: 0.0141 - val_loss: 1.8658e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00015\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - 26s 341ms/step - loss: 3.1629e-04 - mean_absolute_error: 0.0126 - val_loss: 1.7612e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00015\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 3.3083e-04 - mean_absolute_error: 0.0126 - val_loss: 1.5142e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00015 to 0.00015, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - 25s 330ms/step - loss: 3.2715e-04 - mean_absolute_error: 0.0130 - val_loss: 1.6065e-04 - val_mean_absolute_error: 0.0099\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00015\n",
      "Epoch 27/500\n",
      "75/75 [==============================] - 25s 331ms/step - loss: 3.0510e-04 - mean_absolute_error: 0.0128 - val_loss: 2.1150e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00015\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - 25s 328ms/step - loss: 3.1367e-04 - mean_absolute_error: 0.0129 - val_loss: 1.6322e-04 - val_mean_absolute_error: 0.0098\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00015\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 3.7491e-04 - mean_absolute_error: 0.0143 - val_loss: 1.6740e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00015\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - 25s 335ms/step - loss: 3.1170e-04 - mean_absolute_error: 0.0130 - val_loss: 2.1405e-04 - val_mean_absolute_error: 0.0094\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00015\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - 26s 349ms/step - loss: 2.5558e-04 - mean_absolute_error: 0.0123 - val_loss: 2.4432e-04 - val_mean_absolute_error: 0.0117\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00015\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - 25s 333ms/step - loss: 2.7938e-04 - mean_absolute_error: 0.0127 - val_loss: 1.5205e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00015\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - 25s 330ms/step - loss: 2.6893e-04 - mean_absolute_error: 0.0123 - val_loss: 2.8255e-04 - val_mean_absolute_error: 0.0111\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00015\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - 26s 345ms/step - loss: 2.6239e-04 - mean_absolute_error: 0.0127 - val_loss: 1.7411e-04 - val_mean_absolute_error: 0.0091\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00015\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - 25s 332ms/step - loss: 2.9251e-04 - mean_absolute_error: 0.0124 - val_loss: 2.2863e-04 - val_mean_absolute_error: 0.0107\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00015\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - 23s 314ms/step - loss: 2.8326e-04 - mean_absolute_error: 0.0126 - val_loss: 1.5853e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00015\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - 24s 323ms/step - loss: 2.6686e-04 - mean_absolute_error: 0.0124 - val_loss: 2.0519e-04 - val_mean_absolute_error: 0.0095\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00015\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - 24s 320ms/step - loss: 3.2037e-04 - mean_absolute_error: 0.0133 - val_loss: 2.6693e-04 - val_mean_absolute_error: 0.0130\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00015\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - 25s 328ms/step - loss: 3.0502e-04 - mean_absolute_error: 0.0137 - val_loss: 2.0156e-04 - val_mean_absolute_error: 0.0107\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00015\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - 25s 327ms/step - loss: 3.6477e-04 - mean_absolute_error: 0.0139 - val_loss: 3.4213e-04 - val_mean_absolute_error: 0.0125\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00015\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - 25s 329ms/step - loss: 3.2745e-04 - mean_absolute_error: 0.0137 - val_loss: 2.0653e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00015\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - 25s 330ms/step - loss: 2.8574e-04 - mean_absolute_error: 0.0126 - val_loss: 1.7789e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00015\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - 25s 337ms/step - loss: 3.0605e-04 - mean_absolute_error: 0.0134 - val_loss: 1.7786e-04 - val_mean_absolute_error: 0.0093\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00015\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - 24s 326ms/step - loss: 2.8104e-04 - mean_absolute_error: 0.0127 - val_loss: 1.5160e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00015\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - 25s 339ms/step - loss: 3.3868e-04 - mean_absolute_error: 0.0139 - val_loss: 1.6382e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00015\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - 25s 329ms/step - loss: 2.9974e-04 - mean_absolute_error: 0.0132 - val_loss: 1.5367e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00015\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - 25s 331ms/step - loss: 3.7068e-04 - mean_absolute_error: 0.0144 - val_loss: 1.5519e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00015\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - 28s 370ms/step - loss: 3.2909e-04 - mean_absolute_error: 0.0138 - val_loss: 1.7129e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00015\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - 26s 343ms/step - loss: 2.8183e-04 - mean_absolute_error: 0.0129 - val_loss: 2.3034e-04 - val_mean_absolute_error: 0.0104\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00015\n",
      "Epoch 50/500\n",
      "75/75 [==============================] - 30s 402ms/step - loss: 3.3892e-04 - mean_absolute_error: 0.0144 - val_loss: 1.5553e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00015\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - 26s 352ms/step - loss: 2.3141e-04 - mean_absolute_error: 0.0120 - val_loss: 3.6932e-04 - val_mean_absolute_error: 0.0135\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00015\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - 25s 339ms/step - loss: 3.1791e-04 - mean_absolute_error: 0.0135 - val_loss: 2.8644e-04 - val_mean_absolute_error: 0.0115\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00015\n",
      "Epoch 53/500\n",
      "75/75 [==============================] - 30s 401ms/step - loss: 3.0648e-04 - mean_absolute_error: 0.0135 - val_loss: 1.5140e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00015 to 0.00015, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - 26s 342ms/step - loss: 2.7854e-04 - mean_absolute_error: 0.0133 - val_loss: 1.4833e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00015 to 0.00015, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - 27s 365ms/step - loss: 2.7945e-04 - mean_absolute_error: 0.0130 - val_loss: 2.9085e-04 - val_mean_absolute_error: 0.0122\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00015\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - 25s 338ms/step - loss: 3.0682e-04 - mean_absolute_error: 0.0137 - val_loss: 1.4824e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00015 to 0.00015, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 57/500\n",
      "75/75 [==============================] - 26s 343ms/step - loss: 2.9142e-04 - mean_absolute_error: 0.0133 - val_loss: 1.5158e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00015\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - 25s 330ms/step - loss: 2.8938e-04 - mean_absolute_error: 0.0131 - val_loss: 1.7397e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00015\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 3.1687e-04 - mean_absolute_error: 0.0134 - val_loss: 1.9360e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00015\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - 25s 331ms/step - loss: 2.9283e-04 - mean_absolute_error: 0.0135 - val_loss: 2.0935e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00015\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - 25s 340ms/step - loss: 2.7412e-04 - mean_absolute_error: 0.0130 - val_loss: 1.5409e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00015\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - 25s 337ms/step - loss: 2.4272e-04 - mean_absolute_error: 0.0126 - val_loss: 1.4155e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00015 to 0.00014, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - 24s 314ms/step - loss: 3.2153e-04 - mean_absolute_error: 0.0138 - val_loss: 1.5859e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00014\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - 24s 317ms/step - loss: 2.8049e-04 - mean_absolute_error: 0.0131 - val_loss: 1.4433e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00014\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - 24s 317ms/step - loss: 2.8917e-04 - mean_absolute_error: 0.0135 - val_loss: 1.6248e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00014\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - 23s 310ms/step - loss: 2.3528e-04 - mean_absolute_error: 0.0124 - val_loss: 1.4912e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00014\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - 26s 345ms/step - loss: 2.4151e-04 - mean_absolute_error: 0.0125 - val_loss: 1.5377e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00014\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - 25s 340ms/step - loss: 2.6399e-04 - mean_absolute_error: 0.0130 - val_loss: 1.4406e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00014\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - 26s 344ms/step - loss: 2.9690e-04 - mean_absolute_error: 0.0135 - val_loss: 1.3737e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00014 to 0.00014, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - 25s 338ms/step - loss: 2.4405e-04 - mean_absolute_error: 0.0124 - val_loss: 1.3431e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00014 to 0.00013, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - 26s 346ms/step - loss: 2.3058e-04 - mean_absolute_error: 0.0122 - val_loss: 3.0294e-04 - val_mean_absolute_error: 0.0121\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00013\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - 26s 346ms/step - loss: 2.5873e-04 - mean_absolute_error: 0.0131 - val_loss: 2.3675e-04 - val_mean_absolute_error: 0.0105\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00013\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - 26s 349ms/step - loss: 2.5806e-04 - mean_absolute_error: 0.0127 - val_loss: 1.4028e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00013\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - 25s 338ms/step - loss: 2.2655e-04 - mean_absolute_error: 0.0123 - val_loss: 1.5501e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00013\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - 26s 344ms/step - loss: 2.3770e-04 - mean_absolute_error: 0.0122 - val_loss: 1.3167e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00013 to 0.00013, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - 27s 358ms/step - loss: 2.7774e-04 - mean_absolute_error: 0.0132 - val_loss: 1.3463e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00013\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - 26s 347ms/step - loss: 2.6325e-04 - mean_absolute_error: 0.0134 - val_loss: 1.4303e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00013\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - 26s 345ms/step - loss: 2.6554e-04 - mean_absolute_error: 0.0129 - val_loss: 1.7359e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00013\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 2.1298e-04 - mean_absolute_error: 0.0120 - val_loss: 1.8048e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00013\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 2.4986e-04 - mean_absolute_error: 0.0129 - val_loss: 1.5409e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00013\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - 26s 346ms/step - loss: 2.5247e-04 - mean_absolute_error: 0.0128 - val_loss: 1.4291e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00013\n",
      "Epoch 82/500\n",
      "75/75 [==============================] - 26s 343ms/step - loss: 2.3927e-04 - mean_absolute_error: 0.0123 - val_loss: 1.3365e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00013\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - 26s 343ms/step - loss: 2.2148e-04 - mean_absolute_error: 0.0121 - val_loss: 1.3082e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00013 to 0.00013, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - 25s 339ms/step - loss: 2.1848e-04 - mean_absolute_error: 0.0122 - val_loss: 1.4233e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00013\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - 26s 343ms/step - loss: 2.2060e-04 - mean_absolute_error: 0.0122 - val_loss: 1.3593e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00013\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - 26s 345ms/step - loss: 2.6190e-04 - mean_absolute_error: 0.0129 - val_loss: 1.5496e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00013\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - 26s 344ms/step - loss: 2.8109e-04 - mean_absolute_error: 0.0137 - val_loss: 1.2944e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00013 to 0.00013, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - 26s 351ms/step - loss: 2.2485e-04 - mean_absolute_error: 0.0123 - val_loss: 1.6941e-04 - val_mean_absolute_error: 0.0095\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00013\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - 27s 359ms/step - loss: 2.2340e-04 - mean_absolute_error: 0.0123 - val_loss: 1.2428e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00013 to 0.00012, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - 25s 339ms/step - loss: 2.1700e-04 - mean_absolute_error: 0.0119 - val_loss: 1.4217e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00012\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - 25s 332ms/step - loss: 2.2865e-04 - mean_absolute_error: 0.0124 - val_loss: 1.1923e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00012 to 0.00012, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - 25s 331ms/step - loss: 2.2190e-04 - mean_absolute_error: 0.0124 - val_loss: 1.2431e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00012\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - 25s 330ms/step - loss: 2.3003e-04 - mean_absolute_error: 0.0121 - val_loss: 1.5318e-04 - val_mean_absolute_error: 0.0105\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00012\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 2.4214e-04 - mean_absolute_error: 0.0123 - val_loss: 1.2113e-04 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.00012\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - 25s 331ms/step - loss: 2.6130e-04 - mean_absolute_error: 0.0131 - val_loss: 1.6833e-04 - val_mean_absolute_error: 0.0100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00012\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - 24s 319ms/step - loss: 2.3106e-04 - mean_absolute_error: 0.0125 - val_loss: 1.2917e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00012\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - 24s 318ms/step - loss: 2.4064e-04 - mean_absolute_error: 0.0124 - val_loss: 1.2152e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00012\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - 23s 310ms/step - loss: 2.3491e-04 - mean_absolute_error: 0.0120 - val_loss: 1.4226e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00012\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - 23s 312ms/step - loss: 2.8415e-04 - mean_absolute_error: 0.0131 - val_loss: 1.1939e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00012\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - 24s 314ms/step - loss: 2.0228e-04 - mean_absolute_error: 0.0119 - val_loss: 1.2884e-04 - val_mean_absolute_error: 0.0093\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.00012\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - 25s 338ms/step - loss: 2.1411e-04 - mean_absolute_error: 0.0122 - val_loss: 1.1999e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00012\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - 25s 327ms/step - loss: 2.3285e-04 - mean_absolute_error: 0.0124 - val_loss: 1.4108e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00012\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - 25s 331ms/step - loss: 2.2014e-04 - mean_absolute_error: 0.0122 - val_loss: 1.3216e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00012\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - 25s 335ms/step - loss: 2.0163e-04 - mean_absolute_error: 0.0116 - val_loss: 1.1964e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00012\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - 27s 357ms/step - loss: 2.2104e-04 - mean_absolute_error: 0.0120 - val_loss: 1.3496e-04 - val_mean_absolute_error: 0.0093\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00012\n",
      "Epoch 106/500\n",
      "75/75 [==============================] - 26s 345ms/step - loss: 1.9456e-04 - mean_absolute_error: 0.0118 - val_loss: 1.5205e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00012\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 2.2928e-04 - mean_absolute_error: 0.0122 - val_loss: 1.3807e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00012\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 2.5609e-04 - mean_absolute_error: 0.0127 - val_loss: 1.5136e-04 - val_mean_absolute_error: 0.0090\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00012\n",
      "Epoch 109/500\n",
      "75/75 [==============================] - 26s 346ms/step - loss: 2.2474e-04 - mean_absolute_error: 0.0126 - val_loss: 1.1479e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00012 to 0.00011, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - 25s 333ms/step - loss: 2.0677e-04 - mean_absolute_error: 0.0118 - val_loss: 1.1328e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00011 to 0.00011, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 2.1526e-04 - mean_absolute_error: 0.0121 - val_loss: 1.7331e-04 - val_mean_absolute_error: 0.0089\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00011\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - 25s 332ms/step - loss: 2.2657e-04 - mean_absolute_error: 0.0125 - val_loss: 1.2780e-04 - val_mean_absolute_error: 0.0095\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00011\n",
      "Epoch 113/500\n",
      "75/75 [==============================] - 25s 333ms/step - loss: 2.0728e-04 - mean_absolute_error: 0.0119 - val_loss: 1.5686e-04 - val_mean_absolute_error: 0.0085\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.00011\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - 25s 335ms/step - loss: 2.5050e-04 - mean_absolute_error: 0.0127 - val_loss: 1.5440e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.00011\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 3.0082e-04 - mean_absolute_error: 0.0138 - val_loss: 1.5733e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00011\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 2.5024e-04 - mean_absolute_error: 0.0127 - val_loss: 1.2345e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00011\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - 25s 330ms/step - loss: 2.4072e-04 - mean_absolute_error: 0.0128 - val_loss: 1.2444e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.00011\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - 25s 331ms/step - loss: 2.3532e-04 - mean_absolute_error: 0.0122 - val_loss: 1.2638e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.00011\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - 25s 338ms/step - loss: 2.0178e-04 - mean_absolute_error: 0.0117 - val_loss: 1.1978e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00011\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 2.5223e-04 - mean_absolute_error: 0.0126 - val_loss: 1.5088e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00011\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - 25s 338ms/step - loss: 2.3798e-04 - mean_absolute_error: 0.0123 - val_loss: 1.2760e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.00011\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - 24s 317ms/step - loss: 2.3947e-04 - mean_absolute_error: 0.0125 - val_loss: 1.4269e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.00011\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - 23s 313ms/step - loss: 1.9813e-04 - mean_absolute_error: 0.0114 - val_loss: 1.4646e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.00011\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - 24s 318ms/step - loss: 2.2508e-04 - mean_absolute_error: 0.0122 - val_loss: 1.1261e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00011 to 0.00011, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - 24s 319ms/step - loss: 1.9227e-04 - mean_absolute_error: 0.0114 - val_loss: 1.4955e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.00011\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 1.9164e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0833e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00011 to 0.00011, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 2.2034e-04 - mean_absolute_error: 0.0119 - val_loss: 1.3472e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.00011\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - 25s 339ms/step - loss: 2.2106e-04 - mean_absolute_error: 0.0123 - val_loss: 1.5263e-04 - val_mean_absolute_error: 0.0094\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.00011\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - 26s 341ms/step - loss: 2.3197e-04 - mean_absolute_error: 0.0122 - val_loss: 1.1514e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.00011\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - 26s 346ms/step - loss: 2.3103e-04 - mean_absolute_error: 0.0120 - val_loss: 1.1394e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.00011\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - 25s 338ms/step - loss: 1.9077e-04 - mean_absolute_error: 0.0116 - val_loss: 1.1844e-04 - val_mean_absolute_error: 0.0090\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.00011\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - 25s 337ms/step - loss: 2.4519e-04 - mean_absolute_error: 0.0126 - val_loss: 1.0815e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00011 to 0.00011, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - 26s 341ms/step - loss: 2.3351e-04 - mean_absolute_error: 0.0120 - val_loss: 1.5033e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.00011\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - 25s 328ms/step - loss: 2.6756e-04 - mean_absolute_error: 0.0130 - val_loss: 1.1788e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.00011\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - 23s 314ms/step - loss: 2.2542e-04 - mean_absolute_error: 0.0120 - val_loss: 1.1677e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.00011\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - 24s 318ms/step - loss: 2.1701e-04 - mean_absolute_error: 0.0121 - val_loss: 1.1638e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.00011\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - 23s 313ms/step - loss: 2.1008e-04 - mean_absolute_error: 0.0118 - val_loss: 1.3447e-04 - val_mean_absolute_error: 0.0086\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.00011\n",
      "Epoch 138/500\n",
      "75/75 [==============================] - 24s 314ms/step - loss: 2.0986e-04 - mean_absolute_error: 0.0118 - val_loss: 1.0969e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.00011\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 2.4544e-04 - mean_absolute_error: 0.0125 - val_loss: 1.2391e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.00011\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 2.3214e-04 - mean_absolute_error: 0.0124 - val_loss: 1.1454e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.00011\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 1.7603e-04 - mean_absolute_error: 0.0108 - val_loss: 1.0931e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00011\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - 25s 339ms/step - loss: 2.1337e-04 - mean_absolute_error: 0.0117 - val_loss: 1.1935e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.00011\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 2.1575e-04 - mean_absolute_error: 0.0119 - val_loss: 1.0820e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00011\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - 25s 340ms/step - loss: 1.6243e-04 - mean_absolute_error: 0.0108 - val_loss: 1.1220e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.00011\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - 26s 342ms/step - loss: 2.0087e-04 - mean_absolute_error: 0.0115 - val_loss: 1.1179e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00011\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - 26s 350ms/step - loss: 1.9389e-04 - mean_absolute_error: 0.0117 - val_loss: 1.1759e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00011\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 1.9228e-04 - mean_absolute_error: 0.0113 - val_loss: 1.1883e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00011\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - 23s 313ms/step - loss: 2.2481e-04 - mean_absolute_error: 0.0120 - val_loss: 1.1744e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00011\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - 23s 314ms/step - loss: 2.3613e-04 - mean_absolute_error: 0.0127 - val_loss: 1.3740e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00011\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - 23s 310ms/step - loss: 2.3825e-04 - mean_absolute_error: 0.0124 - val_loss: 1.3674e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.00011\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - 23s 310ms/step - loss: 2.5032e-04 - mean_absolute_error: 0.0129 - val_loss: 1.0379e-04 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00011 to 0.00010, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 2.0945e-04 - mean_absolute_error: 0.0118 - val_loss: 1.0511e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.00010\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - 23s 313ms/step - loss: 1.9007e-04 - mean_absolute_error: 0.0113 - val_loss: 1.1128e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.00010\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 2.1235e-04 - mean_absolute_error: 0.0118 - val_loss: 1.0320e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.00010 to 0.00010, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - 25s 330ms/step - loss: 1.9802e-04 - mean_absolute_error: 0.0116 - val_loss: 1.1611e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.00010\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - 25s 332ms/step - loss: 1.7838e-04 - mean_absolute_error: 0.0111 - val_loss: 1.0032e-04 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00010 to 0.00010, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - 26s 341ms/step - loss: 2.1286e-04 - mean_absolute_error: 0.0116 - val_loss: 1.0818e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.00010\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 1.9377e-04 - mean_absolute_error: 0.0112 - val_loss: 1.1341e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.00010\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - 25s 340ms/step - loss: 2.1016e-04 - mean_absolute_error: 0.0116 - val_loss: 1.1599e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.00010\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 2.1617e-04 - mean_absolute_error: 0.0117 - val_loss: 1.0421e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.00010\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - 25s 338ms/step - loss: 2.6377e-04 - mean_absolute_error: 0.0129 - val_loss: 2.2566e-04 - val_mean_absolute_error: 0.0111\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.00010\n",
      "Epoch 162/500\n",
      "75/75 [==============================] - 26s 345ms/step - loss: 2.4663e-04 - mean_absolute_error: 0.0126 - val_loss: 1.1285e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.00010\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - 25s 332ms/step - loss: 2.3851e-04 - mean_absolute_error: 0.0122 - val_loss: 1.1052e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.00010\n",
      "Epoch 164/500\n",
      "75/75 [==============================] - 24s 315ms/step - loss: 2.0519e-04 - mean_absolute_error: 0.0118 - val_loss: 1.2574e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.00010\n",
      "Epoch 165/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 2.0833e-04 - mean_absolute_error: 0.0115 - val_loss: 1.9893e-04 - val_mean_absolute_error: 0.0091\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.00010\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 2.2305e-04 - mean_absolute_error: 0.0122 - val_loss: 1.0637e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00010\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 2.4575e-04 - mean_absolute_error: 0.0124 - val_loss: 1.0731e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.00010\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - 25s 330ms/step - loss: 1.9374e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0247e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.00010\n",
      "Epoch 169/500\n",
      "75/75 [==============================] - 25s 327ms/step - loss: 2.0422e-04 - mean_absolute_error: 0.0116 - val_loss: 1.2371e-04 - val_mean_absolute_error: 0.0100\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.00010\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 1.8720e-04 - mean_absolute_error: 0.0115 - val_loss: 1.0028e-04 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.00010 to 0.00010, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - 25s 328ms/step - loss: 1.9187e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0753e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.00010\n",
      "Epoch 172/500\n",
      "75/75 [==============================] - 25s 336ms/step - loss: 2.0705e-04 - mean_absolute_error: 0.0116 - val_loss: 1.0372e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.00010\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 1.7985e-04 - mean_absolute_error: 0.0112 - val_loss: 1.1580e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.00010\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - 25s 334ms/step - loss: 2.2841e-04 - mean_absolute_error: 0.0119 - val_loss: 1.0469e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.00010\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - 25s 331ms/step - loss: 1.8785e-04 - mean_absolute_error: 0.0113 - val_loss: 1.2122e-04 - val_mean_absolute_error: 0.0087\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.00010\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - 24s 326ms/step - loss: 1.8623e-04 - mean_absolute_error: 0.0112 - val_loss: 1.0428e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.00010\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - 25s 328ms/step - loss: 2.0051e-04 - mean_absolute_error: 0.0116 - val_loss: 1.2562e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.00010\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - 24s 327ms/step - loss: 2.2501e-04 - mean_absolute_error: 0.0121 - val_loss: 9.8380e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.00010 to 0.00010, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - 24s 326ms/step - loss: 1.9792e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0654e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.00010\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - 24s 326ms/step - loss: 1.7814e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0702e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.00010\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - 25s 328ms/step - loss: 1.8928e-04 - mean_absolute_error: 0.0112 - val_loss: 1.1638e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.00010\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - 25s 329ms/step - loss: 2.1581e-04 - mean_absolute_error: 0.0116 - val_loss: 1.1845e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.00010\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - 25s 328ms/step - loss: 2.0526e-04 - mean_absolute_error: 0.0118 - val_loss: 1.1513e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.00010\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - 24s 327ms/step - loss: 1.9368e-04 - mean_absolute_error: 0.0113 - val_loss: 1.8911e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.00010\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - 25s 331ms/step - loss: 2.5139e-04 - mean_absolute_error: 0.0122 - val_loss: 1.1673e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.00010\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - 24s 326ms/step - loss: 2.2865e-04 - mean_absolute_error: 0.0122 - val_loss: 1.1060e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.00010\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - 24s 327ms/step - loss: 1.8509e-04 - mean_absolute_error: 0.0112 - val_loss: 1.2514e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.00010\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - 24s 325ms/step - loss: 2.2090e-04 - mean_absolute_error: 0.0120 - val_loss: 9.9729e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.00010\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 1.8146e-04 - mean_absolute_error: 0.0109 - val_loss: 1.2366e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.00010\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 1.8481e-04 - mean_absolute_error: 0.0112 - val_loss: 1.0916e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.00010\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - 23s 313ms/step - loss: 2.1037e-04 - mean_absolute_error: 0.0117 - val_loss: 1.2029e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.00010\n",
      "Epoch 192/500\n",
      "75/75 [==============================] - 24s 324ms/step - loss: 2.2860e-04 - mean_absolute_error: 0.0119 - val_loss: 1.0388e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.00010\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - 25s 329ms/step - loss: 2.1214e-04 - mean_absolute_error: 0.0119 - val_loss: 1.3650e-04 - val_mean_absolute_error: 0.0095\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.00010\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - 25s 328ms/step - loss: 1.8908e-04 - mean_absolute_error: 0.0115 - val_loss: 8.9089e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.00010 to 0.00009, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - 24s 326ms/step - loss: 2.0334e-04 - mean_absolute_error: 0.0112 - val_loss: 9.7418e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.00009\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - 24s 322ms/step - loss: 1.9738e-04 - mean_absolute_error: 0.0113 - val_loss: 8.8205e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.00009 to 0.00009, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - 24s 324ms/step - loss: 1.7150e-04 - mean_absolute_error: 0.0109 - val_loss: 1.2171e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.00009\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - 24s 326ms/step - loss: 1.8169e-04 - mean_absolute_error: 0.0111 - val_loss: 9.9976e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.00009\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - 24s 325ms/step - loss: 1.8754e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0949e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.00009\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - 24s 326ms/step - loss: 1.8034e-04 - mean_absolute_error: 0.0112 - val_loss: 1.1407e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.00009\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - 24s 325ms/step - loss: 1.9665e-04 - mean_absolute_error: 0.0114 - val_loss: 1.2409e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.00009\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - 24s 326ms/step - loss: 1.8058e-04 - mean_absolute_error: 0.0110 - val_loss: 1.6304e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.00009\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - 25s 329ms/step - loss: 2.0402e-04 - mean_absolute_error: 0.0115 - val_loss: 1.0614e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.00009\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - 25s 328ms/step - loss: 2.2430e-04 - mean_absolute_error: 0.0120 - val_loss: 1.0714e-04 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.00009\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - 25s 333ms/step - loss: 2.1857e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0339e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.00009\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - 25s 330ms/step - loss: 1.8574e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0002e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.00009\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - 25s 329ms/step - loss: 1.7986e-04 - mean_absolute_error: 0.0110 - val_loss: 1.2163e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.00009\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - 25s 329ms/step - loss: 2.0148e-04 - mean_absolute_error: 0.0113 - val_loss: 1.3544e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.00009\n",
      "Epoch 209/500\n",
      "75/75 [==============================] - 24s 321ms/step - loss: 1.9399e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0054e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.00009\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - 25s 328ms/step - loss: 1.7197e-04 - mean_absolute_error: 0.0108 - val_loss: 9.0859e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.00009\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - 24s 323ms/step - loss: 1.7689e-04 - mean_absolute_error: 0.0109 - val_loss: 9.1231e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.00009\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.8148e-04 - mean_absolute_error: 0.0111 - val_loss: 1.1884e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.00009\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 1.9463e-04 - mean_absolute_error: 0.0112 - val_loss: 7.8800e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.00009 to 0.00008, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.8175e-04 - mean_absolute_error: 0.0110 - val_loss: 9.2565e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.00008\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.5926e-04 - mean_absolute_error: 0.0108 - val_loss: 1.0521e-04 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.00008\n",
      "Epoch 216/500\n",
      "75/75 [==============================] - 23s 312ms/step - loss: 1.6405e-04 - mean_absolute_error: 0.0108 - val_loss: 1.3756e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.00008\n",
      "Epoch 217/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 2.2872e-04 - mean_absolute_error: 0.0124 - val_loss: 1.0081e-04 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.00008\n",
      "Epoch 218/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 2.0560e-04 - mean_absolute_error: 0.0115 - val_loss: 9.8311e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.00008\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - 22s 297ms/step - loss: 1.7415e-04 - mean_absolute_error: 0.0108 - val_loss: 1.0110e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.00008\n",
      "Epoch 220/500\n",
      "75/75 [==============================] - 22s 294ms/step - loss: 1.6369e-04 - mean_absolute_error: 0.0107 - val_loss: 7.4356e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.00008 to 0.00007, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 221/500\n",
      "75/75 [==============================] - 22s 296ms/step - loss: 1.6013e-04 - mean_absolute_error: 0.0108 - val_loss: 1.0034e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.00007\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.7062e-04 - mean_absolute_error: 0.0109 - val_loss: 1.0014e-04 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.00007\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.9062e-04 - mean_absolute_error: 0.0115 - val_loss: 7.5564e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.00007\n",
      "Epoch 224/500\n",
      "75/75 [==============================] - 23s 310ms/step - loss: 1.7498e-04 - mean_absolute_error: 0.0110 - val_loss: 8.5548e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.00007\n",
      "Epoch 225/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 1.8190e-04 - mean_absolute_error: 0.0112 - val_loss: 8.4274e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.00007\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - 23s 313ms/step - loss: 1.6017e-04 - mean_absolute_error: 0.0107 - val_loss: 8.9785e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.00007\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - 24s 315ms/step - loss: 1.8407e-04 - mean_absolute_error: 0.0110 - val_loss: 8.7273e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.00007\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - 23s 312ms/step - loss: 1.6097e-04 - mean_absolute_error: 0.0109 - val_loss: 7.9958e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.00007\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - 24s 315ms/step - loss: 1.7917e-04 - mean_absolute_error: 0.0111 - val_loss: 9.6119e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.00007\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 1.6098e-04 - mean_absolute_error: 0.0107 - val_loss: 8.3251e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.00007\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.6291e-04 - mean_absolute_error: 0.0108 - val_loss: 7.7870e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.00007\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - 22s 297ms/step - loss: 1.4546e-04 - mean_absolute_error: 0.0103 - val_loss: 8.2539e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.00007\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - 22s 295ms/step - loss: 1.8471e-04 - mean_absolute_error: 0.0110 - val_loss: 7.7368e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.00007\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - 22s 291ms/step - loss: 1.6425e-04 - mean_absolute_error: 0.0106 - val_loss: 7.6088e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.00007\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - 22s 291ms/step - loss: 1.6166e-04 - mean_absolute_error: 0.0105 - val_loss: 1.1570e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.00007\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.7305e-04 - mean_absolute_error: 0.0108 - val_loss: 8.3952e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.00007\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - 23s 310ms/step - loss: 1.8428e-04 - mean_absolute_error: 0.0111 - val_loss: 9.2179e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.00007\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.6778e-04 - mean_absolute_error: 0.0108 - val_loss: 7.7418e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.00007\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.6486e-04 - mean_absolute_error: 0.0106 - val_loss: 8.0785e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.00007\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - 23s 310ms/step - loss: 1.6422e-04 - mean_absolute_error: 0.0107 - val_loss: 9.2672e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.00007\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - 23s 310ms/step - loss: 1.5145e-04 - mean_absolute_error: 0.0104 - val_loss: 7.8358e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.00007\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.7848e-04 - mean_absolute_error: 0.0112 - val_loss: 8.9643e-05 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.00007\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.9423e-04 - mean_absolute_error: 0.0116 - val_loss: 9.2103e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.00007\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.6348e-04 - mean_absolute_error: 0.0106 - val_loss: 1.3101e-04 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.00007\n",
      "Epoch 245/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.7129e-04 - mean_absolute_error: 0.0108 - val_loss: 1.1070e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.00007\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.6618e-04 - mean_absolute_error: 0.0109 - val_loss: 7.4566e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.00007\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.6355e-04 - mean_absolute_error: 0.0107 - val_loss: 7.2051e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.00007 to 0.00007, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 248/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.5505e-04 - mean_absolute_error: 0.0104 - val_loss: 7.5632e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.00007\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.7849e-04 - mean_absolute_error: 0.0107 - val_loss: 9.4776e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.00007\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - 22s 298ms/step - loss: 1.7567e-04 - mean_absolute_error: 0.0108 - val_loss: 7.7220e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.00007\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - 22s 290ms/step - loss: 1.5536e-04 - mean_absolute_error: 0.0105 - val_loss: 6.9799e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.00007 to 0.00007, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - 22s 291ms/step - loss: 1.3996e-04 - mean_absolute_error: 0.0099 - val_loss: 7.9145e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.00007\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - 22s 294ms/step - loss: 1.6528e-04 - mean_absolute_error: 0.0108 - val_loss: 1.2930e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.00007\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - 22s 292ms/step - loss: 1.8872e-04 - mean_absolute_error: 0.0114 - val_loss: 1.1500e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.00007\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - 21s 287ms/step - loss: 1.8639e-04 - mean_absolute_error: 0.0114 - val_loss: 7.9750e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.00007\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - 22s 295ms/step - loss: 1.5596e-04 - mean_absolute_error: 0.0104 - val_loss: 7.3235e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.00007\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - 22s 292ms/step - loss: 1.8024e-04 - mean_absolute_error: 0.0107 - val_loss: 9.2691e-05 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.00007\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.8511e-04 - mean_absolute_error: 0.0112 - val_loss: 7.5367e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.00007\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - 23s 310ms/step - loss: 2.0068e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0867e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.00007\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.7725e-04 - mean_absolute_error: 0.0108 - val_loss: 7.1942e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.00007\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 1.5264e-04 - mean_absolute_error: 0.0106 - val_loss: 8.2649e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.00007\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - 23s 314ms/step - loss: 1.6962e-04 - mean_absolute_error: 0.0110 - val_loss: 7.9334e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.00007\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.5113e-04 - mean_absolute_error: 0.0103 - val_loss: 1.2105e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.00007\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.8247e-04 - mean_absolute_error: 0.0110 - val_loss: 7.4671e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.00007\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.6694e-04 - mean_absolute_error: 0.0108 - val_loss: 7.7889e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.00007\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.4109e-04 - mean_absolute_error: 0.0102 - val_loss: 6.8123e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.00007 to 0.00007, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - 22s 291ms/step - loss: 1.5463e-04 - mean_absolute_error: 0.0107 - val_loss: 8.4848e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.00007\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - 22s 291ms/step - loss: 1.7082e-04 - mean_absolute_error: 0.0106 - val_loss: 7.4722e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.00007\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - 22s 297ms/step - loss: 1.5113e-04 - mean_absolute_error: 0.0104 - val_loss: 7.3680e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.00007\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - 22s 291ms/step - loss: 1.4755e-04 - mean_absolute_error: 0.0104 - val_loss: 8.3771e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.00007\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - 22s 297ms/step - loss: 1.5578e-04 - mean_absolute_error: 0.0106 - val_loss: 7.5610e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.00007\n",
      "Epoch 272/500\n",
      "75/75 [==============================] - 24s 315ms/step - loss: 1.5619e-04 - mean_absolute_error: 0.0103 - val_loss: 1.1260e-04 - val_mean_absolute_error: 0.0086\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.00007\n",
      "Epoch 273/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 1.8087e-04 - mean_absolute_error: 0.0109 - val_loss: 7.2259e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.00007\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.5946e-04 - mean_absolute_error: 0.0106 - val_loss: 1.0458e-04 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.00007\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.5195e-04 - mean_absolute_error: 0.0104 - val_loss: 7.9738e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.00007\n",
      "Epoch 276/500\n",
      "75/75 [==============================] - 22s 295ms/step - loss: 1.5187e-04 - mean_absolute_error: 0.0103 - val_loss: 7.9817e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.00007\n",
      "Epoch 277/500\n",
      "75/75 [==============================] - 22s 292ms/step - loss: 1.4861e-04 - mean_absolute_error: 0.0106 - val_loss: 7.4939e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.00007\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - 22s 291ms/step - loss: 1.6465e-04 - mean_absolute_error: 0.0110 - val_loss: 8.9894e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.00007\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - 22s 291ms/step - loss: 1.5669e-04 - mean_absolute_error: 0.0106 - val_loss: 7.9264e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.00007\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - 22s 296ms/step - loss: 1.5180e-04 - mean_absolute_error: 0.0102 - val_loss: 8.5740e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.00007\n",
      "Epoch 281/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.5372e-04 - mean_absolute_error: 0.0106 - val_loss: 7.3388e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.00007\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.6139e-04 - mean_absolute_error: 0.0105 - val_loss: 7.8243e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.00007\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.3335e-04 - mean_absolute_error: 0.0099 - val_loss: 9.2940e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.00007\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.5185e-04 - mean_absolute_error: 0.0104 - val_loss: 7.1616e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.00007\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.6472e-04 - mean_absolute_error: 0.0106 - val_loss: 8.9737e-05 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.00007\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.7864e-04 - mean_absolute_error: 0.0112 - val_loss: 7.9358e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.00007\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.7296e-04 - mean_absolute_error: 0.0110 - val_loss: 1.4171e-04 - val_mean_absolute_error: 0.0093\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.00007\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.5687e-04 - mean_absolute_error: 0.0107 - val_loss: 1.1221e-04 - val_mean_absolute_error: 0.0086\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.00007\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.6448e-04 - mean_absolute_error: 0.0110 - val_loss: 8.2053e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.00007\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 2.1563e-04 - mean_absolute_error: 0.0114 - val_loss: 1.0549e-04 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.00007\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.6088e-04 - mean_absolute_error: 0.0109 - val_loss: 7.0774e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.00007\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.5432e-04 - mean_absolute_error: 0.0103 - val_loss: 7.8725e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.00007\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 1.6430e-04 - mean_absolute_error: 0.0106 - val_loss: 7.1483e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.00007\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - 23s 312ms/step - loss: 1.7404e-04 - mean_absolute_error: 0.0105 - val_loss: 7.8881e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.00007\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 1.5795e-04 - mean_absolute_error: 0.0108 - val_loss: 8.9518e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.00007\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.6619e-04 - mean_absolute_error: 0.0107 - val_loss: 8.7878e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.00007\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.3993e-04 - mean_absolute_error: 0.0101 - val_loss: 7.3613e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.00007\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - 22s 293ms/step - loss: 1.4407e-04 - mean_absolute_error: 0.0101 - val_loss: 9.3453e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.00007\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 1.6861e-04 - mean_absolute_error: 0.0107 - val_loss: 7.2690e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.00007\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 1.4409e-04 - mean_absolute_error: 0.0102 - val_loss: 8.0263e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.00007\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.7022e-04 - mean_absolute_error: 0.0112 - val_loss: 9.0644e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.00007\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.4557e-04 - mean_absolute_error: 0.0101 - val_loss: 8.5735e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.00007\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - 22s 291ms/step - loss: 1.5481e-04 - mean_absolute_error: 0.0105 - val_loss: 7.3291e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.00007\n",
      "Epoch 304/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.6553e-04 - mean_absolute_error: 0.0105 - val_loss: 9.5018e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.00007\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.5519e-04 - mean_absolute_error: 0.0105 - val_loss: 1.0201e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.00007\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.3672e-04 - mean_absolute_error: 0.0101 - val_loss: 1.0224e-04 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.00007\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 1.6980e-04 - mean_absolute_error: 0.0106 - val_loss: 8.2090e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.00007\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - 22s 297ms/step - loss: 1.5331e-04 - mean_absolute_error: 0.0104 - val_loss: 7.8410e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.00007\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.5907e-04 - mean_absolute_error: 0.0104 - val_loss: 6.9853e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.00007\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.5577e-04 - mean_absolute_error: 0.0103 - val_loss: 7.4679e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.00007\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 1.6555e-04 - mean_absolute_error: 0.0105 - val_loss: 7.3483e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.00007\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.5684e-04 - mean_absolute_error: 0.0104 - val_loss: 7.5815e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.00007\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.7144e-04 - mean_absolute_error: 0.0109 - val_loss: 6.8686e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.00007\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - 22s 291ms/step - loss: 1.5856e-04 - mean_absolute_error: 0.0103 - val_loss: 6.6219e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00314: val_loss improved from 0.00007 to 0.00007, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 1.5996e-04 - mean_absolute_error: 0.0106 - val_loss: 8.2626e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.00007\n",
      "Epoch 316/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.7082e-04 - mean_absolute_error: 0.0110 - val_loss: 7.3408e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.00007\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.4759e-04 - mean_absolute_error: 0.0103 - val_loss: 6.9558e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.00007\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.6127e-04 - mean_absolute_error: 0.0106 - val_loss: 9.2080e-05 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.00007\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - 21s 286ms/step - loss: 1.6793e-04 - mean_absolute_error: 0.0104 - val_loss: 7.2417e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.00007\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - 21s 286ms/step - loss: 1.5018e-04 - mean_absolute_error: 0.0106 - val_loss: 7.1481e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.00007\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - 22s 292ms/step - loss: 1.4488e-04 - mean_absolute_error: 0.0103 - val_loss: 9.7512e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.00007\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - 21s 285ms/step - loss: 1.6060e-04 - mean_absolute_error: 0.0106 - val_loss: 8.3968e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.00007\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - 21s 287ms/step - loss: 1.7012e-04 - mean_absolute_error: 0.0109 - val_loss: 7.2783e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.00007\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.6317e-04 - mean_absolute_error: 0.0106 - val_loss: 7.1369e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.00007\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.3415e-04 - mean_absolute_error: 0.0100 - val_loss: 6.6466e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.00007\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.4326e-04 - mean_absolute_error: 0.0100 - val_loss: 7.0611e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.00007\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.3881e-04 - mean_absolute_error: 0.0100 - val_loss: 7.6577e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.00007\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.6342e-04 - mean_absolute_error: 0.0105 - val_loss: 7.3252e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.00007\n",
      "Epoch 329/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.5532e-04 - mean_absolute_error: 0.0103 - val_loss: 7.2036e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.00007\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.7579e-04 - mean_absolute_error: 0.0109 - val_loss: 7.5798e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.00007\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.5325e-04 - mean_absolute_error: 0.0102 - val_loss: 8.6124e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.00007\n",
      "Epoch 332/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.6477e-04 - mean_absolute_error: 0.0103 - val_loss: 7.4388e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.00007\n",
      "Epoch 333/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.5975e-04 - mean_absolute_error: 0.0106 - val_loss: 7.3144e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.00007\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.3064e-04 - mean_absolute_error: 0.0099 - val_loss: 8.4287e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.00007\n",
      "Epoch 335/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.6815e-04 - mean_absolute_error: 0.0107 - val_loss: 8.0253e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.00007\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.4051e-04 - mean_absolute_error: 0.0101 - val_loss: 7.2317e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.00007\n",
      "Epoch 337/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.5272e-04 - mean_absolute_error: 0.0102 - val_loss: 8.0546e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.00007\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.5465e-04 - mean_absolute_error: 0.0106 - val_loss: 7.0392e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.00007\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.2721e-04 - mean_absolute_error: 0.0098 - val_loss: 7.2461e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.00007\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.3589e-04 - mean_absolute_error: 0.0100 - val_loss: 7.1205e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.00007\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - 22s 288ms/step - loss: 1.5265e-04 - mean_absolute_error: 0.0104 - val_loss: 1.0311e-04 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.00007\n",
      "Epoch 342/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.7338e-04 - mean_absolute_error: 0.0110 - val_loss: 7.3964e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.00007\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.5761e-04 - mean_absolute_error: 0.0106 - val_loss: 1.1446e-04 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.00007\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.7311e-04 - mean_absolute_error: 0.0110 - val_loss: 8.5911e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.00007\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.6863e-04 - mean_absolute_error: 0.0104 - val_loss: 7.2807e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.00007\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - 21s 284ms/step - loss: 1.7466e-04 - mean_absolute_error: 0.0109 - val_loss: 6.8565e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.00007\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.4695e-04 - mean_absolute_error: 0.0103 - val_loss: 8.3016e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.00007\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.5176e-04 - mean_absolute_error: 0.0102 - val_loss: 6.5916e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00348: val_loss improved from 0.00007 to 0.00007, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.6147e-04 - mean_absolute_error: 0.0106 - val_loss: 7.1691e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.00007\n",
      "Epoch 350/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.5286e-04 - mean_absolute_error: 0.0104 - val_loss: 6.8949e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.00007\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.4061e-04 - mean_absolute_error: 0.0101 - val_loss: 6.7268e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.00007\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - 22s 290ms/step - loss: 1.7283e-04 - mean_absolute_error: 0.0107 - val_loss: 7.8762e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.00007\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - 21s 284ms/step - loss: 1.5819e-04 - mean_absolute_error: 0.0108 - val_loss: 9.6530e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.00007\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - 21s 282ms/step - loss: 1.5258e-04 - mean_absolute_error: 0.0101 - val_loss: 6.9294e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.00007\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - 21s 284ms/step - loss: 1.4525e-04 - mean_absolute_error: 0.0102 - val_loss: 7.9124e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.00007\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.4357e-04 - mean_absolute_error: 0.0099 - val_loss: 6.5072e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00356: val_loss improved from 0.00007 to 0.00007, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.5400e-04 - mean_absolute_error: 0.0103 - val_loss: 1.0628e-04 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.00007\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.6522e-04 - mean_absolute_error: 0.0104 - val_loss: 7.4412e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.00007\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.5521e-04 - mean_absolute_error: 0.0101 - val_loss: 6.6717e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.00007\n",
      "Epoch 360/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.6546e-04 - mean_absolute_error: 0.0102 - val_loss: 7.2268e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.00007\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 1.4395e-04 - mean_absolute_error: 0.0100 - val_loss: 1.0648e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.00007\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.5500e-04 - mean_absolute_error: 0.0105 - val_loss: 7.9305e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.00007\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.4843e-04 - mean_absolute_error: 0.0102 - val_loss: 7.3000e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.00007\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 1.4329e-04 - mean_absolute_error: 0.0099 - val_loss: 7.8419e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.00007\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - 23s 307ms/step - loss: 1.5419e-04 - mean_absolute_error: 0.0101 - val_loss: 7.4276e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.00007\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.4548e-04 - mean_absolute_error: 0.0103 - val_loss: 7.1578e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.00007\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.4032e-04 - mean_absolute_error: 0.0100 - val_loss: 9.4400e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.00007\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - 24s 314ms/step - loss: 1.5634e-04 - mean_absolute_error: 0.0102 - val_loss: 7.5614e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.00007\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 1.5055e-04 - mean_absolute_error: 0.0102 - val_loss: 7.0968e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.00007\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.4615e-04 - mean_absolute_error: 0.0099 - val_loss: 8.6202e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.00007\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.5712e-04 - mean_absolute_error: 0.0104 - val_loss: 7.9878e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.00007\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - 22s 297ms/step - loss: 1.7474e-04 - mean_absolute_error: 0.0108 - val_loss: 8.2704e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.00007\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - 21s 285ms/step - loss: 1.4231e-04 - mean_absolute_error: 0.0101 - val_loss: 8.0101e-05 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.00007\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - 21s 285ms/step - loss: 1.6068e-04 - mean_absolute_error: 0.0105 - val_loss: 1.0453e-04 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.00007\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - 21s 285ms/step - loss: 1.5773e-04 - mean_absolute_error: 0.0106 - val_loss: 6.5160e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.00007\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - 21s 284ms/step - loss: 1.4751e-04 - mean_absolute_error: 0.0102 - val_loss: 7.9754e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.00007\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - 21s 287ms/step - loss: 1.6229e-04 - mean_absolute_error: 0.0104 - val_loss: 6.9264e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.00007\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 1.6240e-04 - mean_absolute_error: 0.0104 - val_loss: 6.7457e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.00007\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.3374e-04 - mean_absolute_error: 0.0100 - val_loss: 7.1307e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.00007\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.2502e-04 - mean_absolute_error: 0.0098 - val_loss: 7.0516e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.00007\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 1.6729e-04 - mean_absolute_error: 0.0107 - val_loss: 1.0086e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.00007\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.4419e-04 - mean_absolute_error: 0.0103 - val_loss: 7.9630e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.00007\n",
      "Epoch 383/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.3736e-04 - mean_absolute_error: 0.0099 - val_loss: 9.8088e-05 - val_mean_absolute_error: 0.0077\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.00007\n",
      "Epoch 384/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.5812e-04 - mean_absolute_error: 0.0108 - val_loss: 7.4488e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.00007\n",
      "Epoch 385/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.5412e-04 - mean_absolute_error: 0.0100 - val_loss: 7.3125e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.00007\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.7813e-04 - mean_absolute_error: 0.0108 - val_loss: 6.7000e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.00007\n",
      "Epoch 387/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.7377e-04 - mean_absolute_error: 0.0109 - val_loss: 9.5239e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.00007\n",
      "Epoch 388/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.5952e-04 - mean_absolute_error: 0.0106 - val_loss: 7.1609e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.00007\n",
      "Epoch 389/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.4736e-04 - mean_absolute_error: 0.0100 - val_loss: 7.8748e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.00007\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.4013e-04 - mean_absolute_error: 0.0102 - val_loss: 6.7365e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.00007\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.6237e-04 - mean_absolute_error: 0.0105 - val_loss: 7.1760e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.00007\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.4809e-04 - mean_absolute_error: 0.0102 - val_loss: 9.2844e-05 - val_mean_absolute_error: 0.0073\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.00007\n",
      "Epoch 393/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.6536e-04 - mean_absolute_error: 0.0106 - val_loss: 6.9902e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.00007\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - 22s 294ms/step - loss: 1.5468e-04 - mean_absolute_error: 0.0103 - val_loss: 6.7655e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.00007\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - 22s 294ms/step - loss: 1.3916e-04 - mean_absolute_error: 0.0099 - val_loss: 7.4386e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.00007\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.2833e-04 - mean_absolute_error: 0.0097 - val_loss: 6.4247e-05 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00396: val_loss improved from 0.00007 to 0.00006, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.3552e-04 - mean_absolute_error: 0.0099 - val_loss: 8.7908e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.00006\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.6083e-04 - mean_absolute_error: 0.0108 - val_loss: 7.1194e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.00006\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - 22s 295ms/step - loss: 1.5159e-04 - mean_absolute_error: 0.0101 - val_loss: 8.9600e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.00006\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - 21s 286ms/step - loss: 1.4058e-04 - mean_absolute_error: 0.0103 - val_loss: 6.9878e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.00006\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - 21s 283ms/step - loss: 1.3909e-04 - mean_absolute_error: 0.0100 - val_loss: 7.9639e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.00006\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - 21s 282ms/step - loss: 1.5874e-04 - mean_absolute_error: 0.0104 - val_loss: 6.4343e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.00006\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - 21s 284ms/step - loss: 1.2789e-04 - mean_absolute_error: 0.0099 - val_loss: 6.8871e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.00006\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - 21s 286ms/step - loss: 1.3976e-04 - mean_absolute_error: 0.0099 - val_loss: 7.6315e-05 - val_mean_absolute_error: 0.0072\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.00006\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.5115e-04 - mean_absolute_error: 0.0103 - val_loss: 1.5500e-04 - val_mean_absolute_error: 0.0090\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.00006\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.5737e-04 - mean_absolute_error: 0.0106 - val_loss: 6.6810e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.00006\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.4491e-04 - mean_absolute_error: 0.0101 - val_loss: 8.4587e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.00006\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - 22s 298ms/step - loss: 1.9459e-04 - mean_absolute_error: 0.0115 - val_loss: 7.2974e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.00006\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.7706e-04 - mean_absolute_error: 0.0110 - val_loss: 6.7601e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.00006\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.5074e-04 - mean_absolute_error: 0.0104 - val_loss: 7.3316e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.00006\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.3472e-04 - mean_absolute_error: 0.0100 - val_loss: 1.4173e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.00006\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.7450e-04 - mean_absolute_error: 0.0111 - val_loss: 6.6765e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.00006\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - 22s 299ms/step - loss: 1.3459e-04 - mean_absolute_error: 0.0098 - val_loss: 6.5979e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.00006\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.5676e-04 - mean_absolute_error: 0.0100 - val_loss: 1.0168e-04 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.00006\n",
      "Epoch 415/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.8400e-04 - mean_absolute_error: 0.0107 - val_loss: 6.8089e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.00006\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.5513e-04 - mean_absolute_error: 0.0101 - val_loss: 6.9012e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.00006\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.4833e-04 - mean_absolute_error: 0.0105 - val_loss: 7.3416e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.00006\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.5564e-04 - mean_absolute_error: 0.0103 - val_loss: 6.4434e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.00006\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.6869e-04 - mean_absolute_error: 0.0104 - val_loss: 6.2861e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00419: val_loss improved from 0.00006 to 0.00006, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 420/500\n",
      "75/75 [==============================] - 22s 299ms/step - loss: 1.5642e-04 - mean_absolute_error: 0.0104 - val_loss: 7.2998e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.00006\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - 22s 296ms/step - loss: 1.3344e-04 - mean_absolute_error: 0.0099 - val_loss: 6.9455e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.00006\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - 22s 292ms/step - loss: 1.5790e-04 - mean_absolute_error: 0.0105 - val_loss: 8.6806e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.00006\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - 21s 286ms/step - loss: 1.5228e-04 - mean_absolute_error: 0.0101 - val_loss: 9.4249e-05 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.00006\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - 21s 281ms/step - loss: 1.5273e-04 - mean_absolute_error: 0.0103 - val_loss: 6.9899e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.00006\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - 21s 281ms/step - loss: 1.4115e-04 - mean_absolute_error: 0.0100 - val_loss: 7.0296e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.00006\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - 22s 289ms/step - loss: 1.3483e-04 - mean_absolute_error: 0.0097 - val_loss: 7.1257e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.00006\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.3738e-04 - mean_absolute_error: 0.0099 - val_loss: 7.0424e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.00006\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - 24s 325ms/step - loss: 1.3798e-04 - mean_absolute_error: 0.0099 - val_loss: 7.3199e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.00006\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.3904e-04 - mean_absolute_error: 0.0100 - val_loss: 7.3340e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.00006\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.4366e-04 - mean_absolute_error: 0.0100 - val_loss: 7.2764e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.00006\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - 22s 296ms/step - loss: 1.2864e-04 - mean_absolute_error: 0.0094 - val_loss: 6.7174e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.00006\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.3408e-04 - mean_absolute_error: 0.0099 - val_loss: 7.3995e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.00006\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.2507e-04 - mean_absolute_error: 0.0096 - val_loss: 6.2672e-05 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00433: val_loss improved from 0.00006 to 0.00006, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.4409e-04 - mean_absolute_error: 0.0100 - val_loss: 6.8265e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.00006\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.6585e-04 - mean_absolute_error: 0.0105 - val_loss: 6.9483e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.00006\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - 23s 308ms/step - loss: 1.6210e-04 - mean_absolute_error: 0.0104 - val_loss: 7.2062e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.00006\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.4537e-04 - mean_absolute_error: 0.0101 - val_loss: 6.2060e-05 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00437: val_loss improved from 0.00006 to 0.00006, saving model to results\\2021-03-24_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - 23s 311ms/step - loss: 1.4627e-04 - mean_absolute_error: 0.0098 - val_loss: 8.0031e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.00006\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.3151e-04 - mean_absolute_error: 0.0096 - val_loss: 6.9022e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.00006\n",
      "Epoch 440/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 1.6477e-04 - mean_absolute_error: 0.0105 - val_loss: 9.3749e-05 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.00006\n",
      "Epoch 441/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.5744e-04 - mean_absolute_error: 0.0104 - val_loss: 7.0783e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.00006\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.4153e-04 - mean_absolute_error: 0.0099 - val_loss: 8.6968e-05 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.00006\n",
      "Epoch 443/500\n",
      "75/75 [==============================] - 22s 295ms/step - loss: 1.4408e-04 - mean_absolute_error: 0.0100 - val_loss: 7.3638e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.00006\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - 21s 284ms/step - loss: 1.5128e-04 - mean_absolute_error: 0.0103 - val_loss: 7.7026e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.00006\n",
      "Epoch 445/500\n",
      "75/75 [==============================] - 21s 284ms/step - loss: 1.3796e-04 - mean_absolute_error: 0.0100 - val_loss: 6.2110e-05 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.00006\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - 22s 289ms/step - loss: 1.4941e-04 - mean_absolute_error: 0.0101 - val_loss: 9.1932e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.00006\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - 21s 285ms/step - loss: 1.3763e-04 - mean_absolute_error: 0.0100 - val_loss: 6.4502e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.00006\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - 21s 281ms/step - loss: 1.3517e-04 - mean_absolute_error: 0.0101 - val_loss: 7.0430e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.00006\n",
      "Epoch 449/500\n",
      "75/75 [==============================] - 22s 288ms/step - loss: 1.3382e-04 - mean_absolute_error: 0.0099 - val_loss: 6.3392e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.00006\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - 21s 283ms/step - loss: 1.5200e-04 - mean_absolute_error: 0.0100 - val_loss: 7.2278e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.00006\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - 22s 288ms/step - loss: 1.4160e-04 - mean_absolute_error: 0.0100 - val_loss: 7.6932e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.00006\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - 23s 300ms/step - loss: 1.4197e-04 - mean_absolute_error: 0.0101 - val_loss: 8.9114e-05 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.00006\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.4238e-04 - mean_absolute_error: 0.0102 - val_loss: 6.6740e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.00006\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.4704e-04 - mean_absolute_error: 0.0102 - val_loss: 7.0434e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.00006\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.4647e-04 - mean_absolute_error: 0.0102 - val_loss: 6.7631e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.00006\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - 22s 294ms/step - loss: 1.5882e-04 - mean_absolute_error: 0.0107 - val_loss: 6.2279e-05 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.00006\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - 22s 288ms/step - loss: 1.4161e-04 - mean_absolute_error: 0.0098 - val_loss: 6.2409e-05 - val_mean_absolute_error: 0.0055\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.00006\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - 21s 287ms/step - loss: 1.4188e-04 - mean_absolute_error: 0.0099 - val_loss: 1.0816e-04 - val_mean_absolute_error: 0.0091\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.00006\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - 22s 294ms/step - loss: 1.5035e-04 - mean_absolute_error: 0.0106 - val_loss: 6.3390e-05 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.00006\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - 22s 288ms/step - loss: 1.2839e-04 - mean_absolute_error: 0.0097 - val_loss: 7.2950e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.00006\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - 22s 294ms/step - loss: 1.4848e-04 - mean_absolute_error: 0.0100 - val_loss: 6.6389e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.00006\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - 23s 306ms/step - loss: 1.4333e-04 - mean_absolute_error: 0.0103 - val_loss: 6.4458e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.00006\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - 22s 299ms/step - loss: 1.3958e-04 - mean_absolute_error: 0.0099 - val_loss: 9.0894e-05 - val_mean_absolute_error: 0.0075\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.00006\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.6292e-04 - mean_absolute_error: 0.0104 - val_loss: 7.2853e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.00006\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - 22s 296ms/step - loss: 1.4260e-04 - mean_absolute_error: 0.0098 - val_loss: 6.2256e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.00006\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.5183e-04 - mean_absolute_error: 0.0101 - val_loss: 6.7061e-05 - val_mean_absolute_error: 0.0067\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.00006\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.3254e-04 - mean_absolute_error: 0.0098 - val_loss: 7.0421e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.00006\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.4287e-04 - mean_absolute_error: 0.0101 - val_loss: 7.7057e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.00006\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - 23s 304ms/step - loss: 1.4460e-04 - mean_absolute_error: 0.0099 - val_loss: 1.2296e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.00006\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - 22s 296ms/step - loss: 1.5009e-04 - mean_absolute_error: 0.0104 - val_loss: 6.3530e-05 - val_mean_absolute_error: 0.0056\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.00006\n",
      "Epoch 471/500\n",
      "75/75 [==============================] - 22s 291ms/step - loss: 1.4343e-04 - mean_absolute_error: 0.0103 - val_loss: 6.6107e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.00006\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - 23s 309ms/step - loss: 1.5684e-04 - mean_absolute_error: 0.0103 - val_loss: 6.8893e-05 - val_mean_absolute_error: 0.0063\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.00006\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.4915e-04 - mean_absolute_error: 0.0100 - val_loss: 7.1654e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.00006\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.4390e-04 - mean_absolute_error: 0.0099 - val_loss: 8.4436e-05 - val_mean_absolute_error: 0.0076\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.00006\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.6068e-04 - mean_absolute_error: 0.0106 - val_loss: 6.9165e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.00006\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - 21s 285ms/step - loss: 1.5549e-04 - mean_absolute_error: 0.0100 - val_loss: 9.1652e-05 - val_mean_absolute_error: 0.0082\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.00006\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.3843e-04 - mean_absolute_error: 0.0100 - val_loss: 7.1598e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.00006\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.2876e-04 - mean_absolute_error: 0.0097 - val_loss: 7.8719e-05 - val_mean_absolute_error: 0.0074\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.00006\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.3800e-04 - mean_absolute_error: 0.0100 - val_loss: 7.6873e-05 - val_mean_absolute_error: 0.0066\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.00006\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.3384e-04 - mean_absolute_error: 0.0098 - val_loss: 9.1619e-05 - val_mean_absolute_error: 0.0078\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.00006\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - 22s 294ms/step - loss: 1.4905e-04 - mean_absolute_error: 0.0105 - val_loss: 6.6671e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.00006\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - 22s 293ms/step - loss: 1.4817e-04 - mean_absolute_error: 0.0099 - val_loss: 8.2379e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.00006\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.3761e-04 - mean_absolute_error: 0.0099 - val_loss: 7.6466e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.00006\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.3855e-04 - mean_absolute_error: 0.0098 - val_loss: 6.2302e-05 - val_mean_absolute_error: 0.0058\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.00006\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - 23s 305ms/step - loss: 1.3035e-04 - mean_absolute_error: 0.0098 - val_loss: 8.0130e-05 - val_mean_absolute_error: 0.0079\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.00006\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - 22s 298ms/step - loss: 1.4100e-04 - mean_absolute_error: 0.0098 - val_loss: 6.4163e-05 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.00006\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - 22s 293ms/step - loss: 1.3579e-04 - mean_absolute_error: 0.0099 - val_loss: 6.3793e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.00006\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.5721e-04 - mean_absolute_error: 0.0104 - val_loss: 6.3971e-05 - val_mean_absolute_error: 0.0057\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.00006\n",
      "Epoch 489/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.5092e-04 - mean_absolute_error: 0.0102 - val_loss: 9.4496e-05 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.00006\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - 22s 300ms/step - loss: 1.5669e-04 - mean_absolute_error: 0.0105 - val_loss: 8.9850e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.00006\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - 22s 297ms/step - loss: 1.3822e-04 - mean_absolute_error: 0.0100 - val_loss: 6.5616e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.00006\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - 22s 291ms/step - loss: 1.5601e-04 - mean_absolute_error: 0.0103 - val_loss: 6.4416e-05 - val_mean_absolute_error: 0.0062\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.00006\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - 22s 297ms/step - loss: 1.3545e-04 - mean_absolute_error: 0.0099 - val_loss: 6.6433e-05 - val_mean_absolute_error: 0.0060\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.00006\n",
      "Epoch 494/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.5095e-04 - mean_absolute_error: 0.0100 - val_loss: 7.7144e-05 - val_mean_absolute_error: 0.0071\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.00006\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.5193e-04 - mean_absolute_error: 0.0102 - val_loss: 8.1948e-05 - val_mean_absolute_error: 0.0068\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.00006\n",
      "Epoch 496/500\n",
      "75/75 [==============================] - 23s 301ms/step - loss: 1.5935e-04 - mean_absolute_error: 0.0103 - val_loss: 7.3753e-05 - val_mean_absolute_error: 0.0059\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.00006\n",
      "Epoch 497/500\n",
      "75/75 [==============================] - 22s 296ms/step - loss: 1.5527e-04 - mean_absolute_error: 0.0103 - val_loss: 8.5882e-05 - val_mean_absolute_error: 0.0064\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.00006\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - 22s 290ms/step - loss: 1.4196e-04 - mean_absolute_error: 0.0098 - val_loss: 7.0238e-05 - val_mean_absolute_error: 0.0061\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.00006\n",
      "Epoch 499/500\n",
      "75/75 [==============================] - 23s 303ms/step - loss: 1.4633e-04 - mean_absolute_error: 0.0100 - val_loss: 8.7712e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.00006\n",
      "Epoch 500/500\n",
      "75/75 [==============================] - 23s 302ms/step - loss: 1.5271e-04 - mean_absolute_error: 0.0102 - val_loss: 7.9117e-05 - val_mean_absolute_error: 0.0065\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.00006\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=\"logs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\jacob\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 3200.16$\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-5c0048ce34b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# printing metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{LOSS} loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean Absolute Error:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy score:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   open         high          low        close     adjclose  \\\n",
      "2020-12-31  3275.000000  3282.919922  3241.199951  3256.929932  3256.929932   \n",
      "2021-01-04  3270.000000  3272.000000  3144.020020  3186.629883  3186.629883   \n",
      "2021-01-08  3180.000000  3190.639893  3142.199951  3182.699951  3182.699951   \n",
      "2021-01-15  3123.020020  3142.550049  3095.169922  3104.250000  3104.250000   \n",
      "2021-01-25  3328.500000  3363.889893  3243.149902  3294.000000  3294.000000   \n",
      "2021-02-01  3242.360107  3350.260010  3235.030029  3342.879883  3342.879883   \n",
      "2021-02-05  3319.000000  3377.000000  3302.709961  3352.149902  3352.149902   \n",
      "2021-02-10  3314.000000  3317.949951  3254.000000  3286.580078  3286.580078   \n",
      "2021-02-12  3250.000000  3280.250000  3233.310059  3277.709961  3277.709961   \n",
      "2021-02-24  3166.750000  3171.229980  3125.379883  3159.530029  3159.530029   \n",
      "\n",
      "             volume ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
      "2020-12-31  2957200   AMZN  3187.500732       3294.000000  -69.429199   \n",
      "2021-01-04  4411400   AMZN  3192.338867       3326.129883    5.708984   \n",
      "2021-01-08  3537700   AMZN  3197.424805       3342.879883   14.724854   \n",
      "2021-01-15  4244000   AMZN  3198.699707       3322.939941   94.449707   \n",
      "2021-01-25  3749800   AMZN  3188.595703       3268.949951    0.000000   \n",
      "2021-02-01  4160200   AMZN  3188.805908       3194.500000    0.000000   \n",
      "2021-02-05  3613600   AMZN  3185.829834       3146.139893    0.000000   \n",
      "2021-02-10  3151600   AMZN  3187.892578       2977.570068    0.000000   \n",
      "2021-02-12  2329300   AMZN  3189.521484       2951.949951    0.000000   \n",
      "2021-02-24  3011300   AMZN  3194.023682       3135.729980    0.000000   \n",
      "\n",
      "            sell_profit  \n",
      "2020-12-31     0.000000  \n",
      "2021-01-04     0.000000  \n",
      "2021-01-08     0.000000  \n",
      "2021-01-15     0.000000  \n",
      "2021-01-25   105.404297  \n",
      "2021-02-01   154.073975  \n",
      "2021-02-05   166.320068  \n",
      "2021-02-10    98.687500  \n",
      "2021-02-12    88.188477  \n",
      "2021-02-24   -34.493652  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
