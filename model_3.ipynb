{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "LOSS = \"mae\"\n",
    "# huber loss\n",
    "#LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# Amazon stock market\n",
    "ticker = \"SPY\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88/88 [==============================] - 27s 276ms/step - loss: 0.0417 - mean_absolute_error: 0.0417 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02094, saving model to results\\2021-03-25_SPY-sh-1-sc-1-sbd-0-mae-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 25s 279ms/step - loss: 0.0228 - mean_absolute_error: 0.0228 - val_loss: 0.0153 - val_mean_absolute_error: 0.0153\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02094 to 0.01526, saving model to results\\2021-03-25_SPY-sh-1-sc-1-sbd-0-mae-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 27s 311ms/step - loss: 0.0214 - mean_absolute_error: 0.0214 - val_loss: 0.0099 - val_mean_absolute_error: 0.0099\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01526 to 0.00986, saving model to results\\2021-03-25_SPY-sh-1-sc-1-sbd-0-mae-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 27s 304ms/step - loss: 0.0197 - mean_absolute_error: 0.0197 - val_loss: 0.0122 - val_mean_absolute_error: 0.0122\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00986\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 29s 328ms/step - loss: 0.0198 - mean_absolute_error: 0.0198 - val_loss: 0.0133 - val_mean_absolute_error: 0.0133\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00986\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 29s 333ms/step - loss: 0.0182 - mean_absolute_error: 0.0182 - val_loss: 0.0139 - val_mean_absolute_error: 0.0139\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00986\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 29s 332ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0129 - val_mean_absolute_error: 0.0129\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00986\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 28s 317ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - val_loss: 0.0103 - val_mean_absolute_error: 0.0103\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00986\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 29s 327ms/step - loss: 0.0178 - mean_absolute_error: 0.0178 - val_loss: 0.0164 - val_mean_absolute_error: 0.0164\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00986\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 28s 324ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0149 - val_mean_absolute_error: 0.0149\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00986\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=\"logs\"\n",
    "\n",
    "# Save model as JSON\n",
    "model_3_15day = model.to_json()\n",
    "\n",
    "file_path = Path(\"model_3_15day.json\")\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(model_3_15day)\n",
    "\n",
    "# Save weights\n",
    "model_3_day_file_path = (\"model_3_15day.h5\")\n",
    "model.save_weights(\"model_3_15day.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\jacob\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "LOSS = \"mae\"\n",
    "# huber loss\n",
    "#LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# Amazon stock market\n",
    "ticker = \"SPY\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 403.48$\n",
      "Accuracy score: 0.5291607396870555\n",
      "Total buy profit: 682.9243583679199\n",
      "Total sell profit: -434.41931343078613\n",
      "Total profit: 248.5050449371338\n",
      "Profit per trade: 0.1767461201544337\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "#print(f\"{LOSS} loss:\", loss)\n",
    "#print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  open        high         low       close    adjclose  \\\n",
      "2020-12-17  371.940002  372.459991  371.049988  372.239990  369.449982   \n",
      "2020-12-21  364.970001  378.459991  362.029999  367.859985  366.659088   \n",
      "2020-12-24  368.079987  369.029999  367.450012  369.000000  367.795380   \n",
      "2021-01-04  375.309998  375.450012  364.820007  368.790009  367.586090   \n",
      "2021-01-06  369.709991  376.980011  369.119995  373.549988  372.330505   \n",
      "2021-01-25  383.670013  384.769989  378.459991  384.390015  383.135162   \n",
      "2021-02-09  389.609985  390.890015  389.170013  390.250000  388.976013   \n",
      "2021-02-11  391.239990  391.690002  388.100006  390.709991  389.434509   \n",
      "2021-02-16  393.959991  394.170013  391.529999  392.299988  391.019318   \n",
      "2021-02-25  390.410004  391.880005  380.779999  382.329987  381.081848   \n",
      "\n",
      "               volume ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
      "2020-12-17   64119500    SPY   375.214325        377.453766    5.764343   \n",
      "2020-12-21   96386700    SPY   375.855438        378.550171    9.196350   \n",
      "2020-12-24   26457900    SPY   376.538177        377.413879    8.742798   \n",
      "2021-01-04  110210800    SPY   379.247742        382.537109   11.661652   \n",
      "2021-01-06  107997700    SPY   379.534393        376.397217    7.203888   \n",
      "2021-01-25   70402000    SPY   390.812469        391.019318    7.677307   \n",
      "2021-02-09   35551100    SPY   394.331177        380.174835    0.000000   \n",
      "2021-02-11   42755400    SPY   397.326233        382.377625    0.000000   \n",
      "2021-02-16   50972400    SPY   399.780579        385.906067    0.000000   \n",
      "2021-02-25  146670500    SPY   399.665924        390.201996   18.584076   \n",
      "\n",
      "            sell_profit  \n",
      "2020-12-17     0.000000  \n",
      "2020-12-21     0.000000  \n",
      "2020-12-24     0.000000  \n",
      "2021-01-04     0.000000  \n",
      "2021-01-06     0.000000  \n",
      "2021-01-25     0.000000  \n",
      "2021-02-09    -5.355164  \n",
      "2021-02-11    -7.891724  \n",
      "2021-02-16    -8.761261  \n",
      "2021-02-25     0.000000  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
