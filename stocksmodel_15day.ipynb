{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTickerPriceData(tickers,period='3650d', interval='1d'):\n",
    "    #Getting Ticker Price Data (Open,High,Close,etc)\n",
    "    ticker_df = yf.download(tickers=tickers,period=period,interval=interval)\n",
    "    return ticker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-09-26</th>\n",
       "      <td>2.720714</td>\n",
       "      <td>2.777857</td>\n",
       "      <td>2.717857</td>\n",
       "      <td>2.771786</td>\n",
       "      <td>2.387515</td>\n",
       "      <td>1102948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-27</th>\n",
       "      <td>2.756071</td>\n",
       "      <td>2.766786</td>\n",
       "      <td>2.707857</td>\n",
       "      <td>2.728929</td>\n",
       "      <td>2.350600</td>\n",
       "      <td>810373200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-28</th>\n",
       "      <td>2.750714</td>\n",
       "      <td>2.767143</td>\n",
       "      <td>2.712500</td>\n",
       "      <td>2.750357</td>\n",
       "      <td>2.369057</td>\n",
       "      <td>723609600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-29</th>\n",
       "      <td>2.753929</td>\n",
       "      <td>2.768571</td>\n",
       "      <td>2.738571</td>\n",
       "      <td>2.749286</td>\n",
       "      <td>2.368134</td>\n",
       "      <td>405812400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-02</th>\n",
       "      <td>2.682143</td>\n",
       "      <td>2.709643</td>\n",
       "      <td>2.653571</td>\n",
       "      <td>2.673571</td>\n",
       "      <td>2.302917</td>\n",
       "      <td>712639200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-22</th>\n",
       "      <td>120.330002</td>\n",
       "      <td>123.870003</td>\n",
       "      <td>120.260002</td>\n",
       "      <td>123.389999</td>\n",
       "      <td>123.389999</td>\n",
       "      <td>111912300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-23</th>\n",
       "      <td>123.330002</td>\n",
       "      <td>124.239998</td>\n",
       "      <td>122.139999</td>\n",
       "      <td>122.540001</td>\n",
       "      <td>122.540001</td>\n",
       "      <td>95467100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-24</th>\n",
       "      <td>122.820000</td>\n",
       "      <td>122.900002</td>\n",
       "      <td>120.070000</td>\n",
       "      <td>120.089996</td>\n",
       "      <td>120.089996</td>\n",
       "      <td>88530500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-25</th>\n",
       "      <td>119.540001</td>\n",
       "      <td>121.660004</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>120.589996</td>\n",
       "      <td>120.589996</td>\n",
       "      <td>98844700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>120.349998</td>\n",
       "      <td>121.480003</td>\n",
       "      <td>118.919998</td>\n",
       "      <td>121.209999</td>\n",
       "      <td>121.209999</td>\n",
       "      <td>93958900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3650 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2006-09-26    2.720714    2.777857    2.717857    2.771786    2.387515   \n",
       "2006-09-27    2.756071    2.766786    2.707857    2.728929    2.350600   \n",
       "2006-09-28    2.750714    2.767143    2.712500    2.750357    2.369057   \n",
       "2006-09-29    2.753929    2.768571    2.738571    2.749286    2.368134   \n",
       "2006-10-02    2.682143    2.709643    2.653571    2.673571    2.302917   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2021-03-22  120.330002  123.870003  120.260002  123.389999  123.389999   \n",
       "2021-03-23  123.330002  124.239998  122.139999  122.540001  122.540001   \n",
       "2021-03-24  122.820000  122.900002  120.070000  120.089996  120.089996   \n",
       "2021-03-25  119.540001  121.660004  119.000000  120.589996  120.589996   \n",
       "2021-03-26  120.349998  121.480003  118.919998  121.209999  121.209999   \n",
       "\n",
       "                Volume  \n",
       "Date                    \n",
       "2006-09-26  1102948000  \n",
       "2006-09-27   810373200  \n",
       "2006-09-28   723609600  \n",
       "2006-09-29   405812400  \n",
       "2006-10-02   712639200  \n",
       "...                ...  \n",
       "2021-03-22   111912300  \n",
       "2021-03-23    95467100  \n",
       "2021-03-24    88530500  \n",
       "2021-03-25    98844700  \n",
       "2021-03-26    93958900  \n",
       "\n",
       "[3650 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTickerPriceData(['AAPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['Adj Close', 'Volume', 'Open', 'High', 'Low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yfinance\n",
    "        df = getTickerPriceData(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['Adj Close'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 10\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = False\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = True\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"Adj Close\", \"Volume\", \"Open\", \"High\", \"Low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "LOSS = \"mae\"\n",
    "# huber loss\n",
    "#LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 700\n",
    "# Apple Stock \n",
    "ticker = \"AAPL\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/700\n",
      "45/45 [==============================] - 22s 400ms/step - loss: 0.0285 - mean_absolute_error: 0.0285 - val_loss: 0.0363 - val_mean_absolute_error: 0.0363\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03629, saving model to results\\2021-03-28_AAPL-sh-0-sc-1-sbd-1-mae-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n",
      "Epoch 2/700\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 0.0104 - mean_absolute_error: 0.0104 - val_loss: 0.0322 - val_mean_absolute_error: 0.0322\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03629 to 0.03223, saving model to results\\2021-03-28_AAPL-sh-0-sc-1-sbd-1-mae-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n",
      "Epoch 3/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0101 - mean_absolute_error: 0.0101 - val_loss: 0.0373 - val_mean_absolute_error: 0.0373\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.03223\n",
      "Epoch 4/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0096 - mean_absolute_error: 0.0096 - val_loss: 0.0378 - val_mean_absolute_error: 0.0378\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03223\n",
      "Epoch 5/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0093 - mean_absolute_error: 0.0093 - val_loss: 0.0399 - val_mean_absolute_error: 0.0399\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03223\n",
      "Epoch 6/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0090 - mean_absolute_error: 0.0090 - val_loss: 0.0460 - val_mean_absolute_error: 0.0460\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03223\n",
      "Epoch 7/700\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.0087 - mean_absolute_error: 0.0087 - val_loss: 0.0511 - val_mean_absolute_error: 0.0511\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03223\n",
      "Epoch 8/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0088 - mean_absolute_error: 0.0088 - val_loss: 0.0369 - val_mean_absolute_error: 0.0369\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03223\n",
      "Epoch 9/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0507 - val_mean_absolute_error: 0.0507\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03223\n",
      "Epoch 10/700\n",
      "45/45 [==============================] - 15s 337ms/step - loss: 0.0086 - mean_absolute_error: 0.0086 - val_loss: 0.0529 - val_mean_absolute_error: 0.0529\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03223\n",
      "Epoch 11/700\n",
      "45/45 [==============================] - 17s 378ms/step - loss: 0.0084 - mean_absolute_error: 0.0084 - val_loss: 0.0402 - val_mean_absolute_error: 0.0402\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.03223\n",
      "Epoch 12/700\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 0.0401 - val_mean_absolute_error: 0.0401\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.03223\n",
      "Epoch 13/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0521 - val_mean_absolute_error: 0.0521\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.03223\n",
      "Epoch 14/700\n",
      "45/45 [==============================] - 15s 335ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0514 - val_mean_absolute_error: 0.0514\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.03223\n",
      "Epoch 15/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0438 - val_mean_absolute_error: 0.0438\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.03223\n",
      "Epoch 16/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0082 - mean_absolute_error: 0.0082 - val_loss: 0.0606 - val_mean_absolute_error: 0.0606\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.03223\n",
      "Epoch 17/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0381 - val_mean_absolute_error: 0.0381\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.03223\n",
      "Epoch 18/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0447 - val_mean_absolute_error: 0.0447\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.03223\n",
      "Epoch 19/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0472 - val_mean_absolute_error: 0.0472\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.03223\n",
      "Epoch 20/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0516 - val_mean_absolute_error: 0.0516\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.03223\n",
      "Epoch 21/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0500 - val_mean_absolute_error: 0.0500\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.03223\n",
      "Epoch 22/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0079 - mean_absolute_error: 0.0079 - val_loss: 0.0568 - val_mean_absolute_error: 0.0568\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.03223\n",
      "Epoch 23/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0083 - mean_absolute_error: 0.0083 - val_loss: 0.0419 - val_mean_absolute_error: 0.0419\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.03223\n",
      "Epoch 24/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0600 - val_mean_absolute_error: 0.0600\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.03223\n",
      "Epoch 25/700\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.0076 - mean_absolute_error: 0.0076 - val_loss: 0.0412 - val_mean_absolute_error: 0.0412\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.03223\n",
      "Epoch 26/700\n",
      "45/45 [==============================] - 15s 344ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0520 - val_mean_absolute_error: 0.0520\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03223\n",
      "Epoch 27/700\n",
      "45/45 [==============================] - 16s 364ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0489 - val_mean_absolute_error: 0.0489\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.03223\n",
      "Epoch 28/700\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0486 - val_mean_absolute_error: 0.0486\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.03223\n",
      "Epoch 29/700\n",
      "45/45 [==============================] - 16s 351ms/step - loss: 0.0078 - mean_absolute_error: 0.0078 - val_loss: 0.0571 - val_mean_absolute_error: 0.0571\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.03223\n",
      "Epoch 30/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0085 - mean_absolute_error: 0.0085 - val_loss: 0.0504 - val_mean_absolute_error: 0.0504\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.03223\n",
      "Epoch 31/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0417 - val_mean_absolute_error: 0.0417\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.03223\n",
      "Epoch 32/700\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0475 - val_mean_absolute_error: 0.0475\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.03223\n",
      "Epoch 33/700\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0413 - val_mean_absolute_error: 0.0413\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.03223\n",
      "Epoch 34/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0625 - val_mean_absolute_error: 0.0625\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.03223\n",
      "Epoch 35/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0461 - val_mean_absolute_error: 0.0461\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.03223\n",
      "Epoch 36/700\n",
      "45/45 [==============================] - 15s 344ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0566 - val_mean_absolute_error: 0.0566\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.03223\n",
      "Epoch 37/700\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0489 - val_mean_absolute_error: 0.0489\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.03223\n",
      "Epoch 38/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0077 - mean_absolute_error: 0.0077 - val_loss: 0.0476 - val_mean_absolute_error: 0.0476\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.03223\n",
      "Epoch 39/700\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0471 - val_mean_absolute_error: 0.0471\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.03223\n",
      "Epoch 40/700\n",
      "45/45 [==============================] - 16s 360ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0560 - val_mean_absolute_error: 0.0560\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.03223\n",
      "Epoch 41/700\n",
      "45/45 [==============================] - 16s 349ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0350 - val_mean_absolute_error: 0.0350\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.03223\n",
      "Epoch 42/700\n",
      "45/45 [==============================] - 16s 349ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0578 - val_mean_absolute_error: 0.0578\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.03223\n",
      "Epoch 43/700\n",
      "45/45 [==============================] - 16s 348ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0381 - val_mean_absolute_error: 0.0381\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.03223\n",
      "Epoch 44/700\n",
      "45/45 [==============================] - 16s 348ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0541 - val_mean_absolute_error: 0.0541\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.03223\n",
      "Epoch 45/700\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0319 - val_mean_absolute_error: 0.0319\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.03223 to 0.03188, saving model to results\\2021-03-28_AAPL-sh-0-sc-1-sbd-1-mae-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n",
      "Epoch 46/700\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 0.0380 - val_mean_absolute_error: 0.0380\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03188\n",
      "Epoch 47/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0280 - val_mean_absolute_error: 0.0280\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.03188 to 0.02800, saving model to results\\2021-03-28_AAPL-sh-0-sc-1-sbd-1-mae-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n",
      "Epoch 48/700\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0363 - val_mean_absolute_error: 0.0363\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.02800\n",
      "Epoch 49/700\n",
      "45/45 [==============================] - 18s 397ms/step - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0394 - val_mean_absolute_error: 0.0394\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.02800\n",
      "Epoch 50/700\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.0081 - mean_absolute_error: 0.0081 - val_loss: 0.0289 - val_mean_absolute_error: 0.0289\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.02800\n",
      "Epoch 51/700\n",
      "45/45 [==============================] - 16s 358ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0309 - val_mean_absolute_error: 0.0309\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.02800\n",
      "Epoch 52/700\n",
      "45/45 [==============================] - 16s 351ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0384 - val_mean_absolute_error: 0.0384\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.02800\n",
      "Epoch 53/700\n",
      "45/45 [==============================] - 16s 364ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0318 - val_mean_absolute_error: 0.0318\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.02800\n",
      "Epoch 54/700\n",
      "45/45 [==============================] - 16s 352ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0402 - val_mean_absolute_error: 0.0402\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.02800\n",
      "Epoch 55/700\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.02800\n",
      "Epoch 56/700\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0420 - val_mean_absolute_error: 0.0420\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.02800\n",
      "Epoch 57/700\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0268 - val_mean_absolute_error: 0.0268\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.02800 to 0.02683, saving model to results\\2021-03-28_AAPL-sh-0-sc-1-sbd-1-mae-adam-LSTM-seq-50-step-10-layers-2-units-256.h5\n",
      "Epoch 58/700\n",
      "45/45 [==============================] - 16s 357ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0300 - val_mean_absolute_error: 0.0300\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.02683\n",
      "Epoch 59/700\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.0375 - val_mean_absolute_error: 0.0375\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.02683\n",
      "Epoch 60/700\n",
      "45/45 [==============================] - 16s 360ms/step - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0358 - val_mean_absolute_error: 0.0358\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.02683\n",
      "Epoch 61/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0394 - val_mean_absolute_error: 0.0394\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.02683\n",
      "Epoch 62/700\n",
      "45/45 [==============================] - 16s 350ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0319 - val_mean_absolute_error: 0.0319\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.02683\n",
      "Epoch 63/700\n",
      "45/45 [==============================] - 16s 353ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0299 - val_mean_absolute_error: 0.0299\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.02683\n",
      "Epoch 64/700\n",
      "45/45 [==============================] - 15s 345ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0452 - val_mean_absolute_error: 0.0452\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.02683\n",
      "Epoch 65/700\n",
      "45/45 [==============================] - 15s 343ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.0649 - val_mean_absolute_error: 0.0649\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.02683\n",
      "Epoch 66/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0615 - val_mean_absolute_error: 0.0615\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.02683\n",
      "Epoch 67/700\n",
      "45/45 [==============================] - 15s 335ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0511 - val_mean_absolute_error: 0.0511\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.02683\n",
      "Epoch 68/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0766 - val_mean_absolute_error: 0.0766\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.02683\n",
      "Epoch 69/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0606 - val_mean_absolute_error: 0.0606\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.02683\n",
      "Epoch 70/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.0462 - val_mean_absolute_error: 0.0462\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.02683\n",
      "Epoch 71/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0893 - val_mean_absolute_error: 0.0893\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.02683\n",
      "Epoch 72/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0631 - val_mean_absolute_error: 0.0631\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.02683\n",
      "Epoch 73/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0487 - val_mean_absolute_error: 0.0487\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.02683\n",
      "Epoch 74/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0565 - val_mean_absolute_error: 0.0565\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.02683\n",
      "Epoch 75/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0664 - val_mean_absolute_error: 0.0664\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.02683\n",
      "Epoch 76/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0491 - val_mean_absolute_error: 0.0491\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.02683\n",
      "Epoch 77/700\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0074 - mean_absolute_error: 0.0074 - val_loss: 0.0587 - val_mean_absolute_error: 0.0587\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.02683\n",
      "Epoch 78/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0656 - val_mean_absolute_error: 0.0656\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.02683\n",
      "Epoch 79/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.0723 - val_mean_absolute_error: 0.0723\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.02683\n",
      "Epoch 80/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0617 - val_mean_absolute_error: 0.0617\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.02683\n",
      "Epoch 81/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0538 - val_mean_absolute_error: 0.0538\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.02683\n",
      "Epoch 82/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0683 - val_mean_absolute_error: 0.0683\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.02683\n",
      "Epoch 83/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.0651 - val_mean_absolute_error: 0.0651\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.02683\n",
      "Epoch 84/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.0717 - val_mean_absolute_error: 0.0717\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.02683\n",
      "Epoch 85/700\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0754 - val_mean_absolute_error: 0.0754\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.02683\n",
      "Epoch 86/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0868 - val_mean_absolute_error: 0.0868\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.02683\n",
      "Epoch 87/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.0772 - val_mean_absolute_error: 0.0772\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.02683\n",
      "Epoch 88/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.0808 - val_mean_absolute_error: 0.0808\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.02683\n",
      "Epoch 89/700\n",
      "45/45 [==============================] - 15s 337ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.0937 - val_mean_absolute_error: 0.0937\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.02683\n",
      "Epoch 90/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.0903 - val_mean_absolute_error: 0.0903\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.02683\n",
      "Epoch 91/700\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.1057 - val_mean_absolute_error: 0.1057\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.02683\n",
      "Epoch 92/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.1002 - val_mean_absolute_error: 0.1002\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.02683\n",
      "Epoch 93/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.0939 - val_mean_absolute_error: 0.0939\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.02683\n",
      "Epoch 94/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1185 - val_mean_absolute_error: 0.1185\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.02683\n",
      "Epoch 95/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1039 - val_mean_absolute_error: 0.1039\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.02683\n",
      "Epoch 96/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.1222 - val_mean_absolute_error: 0.1222\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.02683\n",
      "Epoch 97/700\n",
      "45/45 [==============================] - 15s 337ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.1207 - val_mean_absolute_error: 0.1207\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.02683\n",
      "Epoch 98/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1295 - val_mean_absolute_error: 0.1295\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.02683\n",
      "Epoch 99/700\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1187 - val_mean_absolute_error: 0.1187\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.02683\n",
      "Epoch 100/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1293 - val_mean_absolute_error: 0.1293\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02683\n",
      "Epoch 101/700\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1457 - val_mean_absolute_error: 0.1457\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.02683\n",
      "Epoch 102/700\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.1250 - val_mean_absolute_error: 0.1250\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02683\n",
      "Epoch 103/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1385 - val_mean_absolute_error: 0.1385\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.02683\n",
      "Epoch 104/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.1487 - val_mean_absolute_error: 0.1487\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02683\n",
      "Epoch 105/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1283 - val_mean_absolute_error: 0.1283\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02683\n",
      "Epoch 106/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1451 - val_mean_absolute_error: 0.1451\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02683\n",
      "Epoch 107/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1463 - val_mean_absolute_error: 0.1463\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02683\n",
      "Epoch 108/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1355 - val_mean_absolute_error: 0.1355\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02683\n",
      "Epoch 109/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1469 - val_mean_absolute_error: 0.1469\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02683\n",
      "Epoch 110/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1448 - val_mean_absolute_error: 0.1448\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02683\n",
      "Epoch 111/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1503 - val_mean_absolute_error: 0.1503\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02683\n",
      "Epoch 112/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.1417 - val_mean_absolute_error: 0.1417\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02683\n",
      "Epoch 113/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.1368 - val_mean_absolute_error: 0.1368\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02683\n",
      "Epoch 114/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.1356 - val_mean_absolute_error: 0.1356\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02683\n",
      "Epoch 115/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0075 - mean_absolute_error: 0.0075 - val_loss: 0.1385 - val_mean_absolute_error: 0.1385\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02683\n",
      "Epoch 116/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1628 - val_mean_absolute_error: 0.1628\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02683\n",
      "Epoch 117/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.1492 - val_mean_absolute_error: 0.1492\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02683\n",
      "Epoch 118/700\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1544 - val_mean_absolute_error: 0.1544\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02683\n",
      "Epoch 119/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1663 - val_mean_absolute_error: 0.1663\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02683\n",
      "Epoch 120/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.1665 - val_mean_absolute_error: 0.1665\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02683\n",
      "Epoch 121/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1641 - val_mean_absolute_error: 0.1641\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02683\n",
      "Epoch 122/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1675 - val_mean_absolute_error: 0.1675\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02683\n",
      "Epoch 123/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.1667 - val_mean_absolute_error: 0.1667\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02683\n",
      "Epoch 124/700\n",
      "45/45 [==============================] - 16s 355ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1428 - val_mean_absolute_error: 0.1428\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02683\n",
      "Epoch 125/700\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1477 - val_mean_absolute_error: 0.1477\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02683\n",
      "Epoch 126/700\n",
      "45/45 [==============================] - 16s 347ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1421 - val_mean_absolute_error: 0.1421\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02683\n",
      "Epoch 127/700\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1408 - val_mean_absolute_error: 0.1408\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02683\n",
      "Epoch 128/700\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1535 - val_mean_absolute_error: 0.1535\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02683\n",
      "Epoch 129/700\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1770 - val_mean_absolute_error: 0.1770\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02683\n",
      "Epoch 130/700\n",
      "45/45 [==============================] - 16s 358ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.1587 - val_mean_absolute_error: 0.1587\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02683\n",
      "Epoch 131/700\n",
      "45/45 [==============================] - 16s 361ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1520 - val_mean_absolute_error: 0.1520\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.02683\n",
      "Epoch 132/700\n",
      "45/45 [==============================] - 16s 363ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1716 - val_mean_absolute_error: 0.1716\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.02683\n",
      "Epoch 133/700\n",
      "45/45 [==============================] - 16s 350ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.1809 - val_mean_absolute_error: 0.1809\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.02683\n",
      "Epoch 134/700\n",
      "45/45 [==============================] - 16s 354ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1810 - val_mean_absolute_error: 0.1810\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.02683\n",
      "Epoch 135/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1775 - val_mean_absolute_error: 0.1775\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.02683\n",
      "Epoch 136/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1752 - val_mean_absolute_error: 0.1752\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.02683\n",
      "Epoch 137/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1846 - val_mean_absolute_error: 0.1846\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.02683\n",
      "Epoch 138/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1722 - val_mean_absolute_error: 0.1722\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.02683\n",
      "Epoch 139/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1750 - val_mean_absolute_error: 0.1750\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.02683\n",
      "Epoch 140/700\n",
      "45/45 [==============================] - 16s 349ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1759 - val_mean_absolute_error: 0.1759\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.02683\n",
      "Epoch 141/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1810 - val_mean_absolute_error: 0.1810\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.02683\n",
      "Epoch 142/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1774 - val_mean_absolute_error: 0.1774\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.02683\n",
      "Epoch 143/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1740 - val_mean_absolute_error: 0.1740\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.02683\n",
      "Epoch 144/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0072 - mean_absolute_error: 0.0072 - val_loss: 0.1654 - val_mean_absolute_error: 0.1654\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.02683\n",
      "Epoch 145/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.1723 - val_mean_absolute_error: 0.1723\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.02683\n",
      "Epoch 146/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1672 - val_mean_absolute_error: 0.1672\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.02683\n",
      "Epoch 147/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1805 - val_mean_absolute_error: 0.1805\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.02683\n",
      "Epoch 148/700\n",
      "45/45 [==============================] - 14s 305ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.1721 - val_mean_absolute_error: 0.1721\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.02683\n",
      "Epoch 149/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1688 - val_mean_absolute_error: 0.1688\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.02683\n",
      "Epoch 150/700\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1721 - val_mean_absolute_error: 0.1721\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.02683\n",
      "Epoch 151/700\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1768 - val_mean_absolute_error: 0.1768\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.02683\n",
      "Epoch 152/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1809 - val_mean_absolute_error: 0.1809\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.02683\n",
      "Epoch 153/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1829 - val_mean_absolute_error: 0.1829\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.02683\n",
      "Epoch 154/700\n",
      "45/45 [==============================] - 14s 323ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1735 - val_mean_absolute_error: 0.1735\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.02683\n",
      "Epoch 155/700\n",
      "45/45 [==============================] - 14s 323ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1780 - val_mean_absolute_error: 0.1780\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.02683\n",
      "Epoch 156/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1610 - val_mean_absolute_error: 0.1610\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.02683\n",
      "Epoch 157/700\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1892 - val_mean_absolute_error: 0.1892\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.02683\n",
      "Epoch 158/700\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1686 - val_mean_absolute_error: 0.1686\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.02683\n",
      "Epoch 159/700\n",
      "45/45 [==============================] - 13s 301ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1761 - val_mean_absolute_error: 0.1761\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.02683\n",
      "Epoch 160/700\n",
      "45/45 [==============================] - 14s 323ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1813 - val_mean_absolute_error: 0.1813\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.02683\n",
      "Epoch 161/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1878 - val_mean_absolute_error: 0.1878\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.02683\n",
      "Epoch 162/700\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1844 - val_mean_absolute_error: 0.1844\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.02683\n",
      "Epoch 163/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1823 - val_mean_absolute_error: 0.1823\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.02683\n",
      "Epoch 164/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1737 - val_mean_absolute_error: 0.1737\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.02683\n",
      "Epoch 165/700\n",
      "45/45 [==============================] - 14s 323ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1874 - val_mean_absolute_error: 0.1874\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.02683\n",
      "Epoch 166/700\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1712 - val_mean_absolute_error: 0.1712\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.02683\n",
      "Epoch 167/700\n",
      "45/45 [==============================] - 13s 297ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1868 - val_mean_absolute_error: 0.1868\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.02683\n",
      "Epoch 168/700\n",
      "45/45 [==============================] - 14s 305ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1871 - val_mean_absolute_error: 0.1871\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.02683\n",
      "Epoch 169/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1869 - val_mean_absolute_error: 0.1869\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.02683\n",
      "Epoch 170/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1662 - val_mean_absolute_error: 0.1662\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.02683\n",
      "Epoch 171/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1777 - val_mean_absolute_error: 0.1777\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.02683\n",
      "Epoch 172/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1884 - val_mean_absolute_error: 0.1884\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.02683\n",
      "Epoch 173/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1765 - val_mean_absolute_error: 0.1765\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.02683\n",
      "Epoch 174/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1747 - val_mean_absolute_error: 0.1747\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.02683\n",
      "Epoch 175/700\n",
      "45/45 [==============================] - 14s 305ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.1880 - val_mean_absolute_error: 0.1880\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.02683\n",
      "Epoch 176/700\n",
      "45/45 [==============================] - 13s 286ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1860 - val_mean_absolute_error: 0.1860\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.02683\n",
      "Epoch 177/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1914 - val_mean_absolute_error: 0.1914\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.02683\n",
      "Epoch 178/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1694 - val_mean_absolute_error: 0.1694\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.02683\n",
      "Epoch 179/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1635 - val_mean_absolute_error: 0.1635\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.02683\n",
      "Epoch 180/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1563 - val_mean_absolute_error: 0.1563\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.02683\n",
      "Epoch 181/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1825 - val_mean_absolute_error: 0.1825\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.02683\n",
      "Epoch 182/700\n",
      "45/45 [==============================] - 14s 323ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2028 - val_mean_absolute_error: 0.2028\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.02683\n",
      "Epoch 183/700\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2037 - val_mean_absolute_error: 0.2037\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.02683\n",
      "Epoch 184/700\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1836 - val_mean_absolute_error: 0.1836\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.02683\n",
      "Epoch 185/700\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.2053 - val_mean_absolute_error: 0.2053\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.02683\n",
      "Epoch 186/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2014 - val_mean_absolute_error: 0.2014\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.02683\n",
      "Epoch 187/700\n",
      "45/45 [==============================] - 14s 305ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1829 - val_mean_absolute_error: 0.1829\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.02683\n",
      "Epoch 188/700\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.1970 - val_mean_absolute_error: 0.1970\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.02683\n",
      "Epoch 189/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1694 - val_mean_absolute_error: 0.1694\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.02683\n",
      "Epoch 190/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1837 - val_mean_absolute_error: 0.1837\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.02683\n",
      "Epoch 191/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1951 - val_mean_absolute_error: 0.1951\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.02683\n",
      "Epoch 192/700\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 0.0073 - mean_absolute_error: 0.0073 - val_loss: 0.2080 - val_mean_absolute_error: 0.2080\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.02683\n",
      "Epoch 193/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1989 - val_mean_absolute_error: 0.1989\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.02683\n",
      "Epoch 194/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1923 - val_mean_absolute_error: 0.1923\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.02683\n",
      "Epoch 195/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1915 - val_mean_absolute_error: 0.1915\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.02683\n",
      "Epoch 196/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2029 - val_mean_absolute_error: 0.2029\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.02683\n",
      "Epoch 197/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1979 - val_mean_absolute_error: 0.1979\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.02683\n",
      "Epoch 198/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1831 - val_mean_absolute_error: 0.1831\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.02683\n",
      "Epoch 199/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1888 - val_mean_absolute_error: 0.1888\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.02683\n",
      "Epoch 200/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1787 - val_mean_absolute_error: 0.1787\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.02683\n",
      "Epoch 201/700\n",
      "45/45 [==============================] - 13s 299ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1883 - val_mean_absolute_error: 0.1883\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.02683\n",
      "Epoch 202/700\n",
      "45/45 [==============================] - 13s 292ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1934 - val_mean_absolute_error: 0.1934\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.02683\n",
      "Epoch 203/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.2021 - val_mean_absolute_error: 0.2021\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.02683\n",
      "Epoch 204/700\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1902 - val_mean_absolute_error: 0.1902\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.02683\n",
      "Epoch 205/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1880 - val_mean_absolute_error: 0.1880\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.02683\n",
      "Epoch 206/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.1989 - val_mean_absolute_error: 0.1989\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.02683\n",
      "Epoch 207/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1895 - val_mean_absolute_error: 0.1895\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.02683\n",
      "Epoch 208/700\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1865 - val_mean_absolute_error: 0.1865\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.02683\n",
      "Epoch 209/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1976 - val_mean_absolute_error: 0.1976\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.02683\n",
      "Epoch 210/700\n",
      "45/45 [==============================] - 13s 300ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1871 - val_mean_absolute_error: 0.1871\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.02683\n",
      "Epoch 211/700\n",
      "45/45 [==============================] - 13s 300ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1930 - val_mean_absolute_error: 0.1930\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.02683\n",
      "Epoch 212/700\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1966 - val_mean_absolute_error: 0.1966\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.02683\n",
      "Epoch 213/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1917 - val_mean_absolute_error: 0.1917\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.02683\n",
      "Epoch 214/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1751 - val_mean_absolute_error: 0.1751\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.02683\n",
      "Epoch 215/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1808 - val_mean_absolute_error: 0.1808\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.02683\n",
      "Epoch 216/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1846 - val_mean_absolute_error: 0.1846\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.02683\n",
      "Epoch 217/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1795 - val_mean_absolute_error: 0.1795\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.02683\n",
      "Epoch 218/700\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1811 - val_mean_absolute_error: 0.1811\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.02683\n",
      "Epoch 219/700\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1812 - val_mean_absolute_error: 0.1812\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.02683\n",
      "Epoch 220/700\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1986 - val_mean_absolute_error: 0.1986\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.02683\n",
      "Epoch 221/700\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1889 - val_mean_absolute_error: 0.1889\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.02683\n",
      "Epoch 222/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1944 - val_mean_absolute_error: 0.1944\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.02683\n",
      "Epoch 223/700\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1807 - val_mean_absolute_error: 0.1807\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.02683\n",
      "Epoch 224/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1943 - val_mean_absolute_error: 0.1943\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.02683\n",
      "Epoch 225/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1832 - val_mean_absolute_error: 0.1832\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.02683\n",
      "Epoch 226/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1965 - val_mean_absolute_error: 0.1965\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.02683\n",
      "Epoch 227/700\n",
      "45/45 [==============================] - 13s 297ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1838 - val_mean_absolute_error: 0.1838\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.02683\n",
      "Epoch 228/700\n",
      "45/45 [==============================] - 13s 301ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 0.1883 - val_mean_absolute_error: 0.1883\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.02683\n",
      "Epoch 229/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.2087 - val_mean_absolute_error: 0.2087\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.02683\n",
      "Epoch 230/700\n",
      "45/45 [==============================] - 14s 323ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2026 - val_mean_absolute_error: 0.2026\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.02683\n",
      "Epoch 231/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1998 - val_mean_absolute_error: 0.1998\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.02683\n",
      "Epoch 232/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1897 - val_mean_absolute_error: 0.1897\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.02683\n",
      "Epoch 233/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1770 - val_mean_absolute_error: 0.1770\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.02683\n",
      "Epoch 234/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.1924 - val_mean_absolute_error: 0.1924\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.02683\n",
      "Epoch 235/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1902 - val_mean_absolute_error: 0.1902\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.02683\n",
      "Epoch 236/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.2006 - val_mean_absolute_error: 0.2006\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.02683\n",
      "Epoch 237/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1987 - val_mean_absolute_error: 0.1987\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.02683\n",
      "Epoch 238/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1838 - val_mean_absolute_error: 0.1838\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.02683\n",
      "Epoch 239/700\n",
      "45/45 [==============================] - 14s 305ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.2122 - val_mean_absolute_error: 0.2122\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.02683\n",
      "Epoch 240/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1778 - val_mean_absolute_error: 0.1778\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.02683\n",
      "Epoch 241/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1849 - val_mean_absolute_error: 0.1849\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.02683\n",
      "Epoch 242/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1901 - val_mean_absolute_error: 0.1901\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.02683\n",
      "Epoch 243/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1900 - val_mean_absolute_error: 0.1900\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.02683\n",
      "Epoch 244/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1851 - val_mean_absolute_error: 0.1851\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.02683\n",
      "Epoch 245/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.1839 - val_mean_absolute_error: 0.1839\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.02683\n",
      "Epoch 246/700\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1715 - val_mean_absolute_error: 0.1715\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.02683\n",
      "Epoch 247/700\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 0.0071 - mean_absolute_error: 0.0071 - val_loss: 0.1798 - val_mean_absolute_error: 0.1798\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.02683\n",
      "Epoch 248/700\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.1868 - val_mean_absolute_error: 0.1868\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.02683\n",
      "Epoch 249/700\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 0.0069 - mean_absolute_error: 0.0069 - val_loss: 0.1900 - val_mean_absolute_error: 0.1900\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.02683\n",
      "Epoch 250/700\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1906 - val_mean_absolute_error: 0.1906\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.02683\n",
      "Epoch 251/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.1836 - val_mean_absolute_error: 0.1836\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.02683\n",
      "Epoch 252/700\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.1955 - val_mean_absolute_error: 0.1955\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.02683\n",
      "Epoch 253/700\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1794 - val_mean_absolute_error: 0.1794\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.02683\n",
      "Epoch 254/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1893 - val_mean_absolute_error: 0.1893\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.02683\n",
      "Epoch 255/700\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1906 - val_mean_absolute_error: 0.1906\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.02683\n",
      "Epoch 256/700\n",
      "45/45 [==============================] - 14s 305ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.1822 - val_mean_absolute_error: 0.1822\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.02683\n",
      "Epoch 257/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1919 - val_mean_absolute_error: 0.1919\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.02683\n",
      "Epoch 258/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1891 - val_mean_absolute_error: 0.1891\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.02683\n",
      "Epoch 259/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1952 - val_mean_absolute_error: 0.1952\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.02683\n",
      "Epoch 260/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1877 - val_mean_absolute_error: 0.1877\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.02683\n",
      "Epoch 261/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1893 - val_mean_absolute_error: 0.1893\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.02683\n",
      "Epoch 262/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1983 - val_mean_absolute_error: 0.1983\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.02683\n",
      "Epoch 263/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1973 - val_mean_absolute_error: 0.1973\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.02683\n",
      "Epoch 264/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1987 - val_mean_absolute_error: 0.1987\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.02683\n",
      "Epoch 265/700\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1925 - val_mean_absolute_error: 0.1925\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.02683\n",
      "Epoch 266/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.1965 - val_mean_absolute_error: 0.1965\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.02683\n",
      "Epoch 267/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1894 - val_mean_absolute_error: 0.1894\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.02683\n",
      "Epoch 268/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1841 - val_mean_absolute_error: 0.1841\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.02683\n",
      "Epoch 269/700\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2061 - val_mean_absolute_error: 0.2061\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.02683\n",
      "Epoch 270/700\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2100 - val_mean_absolute_error: 0.2100\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.02683\n",
      "Epoch 271/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2020 - val_mean_absolute_error: 0.2020\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.02683\n",
      "Epoch 272/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.2077 - val_mean_absolute_error: 0.2077\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.02683\n",
      "Epoch 273/700\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1976 - val_mean_absolute_error: 0.1976\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.02683\n",
      "Epoch 274/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.1929 - val_mean_absolute_error: 0.1929\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.02683\n",
      "Epoch 275/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.1911 - val_mean_absolute_error: 0.1911\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.02683\n",
      "Epoch 276/700\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1979 - val_mean_absolute_error: 0.1979\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.02683\n",
      "Epoch 277/700\n",
      "45/45 [==============================] - 13s 297ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.1943 - val_mean_absolute_error: 0.1943\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.02683\n",
      "Epoch 278/700\n",
      "45/45 [==============================] - 13s 291ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.2017 - val_mean_absolute_error: 0.2017\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.02683\n",
      "Epoch 279/700\n",
      "45/45 [==============================] - 13s 298ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2004 - val_mean_absolute_error: 0.2004\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.02683\n",
      "Epoch 280/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.2043 - val_mean_absolute_error: 0.2043\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.02683\n",
      "Epoch 281/700\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.1887 - val_mean_absolute_error: 0.1887\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.02683\n",
      "Epoch 282/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2032 - val_mean_absolute_error: 0.2032\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.02683\n",
      "Epoch 283/700\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.1911 - val_mean_absolute_error: 0.1911\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.02683\n",
      "Epoch 284/700\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2073 - val_mean_absolute_error: 0.2073\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.02683\n",
      "Epoch 285/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.2005 - val_mean_absolute_error: 0.2005\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.02683\n",
      "Epoch 286/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2057 - val_mean_absolute_error: 0.2057\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.02683\n",
      "Epoch 287/700\n",
      "45/45 [==============================] - 13s 295ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2071 - val_mean_absolute_error: 0.2071\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.02683\n",
      "Epoch 288/700\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1977 - val_mean_absolute_error: 0.1977\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.02683\n",
      "Epoch 289/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.2043 - val_mean_absolute_error: 0.2043\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.02683\n",
      "Epoch 290/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2050 - val_mean_absolute_error: 0.2050\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.02683\n",
      "Epoch 291/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2175 - val_mean_absolute_error: 0.2175\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.02683\n",
      "Epoch 292/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2114 - val_mean_absolute_error: 0.2114\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.02683\n",
      "Epoch 293/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2175 - val_mean_absolute_error: 0.2175\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.02683\n",
      "Epoch 294/700\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2018 - val_mean_absolute_error: 0.2018\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.02683\n",
      "Epoch 295/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.1935 - val_mean_absolute_error: 0.1935\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.02683\n",
      "Epoch 296/700\n",
      "45/45 [==============================] - 13s 295ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2159 - val_mean_absolute_error: 0.2159\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.02683\n",
      "Epoch 297/700\n",
      "45/45 [==============================] - 14s 303ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2094 - val_mean_absolute_error: 0.2094\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.02683\n",
      "Epoch 298/700\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2135 - val_mean_absolute_error: 0.2135\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.02683\n",
      "Epoch 299/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.2082 - val_mean_absolute_error: 0.2082\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.02683\n",
      "Epoch 300/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.1986 - val_mean_absolute_error: 0.1986\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.02683\n",
      "Epoch 301/700\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.2127 - val_mean_absolute_error: 0.2127\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.02683\n",
      "Epoch 302/700\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2171 - val_mean_absolute_error: 0.2171\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.02683\n",
      "Epoch 303/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2165 - val_mean_absolute_error: 0.2165\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.02683\n",
      "Epoch 304/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2186 - val_mean_absolute_error: 0.2186\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.02683\n",
      "Epoch 305/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2099 - val_mean_absolute_error: 0.2099\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.02683\n",
      "Epoch 306/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2129 - val_mean_absolute_error: 0.2129\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.02683\n",
      "Epoch 307/700\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2206 - val_mean_absolute_error: 0.2206\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.02683\n",
      "Epoch 308/700\n",
      "45/45 [==============================] - 13s 300ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2221 - val_mean_absolute_error: 0.2221\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.02683\n",
      "Epoch 309/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2102 - val_mean_absolute_error: 0.2102\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.02683\n",
      "Epoch 310/700\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2042 - val_mean_absolute_error: 0.2042\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.02683\n",
      "Epoch 311/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2179 - val_mean_absolute_error: 0.2179\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.02683\n",
      "Epoch 312/700\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2107 - val_mean_absolute_error: 0.2107\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.02683\n",
      "Epoch 313/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2095 - val_mean_absolute_error: 0.2095\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.02683\n",
      "Epoch 314/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2080 - val_mean_absolute_error: 0.2080\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.02683\n",
      "Epoch 315/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2068 - val_mean_absolute_error: 0.2068\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.02683\n",
      "Epoch 316/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2138 - val_mean_absolute_error: 0.2138\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.02683\n",
      "Epoch 317/700\n",
      "45/45 [==============================] - 14s 303ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2112 - val_mean_absolute_error: 0.2112\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.02683\n",
      "Epoch 318/700\n",
      "45/45 [==============================] - 14s 303ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2209 - val_mean_absolute_error: 0.2209\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.02683\n",
      "Epoch 319/700\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2219 - val_mean_absolute_error: 0.2219\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.02683\n",
      "Epoch 320/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2282 - val_mean_absolute_error: 0.2282\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.02683\n",
      "Epoch 321/700\n",
      "45/45 [==============================] - 14s 303ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2220 - val_mean_absolute_error: 0.2220\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.02683\n",
      "Epoch 322/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2140 - val_mean_absolute_error: 0.2140\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.02683\n",
      "Epoch 323/700\n",
      "45/45 [==============================] - 14s 323ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 0.2171 - val_mean_absolute_error: 0.2171\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.02683\n",
      "Epoch 324/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.1997 - val_mean_absolute_error: 0.1997\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.02683\n",
      "Epoch 325/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2206 - val_mean_absolute_error: 0.2206\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.02683\n",
      "Epoch 326/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2133 - val_mean_absolute_error: 0.2133\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.02683\n",
      "Epoch 327/700\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2148 - val_mean_absolute_error: 0.2148\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.02683\n",
      "Epoch 328/700\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2232 - val_mean_absolute_error: 0.2232\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.02683\n",
      "Epoch 329/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2220 - val_mean_absolute_error: 0.2220\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.02683\n",
      "Epoch 330/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2127 - val_mean_absolute_error: 0.2127\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.02683\n",
      "Epoch 331/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2094 - val_mean_absolute_error: 0.2094\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.02683\n",
      "Epoch 332/700\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2045 - val_mean_absolute_error: 0.2045\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.02683\n",
      "Epoch 333/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.2102 - val_mean_absolute_error: 0.2102\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.02683\n",
      "Epoch 334/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2156 - val_mean_absolute_error: 0.2156\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.02683\n",
      "Epoch 335/700\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2276 - val_mean_absolute_error: 0.2276\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.02683\n",
      "Epoch 336/700\n",
      "45/45 [==============================] - 13s 298ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2047 - val_mean_absolute_error: 0.2047\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.02683\n",
      "Epoch 337/700\n",
      "45/45 [==============================] - 13s 297ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2199 - val_mean_absolute_error: 0.2199\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.02683\n",
      "Epoch 338/700\n",
      "45/45 [==============================] - 13s 292ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2150 - val_mean_absolute_error: 0.2150\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.02683\n",
      "Epoch 339/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2163 - val_mean_absolute_error: 0.2163\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.02683\n",
      "Epoch 340/700\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2292 - val_mean_absolute_error: 0.2292\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.02683\n",
      "Epoch 341/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2378 - val_mean_absolute_error: 0.2378\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.02683\n",
      "Epoch 342/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2213 - val_mean_absolute_error: 0.2213\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.02683\n",
      "Epoch 343/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2381 - val_mean_absolute_error: 0.2381\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.02683\n",
      "Epoch 344/700\n",
      "45/45 [==============================] - 13s 299ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2231 - val_mean_absolute_error: 0.2231\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.02683\n",
      "Epoch 345/700\n",
      "45/45 [==============================] - 16s 352ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.2249 - val_mean_absolute_error: 0.2249\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.02683\n",
      "Epoch 346/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2273 - val_mean_absolute_error: 0.2273\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.02683\n",
      "Epoch 347/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2289 - val_mean_absolute_error: 0.2289\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.02683\n",
      "Epoch 348/700\n",
      "45/45 [==============================] - 15s 344ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2455 - val_mean_absolute_error: 0.2455\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.02683\n",
      "Epoch 349/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2240 - val_mean_absolute_error: 0.2240\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.02683\n",
      "Epoch 350/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2309 - val_mean_absolute_error: 0.2309\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.02683\n",
      "Epoch 351/700\n",
      "45/45 [==============================] - 16s 346ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2407 - val_mean_absolute_error: 0.2407\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.02683\n",
      "Epoch 352/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2354 - val_mean_absolute_error: 0.2354\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.02683\n",
      "Epoch 353/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2288 - val_mean_absolute_error: 0.2288\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.02683\n",
      "Epoch 354/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2308 - val_mean_absolute_error: 0.2308\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.02683\n",
      "Epoch 355/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2267 - val_mean_absolute_error: 0.2267\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.02683\n",
      "Epoch 356/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2341 - val_mean_absolute_error: 0.2341\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.02683\n",
      "Epoch 357/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2339 - val_mean_absolute_error: 0.2339\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.02683\n",
      "Epoch 358/700\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2359 - val_mean_absolute_error: 0.2359\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.02683\n",
      "Epoch 359/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2310 - val_mean_absolute_error: 0.2310\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.02683\n",
      "Epoch 360/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2303 - val_mean_absolute_error: 0.2303\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.02683\n",
      "Epoch 361/700\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2343 - val_mean_absolute_error: 0.2343\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.02683\n",
      "Epoch 362/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2365 - val_mean_absolute_error: 0.2365\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.02683\n",
      "Epoch 363/700\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2330 - val_mean_absolute_error: 0.2330\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.02683\n",
      "Epoch 364/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2520 - val_mean_absolute_error: 0.2520\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.02683\n",
      "Epoch 365/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2347 - val_mean_absolute_error: 0.2347\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.02683\n",
      "Epoch 366/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2501 - val_mean_absolute_error: 0.2501\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.02683\n",
      "Epoch 367/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2477 - val_mean_absolute_error: 0.2477\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.02683\n",
      "Epoch 368/700\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2624 - val_mean_absolute_error: 0.2624\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.02683\n",
      "Epoch 369/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2436 - val_mean_absolute_error: 0.2436\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.02683\n",
      "Epoch 370/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2487 - val_mean_absolute_error: 0.2487\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.02683\n",
      "Epoch 371/700\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2327 - val_mean_absolute_error: 0.2327\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.02683\n",
      "Epoch 372/700\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2428 - val_mean_absolute_error: 0.2428\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.02683\n",
      "Epoch 373/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2379 - val_mean_absolute_error: 0.2379\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.02683\n",
      "Epoch 374/700\n",
      "45/45 [==============================] - 16s 347ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2357 - val_mean_absolute_error: 0.2357\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.02683\n",
      "Epoch 375/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2417 - val_mean_absolute_error: 0.2417\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.02683\n",
      "Epoch 376/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.2335 - val_mean_absolute_error: 0.2335\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.02683\n",
      "Epoch 377/700\n",
      "45/45 [==============================] - 16s 349ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2396 - val_mean_absolute_error: 0.2396\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.02683\n",
      "Epoch 378/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2442 - val_mean_absolute_error: 0.2442\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.02683\n",
      "Epoch 379/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2494 - val_mean_absolute_error: 0.2494\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.02683\n",
      "Epoch 380/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2431 - val_mean_absolute_error: 0.2431\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.02683\n",
      "Epoch 381/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2423 - val_mean_absolute_error: 0.2423\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.02683\n",
      "Epoch 382/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0068 - mean_absolute_error: 0.0068 - val_loss: 0.2388 - val_mean_absolute_error: 0.2388\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.02683\n",
      "Epoch 383/700\n",
      "45/45 [==============================] - 16s 347ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2504 - val_mean_absolute_error: 0.2504\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.02683\n",
      "Epoch 384/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2495 - val_mean_absolute_error: 0.2495\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.02683\n",
      "Epoch 385/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2649 - val_mean_absolute_error: 0.2649\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.02683\n",
      "Epoch 386/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2515 - val_mean_absolute_error: 0.2515\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.02683\n",
      "Epoch 387/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2412 - val_mean_absolute_error: 0.2412\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.02683\n",
      "Epoch 388/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2266 - val_mean_absolute_error: 0.2266\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.02683\n",
      "Epoch 389/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 0.2415 - val_mean_absolute_error: 0.2415\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.02683\n",
      "Epoch 390/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2331 - val_mean_absolute_error: 0.2331\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.02683\n",
      "Epoch 391/700\n",
      "45/45 [==============================] - 16s 358ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2455 - val_mean_absolute_error: 0.2455\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.02683\n",
      "Epoch 392/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2519 - val_mean_absolute_error: 0.2519\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.02683\n",
      "Epoch 393/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2565 - val_mean_absolute_error: 0.2565\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.02683\n",
      "Epoch 394/700\n",
      "45/45 [==============================] - 15s 343ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2587 - val_mean_absolute_error: 0.2587\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.02683\n",
      "Epoch 395/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2543 - val_mean_absolute_error: 0.2543\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.02683\n",
      "Epoch 396/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2498 - val_mean_absolute_error: 0.2498\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.02683\n",
      "Epoch 397/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2442 - val_mean_absolute_error: 0.2442\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.02683\n",
      "Epoch 398/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2440 - val_mean_absolute_error: 0.2440\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.02683\n",
      "Epoch 399/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2528 - val_mean_absolute_error: 0.2528\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.02683\n",
      "Epoch 400/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2484 - val_mean_absolute_error: 0.2484\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.02683\n",
      "Epoch 401/700\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2580 - val_mean_absolute_error: 0.2580\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.02683\n",
      "Epoch 402/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2518 - val_mean_absolute_error: 0.2518\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.02683\n",
      "Epoch 403/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2394 - val_mean_absolute_error: 0.2394\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.02683\n",
      "Epoch 404/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2538 - val_mean_absolute_error: 0.2538\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.02683\n",
      "Epoch 405/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2473 - val_mean_absolute_error: 0.2473\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.02683\n",
      "Epoch 406/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2442 - val_mean_absolute_error: 0.2442\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.02683\n",
      "Epoch 407/700\n",
      "45/45 [==============================] - 15s 339ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2466 - val_mean_absolute_error: 0.2466\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.02683\n",
      "Epoch 408/700\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2523 - val_mean_absolute_error: 0.2523\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.02683\n",
      "Epoch 409/700\n",
      "45/45 [==============================] - 15s 335ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2629 - val_mean_absolute_error: 0.2629\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.02683\n",
      "Epoch 410/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2544 - val_mean_absolute_error: 0.2544\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.02683\n",
      "Epoch 411/700\n",
      "45/45 [==============================] - 15s 341ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2569 - val_mean_absolute_error: 0.2569\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.02683\n",
      "Epoch 412/700\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2450 - val_mean_absolute_error: 0.2450\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.02683\n",
      "Epoch 413/700\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2574 - val_mean_absolute_error: 0.2574\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.02683\n",
      "Epoch 414/700\n",
      "45/45 [==============================] - 16s 349ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2439 - val_mean_absolute_error: 0.2439\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.02683\n",
      "Epoch 415/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2553 - val_mean_absolute_error: 0.2553\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.02683\n",
      "Epoch 416/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2620 - val_mean_absolute_error: 0.2620\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.02683\n",
      "Epoch 417/700\n",
      "45/45 [==============================] - 16s 347ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2580 - val_mean_absolute_error: 0.2580\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.02683\n",
      "Epoch 418/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2613 - val_mean_absolute_error: 0.2613\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.02683\n",
      "Epoch 419/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2672 - val_mean_absolute_error: 0.2672\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.02683\n",
      "Epoch 420/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2576 - val_mean_absolute_error: 0.2576\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.02683\n",
      "Epoch 421/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2571 - val_mean_absolute_error: 0.2571\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.02683\n",
      "Epoch 422/700\n",
      "45/45 [==============================] - 16s 346ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2514 - val_mean_absolute_error: 0.2514\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.02683\n",
      "Epoch 423/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2504 - val_mean_absolute_error: 0.2504\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.02683\n",
      "Epoch 424/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.02683\n",
      "Epoch 425/700\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2517 - val_mean_absolute_error: 0.2517\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.02683\n",
      "Epoch 426/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2569 - val_mean_absolute_error: 0.2569\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.02683\n",
      "Epoch 427/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2613 - val_mean_absolute_error: 0.2613\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.02683\n",
      "Epoch 428/700\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2418 - val_mean_absolute_error: 0.2418\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.02683\n",
      "Epoch 429/700\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2601 - val_mean_absolute_error: 0.2601\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.02683\n",
      "Epoch 430/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2643 - val_mean_absolute_error: 0.2643\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.02683\n",
      "Epoch 431/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2602 - val_mean_absolute_error: 0.2602\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.02683\n",
      "Epoch 432/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2588 - val_mean_absolute_error: 0.2588\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.02683\n",
      "Epoch 433/700\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2493 - val_mean_absolute_error: 0.2493\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.02683\n",
      "Epoch 434/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2524 - val_mean_absolute_error: 0.2524\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.02683\n",
      "Epoch 435/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2575 - val_mean_absolute_error: 0.2575\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.02683\n",
      "Epoch 436/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2555 - val_mean_absolute_error: 0.2555\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.02683\n",
      "Epoch 437/700\n",
      "45/45 [==============================] - 14s 323ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2718 - val_mean_absolute_error: 0.2718\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.02683\n",
      "Epoch 438/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2639 - val_mean_absolute_error: 0.2639\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.02683\n",
      "Epoch 439/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2641 - val_mean_absolute_error: 0.2641\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.02683\n",
      "Epoch 440/700\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2695 - val_mean_absolute_error: 0.2695\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.02683\n",
      "Epoch 441/700\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2460 - val_mean_absolute_error: 0.2460\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.02683\n",
      "Epoch 442/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2541 - val_mean_absolute_error: 0.2541\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.02683\n",
      "Epoch 443/700\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2572 - val_mean_absolute_error: 0.2572\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.02683\n",
      "Epoch 444/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2492 - val_mean_absolute_error: 0.2492\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.02683\n",
      "Epoch 445/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2576 - val_mean_absolute_error: 0.2576\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.02683\n",
      "Epoch 446/700\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2583 - val_mean_absolute_error: 0.2583\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.02683\n",
      "Epoch 447/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2544 - val_mean_absolute_error: 0.2544\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.02683\n",
      "Epoch 448/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2622 - val_mean_absolute_error: 0.2622\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.02683\n",
      "Epoch 449/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2386 - val_mean_absolute_error: 0.2386\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.02683\n",
      "Epoch 450/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 0.2483 - val_mean_absolute_error: 0.2483\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.02683\n",
      "Epoch 451/700\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2468 - val_mean_absolute_error: 0.2468\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.02683\n",
      "Epoch 452/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2517 - val_mean_absolute_error: 0.2517\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.02683\n",
      "Epoch 453/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2606 - val_mean_absolute_error: 0.2606\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.02683\n",
      "Epoch 454/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2535 - val_mean_absolute_error: 0.2535\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.02683\n",
      "Epoch 455/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2470 - val_mean_absolute_error: 0.2470\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.02683\n",
      "Epoch 456/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2448 - val_mean_absolute_error: 0.2448\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.02683\n",
      "Epoch 457/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2653 - val_mean_absolute_error: 0.2653\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.02683\n",
      "Epoch 458/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2517 - val_mean_absolute_error: 0.2517\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.02683\n",
      "Epoch 459/700\n",
      "45/45 [==============================] - 14s 305ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2562 - val_mean_absolute_error: 0.2562\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.02683\n",
      "Epoch 460/700\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2534 - val_mean_absolute_error: 0.2534\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.02683\n",
      "Epoch 461/700\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2601 - val_mean_absolute_error: 0.2601\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.02683\n",
      "Epoch 462/700\n",
      "45/45 [==============================] - 14s 323ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2644 - val_mean_absolute_error: 0.2644\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.02683\n",
      "Epoch 463/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2596 - val_mean_absolute_error: 0.2596\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.02683\n",
      "Epoch 464/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2566 - val_mean_absolute_error: 0.2566\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.02683\n",
      "Epoch 465/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2647 - val_mean_absolute_error: 0.2647\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.02683\n",
      "Epoch 466/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2607 - val_mean_absolute_error: 0.2607\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.02683\n",
      "Epoch 467/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2624 - val_mean_absolute_error: 0.2624\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.02683\n",
      "Epoch 468/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2651 - val_mean_absolute_error: 0.2651\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.02683\n",
      "Epoch 469/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2605 - val_mean_absolute_error: 0.2605\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.02683\n",
      "Epoch 470/700\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2592 - val_mean_absolute_error: 0.2592\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.02683\n",
      "Epoch 471/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2671 - val_mean_absolute_error: 0.2671\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.02683\n",
      "Epoch 472/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2627 - val_mean_absolute_error: 0.2627\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.02683\n",
      "Epoch 473/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2636 - val_mean_absolute_error: 0.2636\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.02683\n",
      "Epoch 474/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2711 - val_mean_absolute_error: 0.2711\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.02683\n",
      "Epoch 475/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2726 - val_mean_absolute_error: 0.2726\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.02683\n",
      "Epoch 476/700\n",
      "45/45 [==============================] - 13s 298ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2551 - val_mean_absolute_error: 0.2551\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.02683\n",
      "Epoch 477/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2576 - val_mean_absolute_error: 0.2576\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.02683\n",
      "Epoch 478/700\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2452 - val_mean_absolute_error: 0.2452\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.02683\n",
      "Epoch 479/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2442 - val_mean_absolute_error: 0.2442\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.02683\n",
      "Epoch 480/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2621 - val_mean_absolute_error: 0.2621\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.02683\n",
      "Epoch 481/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2668 - val_mean_absolute_error: 0.2668\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.02683\n",
      "Epoch 482/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2621 - val_mean_absolute_error: 0.2621\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.02683\n",
      "Epoch 483/700\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2706 - val_mean_absolute_error: 0.2706\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.02683\n",
      "Epoch 484/700\n",
      "45/45 [==============================] - 14s 303ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2731 - val_mean_absolute_error: 0.2731\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.02683\n",
      "Epoch 485/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2672 - val_mean_absolute_error: 0.2672\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.02683\n",
      "Epoch 486/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2628 - val_mean_absolute_error: 0.2628\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.02683\n",
      "Epoch 487/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2558 - val_mean_absolute_error: 0.2558\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.02683\n",
      "Epoch 488/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2567 - val_mean_absolute_error: 0.2567\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.02683\n",
      "Epoch 489/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2618 - val_mean_absolute_error: 0.2618\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.02683\n",
      "Epoch 490/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2657 - val_mean_absolute_error: 0.2657\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.02683\n",
      "Epoch 491/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2620 - val_mean_absolute_error: 0.2620\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.02683\n",
      "Epoch 492/700\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2700 - val_mean_absolute_error: 0.2700\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.02683\n",
      "Epoch 493/700\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2587 - val_mean_absolute_error: 0.2587\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.02683\n",
      "Epoch 494/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2506 - val_mean_absolute_error: 0.2506\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.02683\n",
      "Epoch 495/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2674 - val_mean_absolute_error: 0.2674\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.02683\n",
      "Epoch 496/700\n",
      "45/45 [==============================] - 15s 335ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2602 - val_mean_absolute_error: 0.2602\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.02683\n",
      "Epoch 497/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2698 - val_mean_absolute_error: 0.2698\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.02683\n",
      "Epoch 498/700\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2636 - val_mean_absolute_error: 0.2636\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.02683\n",
      "Epoch 499/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2621 - val_mean_absolute_error: 0.2621\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.02683\n",
      "Epoch 500/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2450 - val_mean_absolute_error: 0.2450\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.02683\n",
      "Epoch 501/700\n",
      "45/45 [==============================] - 13s 289ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2638 - val_mean_absolute_error: 0.2638\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.02683\n",
      "Epoch 502/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2670 - val_mean_absolute_error: 0.2670\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.02683\n",
      "Epoch 503/700\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2485 - val_mean_absolute_error: 0.2485\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.02683\n",
      "Epoch 504/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2572 - val_mean_absolute_error: 0.2572\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.02683\n",
      "Epoch 505/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2589 - val_mean_absolute_error: 0.2589\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.02683\n",
      "Epoch 506/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2728 - val_mean_absolute_error: 0.2728\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.02683\n",
      "Epoch 507/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2680 - val_mean_absolute_error: 0.2680\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.02683\n",
      "Epoch 508/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2608 - val_mean_absolute_error: 0.2608\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.02683\n",
      "Epoch 509/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2572 - val_mean_absolute_error: 0.2572\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.02683\n",
      "Epoch 510/700\n",
      "45/45 [==============================] - 14s 303ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2467 - val_mean_absolute_error: 0.2467\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.02683\n",
      "Epoch 511/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2606 - val_mean_absolute_error: 0.2606\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.02683\n",
      "Epoch 512/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2604 - val_mean_absolute_error: 0.2604\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.02683\n",
      "Epoch 513/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2733 - val_mean_absolute_error: 0.2733\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.02683\n",
      "Epoch 514/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2676 - val_mean_absolute_error: 0.2676\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.02683\n",
      "Epoch 515/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2652 - val_mean_absolute_error: 0.2652\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.02683\n",
      "Epoch 516/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2679 - val_mean_absolute_error: 0.2679\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.02683\n",
      "Epoch 517/700\n",
      "45/45 [==============================] - 15s 340ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2703 - val_mean_absolute_error: 0.2703\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.02683\n",
      "Epoch 518/700\n",
      "45/45 [==============================] - 14s 301ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2687 - val_mean_absolute_error: 0.2687\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.02683\n",
      "Epoch 519/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2679 - val_mean_absolute_error: 0.2679\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.02683\n",
      "Epoch 520/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2661 - val_mean_absolute_error: 0.2661\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.02683\n",
      "Epoch 521/700\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2742 - val_mean_absolute_error: 0.2742\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.02683\n",
      "Epoch 522/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2743 - val_mean_absolute_error: 0.2743\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.02683\n",
      "Epoch 523/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2666 - val_mean_absolute_error: 0.2666\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.02683\n",
      "Epoch 524/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2746 - val_mean_absolute_error: 0.2746\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.02683\n",
      "Epoch 525/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2676 - val_mean_absolute_error: 0.2676\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.02683\n",
      "Epoch 526/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 0.2724 - val_mean_absolute_error: 0.2724\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.02683\n",
      "Epoch 527/700\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2687 - val_mean_absolute_error: 0.2687\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.02683\n",
      "Epoch 528/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2627 - val_mean_absolute_error: 0.2627\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.02683\n",
      "Epoch 529/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2689 - val_mean_absolute_error: 0.2689\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.02683\n",
      "Epoch 530/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2754 - val_mean_absolute_error: 0.2754\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.02683\n",
      "Epoch 531/700\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2713 - val_mean_absolute_error: 0.2713\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.02683\n",
      "Epoch 532/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2724 - val_mean_absolute_error: 0.2724\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.02683\n",
      "Epoch 533/700\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2588 - val_mean_absolute_error: 0.2588\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.02683\n",
      "Epoch 534/700\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2638 - val_mean_absolute_error: 0.2638\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.02683\n",
      "Epoch 535/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2662 - val_mean_absolute_error: 0.2662\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.02683\n",
      "Epoch 536/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2556 - val_mean_absolute_error: 0.2556\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.02683\n",
      "Epoch 537/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2681 - val_mean_absolute_error: 0.2681\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.02683\n",
      "Epoch 538/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2656 - val_mean_absolute_error: 0.2656\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.02683\n",
      "Epoch 539/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2661 - val_mean_absolute_error: 0.2661\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.02683\n",
      "Epoch 540/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2647 - val_mean_absolute_error: 0.2647\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.02683\n",
      "Epoch 541/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2790 - val_mean_absolute_error: 0.2790\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.02683\n",
      "Epoch 542/700\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2678 - val_mean_absolute_error: 0.2678\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.02683\n",
      "Epoch 543/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2657 - val_mean_absolute_error: 0.2657\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.02683\n",
      "Epoch 544/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2610 - val_mean_absolute_error: 0.2610\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.02683\n",
      "Epoch 545/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2755 - val_mean_absolute_error: 0.2755\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.02683\n",
      "Epoch 546/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2673 - val_mean_absolute_error: 0.2673\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.02683\n",
      "Epoch 547/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2823 - val_mean_absolute_error: 0.2823\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.02683\n",
      "Epoch 548/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2756 - val_mean_absolute_error: 0.2756\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.02683\n",
      "Epoch 549/700\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2769 - val_mean_absolute_error: 0.2769\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.02683\n",
      "Epoch 550/700\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2732 - val_mean_absolute_error: 0.2732\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.02683\n",
      "Epoch 551/700\n",
      "45/45 [==============================] - 13s 294ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2710 - val_mean_absolute_error: 0.2710\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.02683\n",
      "Epoch 552/700\n",
      "45/45 [==============================] - 14s 303ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2662 - val_mean_absolute_error: 0.2662\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.02683\n",
      "Epoch 553/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2754 - val_mean_absolute_error: 0.2754\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.02683\n",
      "Epoch 554/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2684 - val_mean_absolute_error: 0.2684\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.02683\n",
      "Epoch 555/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2730 - val_mean_absolute_error: 0.2730\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.02683\n",
      "Epoch 556/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2636 - val_mean_absolute_error: 0.2636\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.02683\n",
      "Epoch 557/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2782 - val_mean_absolute_error: 0.2782\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.02683\n",
      "Epoch 558/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2763 - val_mean_absolute_error: 0.2763\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.02683\n",
      "Epoch 559/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2712 - val_mean_absolute_error: 0.2712\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.02683\n",
      "Epoch 560/700\n",
      "45/45 [==============================] - 13s 294ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2568 - val_mean_absolute_error: 0.2568\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.02683\n",
      "Epoch 561/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2734 - val_mean_absolute_error: 0.2734\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.02683\n",
      "Epoch 562/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2685 - val_mean_absolute_error: 0.2685\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.02683\n",
      "Epoch 563/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2737 - val_mean_absolute_error: 0.2737\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.02683\n",
      "Epoch 564/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2697 - val_mean_absolute_error: 0.2697\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.02683\n",
      "Epoch 565/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 0.2844 - val_mean_absolute_error: 0.2844\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.02683\n",
      "Epoch 566/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2780 - val_mean_absolute_error: 0.2780\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.02683\n",
      "Epoch 567/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2720 - val_mean_absolute_error: 0.2720\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.02683\n",
      "Epoch 568/700\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2626 - val_mean_absolute_error: 0.2626\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.02683\n",
      "Epoch 569/700\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2761 - val_mean_absolute_error: 0.2761\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.02683\n",
      "Epoch 570/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2735 - val_mean_absolute_error: 0.2735\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.02683\n",
      "Epoch 571/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2692 - val_mean_absolute_error: 0.2692\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.02683\n",
      "Epoch 572/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2664 - val_mean_absolute_error: 0.2664\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.02683\n",
      "Epoch 573/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2809 - val_mean_absolute_error: 0.2809\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.02683\n",
      "Epoch 574/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2725 - val_mean_absolute_error: 0.2725\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.02683\n",
      "Epoch 575/700\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2753 - val_mean_absolute_error: 0.2753\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.02683\n",
      "Epoch 576/700\n",
      "45/45 [==============================] - 14s 299ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2839 - val_mean_absolute_error: 0.2839\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.02683\n",
      "Epoch 577/700\n",
      "45/45 [==============================] - 13s 297ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2708 - val_mean_absolute_error: 0.2708\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.02683\n",
      "Epoch 578/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2737 - val_mean_absolute_error: 0.2737\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.02683\n",
      "Epoch 579/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2693 - val_mean_absolute_error: 0.2693\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.02683\n",
      "Epoch 580/700\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2743 - val_mean_absolute_error: 0.2743\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.02683\n",
      "Epoch 581/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2755 - val_mean_absolute_error: 0.2755\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.02683\n",
      "Epoch 582/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2660 - val_mean_absolute_error: 0.2660\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.02683\n",
      "Epoch 583/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2837 - val_mean_absolute_error: 0.2837\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.02683\n",
      "Epoch 584/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2770 - val_mean_absolute_error: 0.2770\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.02683\n",
      "Epoch 585/700\n",
      "45/45 [==============================] - 13s 287ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2716 - val_mean_absolute_error: 0.2716\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.02683\n",
      "Epoch 586/700\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2817 - val_mean_absolute_error: 0.2817\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.02683\n",
      "Epoch 587/700\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2816 - val_mean_absolute_error: 0.2816\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.02683\n",
      "Epoch 588/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2826 - val_mean_absolute_error: 0.2826\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.02683\n",
      "Epoch 589/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2776 - val_mean_absolute_error: 0.2776\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.02683\n",
      "Epoch 590/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2888 - val_mean_absolute_error: 0.2888\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.02683\n",
      "Epoch 591/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2765 - val_mean_absolute_error: 0.2765\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.02683\n",
      "Epoch 592/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2725 - val_mean_absolute_error: 0.2725\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.02683\n",
      "Epoch 593/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2678 - val_mean_absolute_error: 0.2678\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.02683\n",
      "Epoch 594/700\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2818 - val_mean_absolute_error: 0.2818\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.02683\n",
      "Epoch 595/700\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2778 - val_mean_absolute_error: 0.2778\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.02683\n",
      "Epoch 596/700\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2778 - val_mean_absolute_error: 0.2778\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.02683\n",
      "Epoch 597/700\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2706 - val_mean_absolute_error: 0.2706\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.02683\n",
      "Epoch 598/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2721 - val_mean_absolute_error: 0.2721\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.02683\n",
      "Epoch 599/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2739 - val_mean_absolute_error: 0.2739\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.02683\n",
      "Epoch 600/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2790 - val_mean_absolute_error: 0.2790\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.02683\n",
      "Epoch 601/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2836 - val_mean_absolute_error: 0.2836\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.02683\n",
      "Epoch 602/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2703 - val_mean_absolute_error: 0.2703\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.02683\n",
      "Epoch 603/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2759 - val_mean_absolute_error: 0.2759\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.02683\n",
      "Epoch 604/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2788 - val_mean_absolute_error: 0.2788\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.02683\n",
      "Epoch 605/700\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.2778 - val_mean_absolute_error: 0.2778\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.02683\n",
      "Epoch 606/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2812 - val_mean_absolute_error: 0.2812\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.02683\n",
      "Epoch 607/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2780 - val_mean_absolute_error: 0.2780\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.02683\n",
      "Epoch 608/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2776 - val_mean_absolute_error: 0.2776\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.02683\n",
      "Epoch 609/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2691 - val_mean_absolute_error: 0.2691\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.02683\n",
      "Epoch 610/700\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2653 - val_mean_absolute_error: 0.2653\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.02683\n",
      "Epoch 611/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2834 - val_mean_absolute_error: 0.2834\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.02683\n",
      "Epoch 612/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2634 - val_mean_absolute_error: 0.2634\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.02683\n",
      "Epoch 613/700\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 0.0054 - mean_absolute_error: 0.0054 - val_loss: 0.2678 - val_mean_absolute_error: 0.2678\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.02683\n",
      "Epoch 614/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2660 - val_mean_absolute_error: 0.2660\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.02683\n",
      "Epoch 615/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2613 - val_mean_absolute_error: 0.2613\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.02683\n",
      "Epoch 616/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2766 - val_mean_absolute_error: 0.2766\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.02683\n",
      "Epoch 617/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2677 - val_mean_absolute_error: 0.2677\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.02683\n",
      "Epoch 618/700\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2716 - val_mean_absolute_error: 0.2716\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.02683\n",
      "Epoch 619/700\n",
      "45/45 [==============================] - 13s 300ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2607 - val_mean_absolute_error: 0.2607\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.02683\n",
      "Epoch 620/700\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2708 - val_mean_absolute_error: 0.2708\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.02683\n",
      "Epoch 621/700\n",
      "45/45 [==============================] - 14s 323ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2703 - val_mean_absolute_error: 0.2703\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.02683\n",
      "Epoch 622/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2644 - val_mean_absolute_error: 0.2644\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.02683\n",
      "Epoch 623/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2663 - val_mean_absolute_error: 0.2663\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.02683\n",
      "Epoch 624/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2652 - val_mean_absolute_error: 0.2652\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.02683\n",
      "Epoch 625/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2689 - val_mean_absolute_error: 0.2689\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.02683\n",
      "Epoch 626/700\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2709 - val_mean_absolute_error: 0.2709\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.02683\n",
      "Epoch 627/700\n",
      "45/45 [==============================] - 13s 290ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2816 - val_mean_absolute_error: 0.2816\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.02683\n",
      "Epoch 628/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2629 - val_mean_absolute_error: 0.2629\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.02683\n",
      "Epoch 629/700\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2593 - val_mean_absolute_error: 0.2593\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.02683\n",
      "Epoch 630/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2683 - val_mean_absolute_error: 0.2683\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.02683\n",
      "Epoch 631/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2606 - val_mean_absolute_error: 0.2606\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.02683\n",
      "Epoch 632/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2679 - val_mean_absolute_error: 0.2679\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.02683\n",
      "Epoch 633/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2801 - val_mean_absolute_error: 0.2801\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.02683\n",
      "Epoch 634/700\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2804 - val_mean_absolute_error: 0.2804\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.02683\n",
      "Epoch 635/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2752 - val_mean_absolute_error: 0.2752\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.02683\n",
      "Epoch 636/700\n",
      "45/45 [==============================] - 13s 299ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2776 - val_mean_absolute_error: 0.2776\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.02683\n",
      "Epoch 637/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2663 - val_mean_absolute_error: 0.2663\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.02683\n",
      "Epoch 638/700\n",
      "45/45 [==============================] - 15s 337ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2851 - val_mean_absolute_error: 0.2851\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.02683\n",
      "Epoch 639/700\n",
      "45/45 [==============================] - 16s 348ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2651 - val_mean_absolute_error: 0.2651\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.02683\n",
      "Epoch 640/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2707 - val_mean_absolute_error: 0.2707\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.02683\n",
      "Epoch 641/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2887 - val_mean_absolute_error: 0.2887\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.02683\n",
      "Epoch 642/700\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2834 - val_mean_absolute_error: 0.2834\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.02683\n",
      "Epoch 643/700\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2744 - val_mean_absolute_error: 0.2744\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.02683\n",
      "Epoch 644/700\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2869 - val_mean_absolute_error: 0.2869\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.02683\n",
      "Epoch 645/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.2820 - val_mean_absolute_error: 0.2820\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.02683\n",
      "Epoch 646/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2794 - val_mean_absolute_error: 0.2794\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.02683\n",
      "Epoch 647/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2852 - val_mean_absolute_error: 0.2852\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.02683\n",
      "Epoch 648/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2849 - val_mean_absolute_error: 0.2849\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.02683\n",
      "Epoch 649/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2762 - val_mean_absolute_error: 0.2762\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.02683\n",
      "Epoch 650/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2838 - val_mean_absolute_error: 0.2838\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.02683\n",
      "Epoch 651/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2993 - val_mean_absolute_error: 0.2993\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.02683\n",
      "Epoch 652/700\n",
      "45/45 [==============================] - 13s 292ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.2613 - val_mean_absolute_error: 0.2613\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.02683\n",
      "Epoch 653/700\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.2638 - val_mean_absolute_error: 0.2638\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.02683\n",
      "Epoch 654/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2472 - val_mean_absolute_error: 0.2472\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.02683\n",
      "Epoch 655/700\n",
      "45/45 [==============================] - 15s 334ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 0.2536 - val_mean_absolute_error: 0.2536\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.02683\n",
      "Epoch 656/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2647 - val_mean_absolute_error: 0.2647\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.02683\n",
      "Epoch 657/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2716 - val_mean_absolute_error: 0.2716\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.02683\n",
      "Epoch 658/700\n",
      "45/45 [==============================] - 14s 323ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2640 - val_mean_absolute_error: 0.2640\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.02683\n",
      "Epoch 659/700\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.2833 - val_mean_absolute_error: 0.2833\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.02683\n",
      "Epoch 660/700\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2698 - val_mean_absolute_error: 0.2698\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.02683\n",
      "Epoch 661/700\n",
      "45/45 [==============================] - 13s 298ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2735 - val_mean_absolute_error: 0.2735\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.02683\n",
      "Epoch 662/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2757 - val_mean_absolute_error: 0.2757\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.02683\n",
      "Epoch 663/700\n",
      "45/45 [==============================] - 15s 338ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2741 - val_mean_absolute_error: 0.2741\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.02683\n",
      "Epoch 664/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2697 - val_mean_absolute_error: 0.2697\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.02683\n",
      "Epoch 665/700\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2818 - val_mean_absolute_error: 0.2818\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.02683\n",
      "Epoch 666/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2708 - val_mean_absolute_error: 0.2708\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.02683\n",
      "Epoch 667/700\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2643 - val_mean_absolute_error: 0.2643\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.02683\n",
      "Epoch 668/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2723 - val_mean_absolute_error: 0.2723\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.02683\n",
      "Epoch 669/700\n",
      "45/45 [==============================] - 13s 295ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2719 - val_mean_absolute_error: 0.2719\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.02683\n",
      "Epoch 670/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2641 - val_mean_absolute_error: 0.2641\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.02683\n",
      "Epoch 671/700\n",
      "45/45 [==============================] - 15s 335ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2520 - val_mean_absolute_error: 0.2520\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.02683\n",
      "Epoch 672/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2649 - val_mean_absolute_error: 0.2649\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.02683\n",
      "Epoch 673/700\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2715 - val_mean_absolute_error: 0.2715\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.02683\n",
      "Epoch 674/700\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 0.2685 - val_mean_absolute_error: 0.2685\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.02683\n",
      "Epoch 675/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2694 - val_mean_absolute_error: 0.2694\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.02683\n",
      "Epoch 676/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2700 - val_mean_absolute_error: 0.2700\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.02683\n",
      "Epoch 677/700\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2703 - val_mean_absolute_error: 0.2703\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.02683\n",
      "Epoch 678/700\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.2646 - val_mean_absolute_error: 0.2646\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.02683\n",
      "Epoch 679/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2711 - val_mean_absolute_error: 0.2711\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.02683\n",
      "Epoch 680/700\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2640 - val_mean_absolute_error: 0.2640\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.02683\n",
      "Epoch 681/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2700 - val_mean_absolute_error: 0.2700\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.02683\n",
      "Epoch 682/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2672 - val_mean_absolute_error: 0.2672\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.02683\n",
      "Epoch 683/700\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2633 - val_mean_absolute_error: 0.2633\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.02683\n",
      "Epoch 684/700\n",
      "45/45 [==============================] - 15s 335ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2740 - val_mean_absolute_error: 0.2740\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.02683\n",
      "Epoch 685/700\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2578 - val_mean_absolute_error: 0.2578\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.02683\n",
      "Epoch 686/700\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2653 - val_mean_absolute_error: 0.2653\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.02683\n",
      "Epoch 687/700\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.2637 - val_mean_absolute_error: 0.2637\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.02683\n",
      "Epoch 688/700\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2665 - val_mean_absolute_error: 0.2665\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.02683\n",
      "Epoch 689/700\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2678 - val_mean_absolute_error: 0.2678\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.02683\n",
      "Epoch 690/700\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2668 - val_mean_absolute_error: 0.2668\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.02683\n",
      "Epoch 691/700\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 0.2636 - val_mean_absolute_error: 0.2636\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.02683\n",
      "Epoch 692/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2521 - val_mean_absolute_error: 0.2521\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.02683\n",
      "Epoch 693/700\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 0.2647 - val_mean_absolute_error: 0.2647\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.02683\n",
      "Epoch 694/700\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 0.2603 - val_mean_absolute_error: 0.2603\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.02683\n",
      "Epoch 695/700\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 0.0055 - mean_absolute_error: 0.0055 - val_loss: 0.2584 - val_mean_absolute_error: 0.2584\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.02683\n",
      "Epoch 696/700\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2709 - val_mean_absolute_error: 0.2709\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.02683\n",
      "Epoch 697/700\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 0.0056 - mean_absolute_error: 0.0056 - val_loss: 0.2668 - val_mean_absolute_error: 0.2668\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.02683\n",
      "Epoch 698/700\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2754 - val_mean_absolute_error: 0.2754\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.02683\n",
      "Epoch 699/700\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2800 - val_mean_absolute_error: 0.2800\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.02683\n",
      "Epoch 700/700\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 0.2750 - val_mean_absolute_error: 0.2750\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.02683\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Model for import later\n",
    "\n",
    "# Save model as JSON\n",
    "model_1_day = model.to_json()\n",
    "\n",
    "file_path = Path(\"aaplmodel_10day.json\")\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(model_1_day)\n",
    "\n",
    "# Save weights\n",
    "aaplemodel_10day_file_path = (\"aaplmodel_10day.h5\")\n",
    "model.save_weights(\"aaplmodel_10day.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"Adj Close\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"Adj Close\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"Adj Close\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"Adj Close\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"Adj Close\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]# load optimal model weights from results folder\n",
    "    model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "    model.load_weights(model_path)\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"Adj Close\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>adjclose_10</th>\n",
       "      <th>true_adjclose_10</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-05-04</th>\n",
       "      <td>44.562500</td>\n",
       "      <td>46.062500</td>\n",
       "      <td>44.542500</td>\n",
       "      <td>45.957500</td>\n",
       "      <td>44.339626</td>\n",
       "      <td>224805200</td>\n",
       "      <td>42.421425</td>\n",
       "      <td>45.111092</td>\n",
       "      <td>-1.918201</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-07</th>\n",
       "      <td>46.294998</td>\n",
       "      <td>46.917500</td>\n",
       "      <td>46.187500</td>\n",
       "      <td>46.290001</td>\n",
       "      <td>44.660423</td>\n",
       "      <td>169805600</td>\n",
       "      <td>43.278019</td>\n",
       "      <td>45.430706</td>\n",
       "      <td>-1.382404</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-08</th>\n",
       "      <td>46.247501</td>\n",
       "      <td>46.555000</td>\n",
       "      <td>45.917500</td>\n",
       "      <td>46.512501</td>\n",
       "      <td>44.875103</td>\n",
       "      <td>113611200</td>\n",
       "      <td>44.016148</td>\n",
       "      <td>45.316906</td>\n",
       "      <td>-0.858955</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09</th>\n",
       "      <td>46.637501</td>\n",
       "      <td>46.849998</td>\n",
       "      <td>46.305000</td>\n",
       "      <td>46.840000</td>\n",
       "      <td>45.191067</td>\n",
       "      <td>92844800</td>\n",
       "      <td>44.644428</td>\n",
       "      <td>45.607460</td>\n",
       "      <td>-0.546638</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-10</th>\n",
       "      <td>46.935001</td>\n",
       "      <td>47.592499</td>\n",
       "      <td>46.912498</td>\n",
       "      <td>47.509998</td>\n",
       "      <td>45.837475</td>\n",
       "      <td>111957200</td>\n",
       "      <td>45.211708</td>\n",
       "      <td>45.556606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-08</th>\n",
       "      <td>120.930000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>116.209999</td>\n",
       "      <td>116.360001</td>\n",
       "      <td>116.360001</td>\n",
       "      <td>153918600</td>\n",
       "      <td>127.774239</td>\n",
       "      <td>123.389999</td>\n",
       "      <td>11.414238</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <td>119.029999</td>\n",
       "      <td>122.059998</td>\n",
       "      <td>118.790001</td>\n",
       "      <td>121.089996</td>\n",
       "      <td>121.089996</td>\n",
       "      <td>129159600</td>\n",
       "      <td>127.636894</td>\n",
       "      <td>122.540001</td>\n",
       "      <td>6.546898</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-10</th>\n",
       "      <td>121.690002</td>\n",
       "      <td>122.169998</td>\n",
       "      <td>119.449997</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>111760400</td>\n",
       "      <td>127.522675</td>\n",
       "      <td>120.089996</td>\n",
       "      <td>7.542671</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11</th>\n",
       "      <td>122.540001</td>\n",
       "      <td>123.209999</td>\n",
       "      <td>121.260002</td>\n",
       "      <td>121.959999</td>\n",
       "      <td>121.959999</td>\n",
       "      <td>102753600</td>\n",
       "      <td>127.694420</td>\n",
       "      <td>120.589996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.734421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-12</th>\n",
       "      <td>120.400002</td>\n",
       "      <td>121.169998</td>\n",
       "      <td>119.160004</td>\n",
       "      <td>121.029999</td>\n",
       "      <td>121.029999</td>\n",
       "      <td>87963400</td>\n",
       "      <td>127.571632</td>\n",
       "      <td>121.209999</td>\n",
       "      <td>6.541634</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>719 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2018-05-04   44.562500   46.062500   44.542500   45.957500   44.339626   \n",
       "2018-05-07   46.294998   46.917500   46.187500   46.290001   44.660423   \n",
       "2018-05-08   46.247501   46.555000   45.917500   46.512501   44.875103   \n",
       "2018-05-09   46.637501   46.849998   46.305000   46.840000   45.191067   \n",
       "2018-05-10   46.935001   47.592499   46.912498   47.509998   45.837475   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2021-03-08  120.930000  121.000000  116.209999  116.360001  116.360001   \n",
       "2021-03-09  119.029999  122.059998  118.790001  121.089996  121.089996   \n",
       "2021-03-10  121.690002  122.169998  119.449997  119.980003  119.980003   \n",
       "2021-03-11  122.540001  123.209999  121.260002  121.959999  121.959999   \n",
       "2021-03-12  120.400002  121.169998  119.160004  121.029999  121.029999   \n",
       "\n",
       "               Volume  adjclose_10  true_adjclose_10  buy_profit  sell_profit  \n",
       "Date                                                                           \n",
       "2018-05-04  224805200    42.421425         45.111092   -1.918201     0.000000  \n",
       "2018-05-07  169805600    43.278019         45.430706   -1.382404     0.000000  \n",
       "2018-05-08  113611200    44.016148         45.316906   -0.858955     0.000000  \n",
       "2018-05-09   92844800    44.644428         45.607460   -0.546638     0.000000  \n",
       "2018-05-10  111957200    45.211708         45.556606    0.000000     0.625767  \n",
       "...               ...          ...               ...         ...          ...  \n",
       "2021-03-08  153918600   127.774239        123.389999   11.414238     0.000000  \n",
       "2021-03-09  129159600   127.636894        122.540001    6.546898     0.000000  \n",
       "2021-03-10  111760400   127.522675        120.089996    7.542671     0.000000  \n",
       "2021-03-11  102753600   127.694420        120.589996    0.000000    -5.734421  \n",
       "2021-03-12   87963400   127.571632        121.209999    6.541634     0.000000  \n",
       "\n",
       "[719 rows x 10 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the future price\n",
    "final_df = get_final_df(model, data)\n",
    "\n",
    "# predict the future price\n",
    "future_price = predict(model, data)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 10 days is 127.06$\n",
      "mae loss: 0.02682538703083992\n",
      "Mean Absolute Error: 6.026933003521401\n",
      "Accuracy score: 0.6397774687065368\n",
      "Total buy profit: 1017.0425758361816\n",
      "Total sell profit: -464.13183975219727\n",
      "Total profit: 552.9107360839844\n",
      "Profit per trade: 0.7689996329401729\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model predicts the Future price after 10 days will be 127.06$\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"This model predicts the Future price after {LOOKUP_STEP} days will be {future_price:.2f}$\")\n",
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
