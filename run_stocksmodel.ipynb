{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTickerPriceData(tickers,period='7300d', interval='1d'):\n",
    "    #Getting Ticker Price Data (Open,High,Close,etc)\n",
    "    ticker_df = yf.download(tickers=tickers,period=period,interval=interval)\n",
    "    return ticker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getTickerPriceData('SPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['Adj Close', 'Volume', 'Open', 'High', 'Low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yfinance\n",
    "        df = getTickerPriceData(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['Adj Close'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 10\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = False\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = True\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"Adj Close\", \"Volume\", \"Open\", \"High\", \"Low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "LOSS = \"mae\"\n",
    "# huber loss\n",
    "#LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# AAPL stock market\n",
    "ticker = \"AAPL\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "\n",
    "# load json and create model\n",
    "file_path = Path(\"aaplmodel_10day.json\")\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "aaplmodel_10day = model_from_json(model_json)\n",
    "\n",
    "# load weights into new model\n",
    "file_path = \"aaplmodel_10day.h5\"\n",
    "aaplmodel_10day.load_weights(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"Adj Close\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"Adj Close\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"Adj Close\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"Adj Close\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"Adj Close\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(aaplmodel_10day, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(aaplmodel_10day, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 10\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = False\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = True\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"Adj Close\", \"Volume\", \"Open\", \"High\", \"Low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "LOSS = \"mae\"\n",
    "# huber loss\n",
    "#LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# Amazon stock market\n",
    "ticker = \"AAPL\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>adjclose_10</th>\n",
       "      <th>true_adjclose_10</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-06-11</th>\n",
       "      <td>32.294998</td>\n",
       "      <td>32.544998</td>\n",
       "      <td>32.119999</td>\n",
       "      <td>32.147499</td>\n",
       "      <td>29.479107</td>\n",
       "      <td>141563600</td>\n",
       "      <td>30.147671</td>\n",
       "      <td>29.229227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.668564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-12</th>\n",
       "      <td>32.047501</td>\n",
       "      <td>32.082500</td>\n",
       "      <td>31.777500</td>\n",
       "      <td>31.792500</td>\n",
       "      <td>29.153574</td>\n",
       "      <td>147544800</td>\n",
       "      <td>29.942493</td>\n",
       "      <td>29.057289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.788919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-15</th>\n",
       "      <td>31.525000</td>\n",
       "      <td>31.809999</td>\n",
       "      <td>31.427500</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>29.096258</td>\n",
       "      <td>175955600</td>\n",
       "      <td>29.816599</td>\n",
       "      <td>28.548355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.720341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-16</th>\n",
       "      <td>31.757500</td>\n",
       "      <td>31.962500</td>\n",
       "      <td>31.592501</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>29.252151</td>\n",
       "      <td>125976400</td>\n",
       "      <td>29.941366</td>\n",
       "      <td>28.754684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.689215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-17</th>\n",
       "      <td>31.930000</td>\n",
       "      <td>31.969999</td>\n",
       "      <td>31.684999</td>\n",
       "      <td>31.825001</td>\n",
       "      <td>29.183380</td>\n",
       "      <td>131672400</td>\n",
       "      <td>29.925499</td>\n",
       "      <td>29.022902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.742119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-08</th>\n",
       "      <td>120.930000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>116.209999</td>\n",
       "      <td>116.360001</td>\n",
       "      <td>116.360001</td>\n",
       "      <td>153918600</td>\n",
       "      <td>26.392244</td>\n",
       "      <td>123.389999</td>\n",
       "      <td>-89.967756</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <td>119.029999</td>\n",
       "      <td>122.059998</td>\n",
       "      <td>118.790001</td>\n",
       "      <td>121.089996</td>\n",
       "      <td>121.089996</td>\n",
       "      <td>129159600</td>\n",
       "      <td>26.488811</td>\n",
       "      <td>122.540001</td>\n",
       "      <td>-94.601185</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-10</th>\n",
       "      <td>121.690002</td>\n",
       "      <td>122.169998</td>\n",
       "      <td>119.449997</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>111760400</td>\n",
       "      <td>26.413969</td>\n",
       "      <td>120.089996</td>\n",
       "      <td>-93.566034</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11</th>\n",
       "      <td>122.540001</td>\n",
       "      <td>123.209999</td>\n",
       "      <td>121.260002</td>\n",
       "      <td>121.959999</td>\n",
       "      <td>121.959999</td>\n",
       "      <td>102753600</td>\n",
       "      <td>26.088951</td>\n",
       "      <td>120.589996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.871048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-12</th>\n",
       "      <td>120.400002</td>\n",
       "      <td>121.169998</td>\n",
       "      <td>119.160004</td>\n",
       "      <td>121.029999</td>\n",
       "      <td>121.029999</td>\n",
       "      <td>87963400</td>\n",
       "      <td>25.981548</td>\n",
       "      <td>121.209999</td>\n",
       "      <td>-95.048450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1449 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2015-06-11   32.294998   32.544998   32.119999   32.147499   29.479107   \n",
       "2015-06-12   32.047501   32.082500   31.777500   31.792500   29.153574   \n",
       "2015-06-15   31.525000   31.809999   31.427500   31.730000   29.096258   \n",
       "2015-06-16   31.757500   31.962500   31.592501   31.900000   29.252151   \n",
       "2015-06-17   31.930000   31.969999   31.684999   31.825001   29.183380   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2021-03-08  120.930000  121.000000  116.209999  116.360001  116.360001   \n",
       "2021-03-09  119.029999  122.059998  118.790001  121.089996  121.089996   \n",
       "2021-03-10  121.690002  122.169998  119.449997  119.980003  119.980003   \n",
       "2021-03-11  122.540001  123.209999  121.260002  121.959999  121.959999   \n",
       "2021-03-12  120.400002  121.169998  119.160004  121.029999  121.029999   \n",
       "\n",
       "               Volume  adjclose_10  true_adjclose_10  buy_profit  sell_profit  \n",
       "Date                                                                           \n",
       "2015-06-11  141563600    30.147671         29.229227    0.000000    -0.668564  \n",
       "2015-06-12  147544800    29.942493         29.057289    0.000000    -0.788919  \n",
       "2015-06-15  175955600    29.816599         28.548355    0.000000    -0.720341  \n",
       "2015-06-16  125976400    29.941366         28.754684    0.000000    -0.689215  \n",
       "2015-06-17  131672400    29.925499         29.022902    0.000000    -0.742119  \n",
       "...               ...          ...               ...         ...          ...  \n",
       "2021-03-08  153918600    26.392244        123.389999  -89.967756     0.000000  \n",
       "2021-03-09  129159600    26.488811        122.540001  -94.601185     0.000000  \n",
       "2021-03-10  111760400    26.413969        120.089996  -93.566034     0.000000  \n",
       "2021-03-11  102753600    26.088951        120.589996    0.000000    95.871048  \n",
       "2021-03-12   87963400    25.981548        121.209999  -95.048450     0.000000  \n",
       "\n",
       "[1449 rows x 10 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model predicts the Future price after 10 days will be 26.10$\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"This model predicts the Future price after {LOOKUP_STEP} days will be {future_price:.2f}$\")\n",
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
