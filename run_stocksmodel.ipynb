{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTickerPriceData(tickers,period='7300d', interval='1d'):\n",
    "    #Getting Ticker Price Data (Open,High,Close,etc)\n",
    "    ticker_df = yf.download(tickers=tickers,period=period,interval=interval)\n",
    "    return ticker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getTickerPriceData('SPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=False, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['Adj Close', 'Volume', 'Open', 'High', 'Low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yfinance\n",
    "        df = getTickerPriceData(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['Adj Close'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 10\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = False\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = True\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"Adj Close\", \"Volume\", \"Open\", \"High\", \"Low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "LOSS = \"mae\"\n",
    "# huber loss\n",
    "#LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# AAPL stock market\n",
    "ticker = \"TSLA\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "\n",
    "# load json and create model\n",
    "file_path = Path(\"aaplmodel_10day.json\")\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "aaplmodel_10day = model_from_json(model_json)\n",
    "\n",
    "# load weights into new model\n",
    "file_path = \"aaplmodel_10day.h5\"\n",
    "aaplmodel_10day.load_weights(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df':                   Open        High         Low       Close   Adj Close  \\\n",
       " Date                                                                     \n",
       " 2010-06-29    3.800000    5.000000    3.508000    4.778000    4.778000   \n",
       " 2010-06-30    5.158000    6.084000    4.660000    4.766000    4.766000   \n",
       " 2010-07-01    5.000000    5.184000    4.054000    4.392000    4.392000   \n",
       " 2010-07-02    4.600000    4.620000    3.742000    3.840000    3.840000   \n",
       " 2010-07-06    4.000000    4.000000    3.166000    3.222000    3.222000   \n",
       " ...                ...         ...         ...         ...         ...   \n",
       " 2021-03-23  675.770020  677.799988  657.510010  662.159973  662.159973   \n",
       " 2021-03-24  667.909973  668.020020  630.109985  630.270020  630.270020   \n",
       " 2021-03-25  613.000000  645.500000  609.500000  640.390015  640.390015   \n",
       " 2021-03-26  641.869995  643.820007  599.890015  618.710022  618.710022   \n",
       " 2021-03-29  615.640015  616.450012  596.020020  611.289978  611.289978   \n",
       " \n",
       "               Volume  \n",
       " Date                  \n",
       " 2010-06-29  93831500  \n",
       " 2010-06-30  85935500  \n",
       " 2010-07-01  41094000  \n",
       " 2010-07-02  25699000  \n",
       " 2010-07-06  34334500  \n",
       " ...              ...  \n",
       " 2021-03-23  30491900  \n",
       " 2021-03-24  33795200  \n",
       " 2021-03-25  39224900  \n",
       " 2021-03-26  33778400  \n",
       " 2021-03-29  28636985  \n",
       " \n",
       " [2706 rows x 6 columns],\n",
       " 'column_scaler': {'Adj Close': MinMaxScaler(),\n",
       "  'Volume': MinMaxScaler(),\n",
       "  'Open': MinMaxScaler(),\n",
       "  'High': MinMaxScaler(),\n",
       "  'Low': MinMaxScaler()},\n",
       " 'last_sequence': array([[0.7983703 , 0.16131917, 0.7845076 , 0.79747486, 0.7922183 ],\n",
       "        [0.8257589 , 0.15799232, 0.80642956, 0.8262016 , 0.822232  ],\n",
       "        [0.83182746, 0.10408597, 0.8111584 , 0.8221328 , 0.8245461 ],\n",
       "        [0.8555453 , 0.14504203, 0.8503747 , 0.8590974 , 0.8589691 ],\n",
       "        [0.9238007 , 0.16739938, 0.87192506, 0.9070199 , 0.88901734],\n",
       "        [0.9965111 , 0.24486232, 0.9601645 , 0.9822645 , 0.9617663 ],\n",
       "        [0.91828895, 0.19305758, 0.95273334, 0.94875556, 0.9217365 ],\n",
       "        [0.9617583 , 0.15020709, 0.93201613, 0.96388257, 0.9490447 ],\n",
       "        [0.96740645, 0.10759565, 0.95651644, 0.95548856, 0.95440966],\n",
       "        [0.9567124 , 0.10086698, 0.9459665 , 0.9583089 , 0.96218073],\n",
       "        [0.9353016 , 0.12556696, 0.95566076, 0.95485324, 0.9395582 ],\n",
       "        [0.956201  , 0.08146787, 0.93967247, 0.9438173 , 0.9555609 ],\n",
       "        [0.9629061 , 0.08245076, 0.9632495 , 0.9544073 , 0.9604884 ],\n",
       "        [0.95670104, 0.06553272, 0.95903856, 0.9501936 , 0.9652546 ],\n",
       "        [0.95857626, 0.06403783, 0.935743  , 0.94158787, 0.9505183 ],\n",
       "        [0.9973975 , 0.13344525, 0.95903856, 1.        , 0.9622613 ],\n",
       "        [1.        , 0.07411703, 1.        , 0.9949837 , 1.        ],\n",
       "        [0.97848684, 0.0879361 , 0.9763216 , 0.9900788 , 0.98510253],\n",
       "        [0.94583654, 0.08479241, 0.9196309 , 0.94158787, 0.9187202 ],\n",
       "        [0.89821917, 0.11311454, 0.9308902 , 0.93535644, 0.89465857],\n",
       "        [0.95081425, 0.0815481 , 0.91320175, 0.93489945, 0.9124572 ],\n",
       "        [0.9882945 , 0.07811109, 0.94741887, 0.97781676, 0.9661526 ],\n",
       "        [0.9677247 , 0.05837196, 0.9838316 , 0.9751191 , 0.97865546],\n",
       "        [0.96238333, 0.05004974, 0.95903856, 0.9510631 , 0.95604444],\n",
       "        [0.964929  , 0.05910559, 0.9477792 , 0.96028197, 0.962434  ],\n",
       "        [0.9776459 , 0.06435088, 0.97555596, 0.9747735 , 0.9806011 ],\n",
       "        [0.961781  , 0.04789585, 0.9591736 , 0.9547417 , 0.9656345 ],\n",
       "        [0.9110497 , 0.11714378, 0.94624794, 0.938043  , 0.9175919 ],\n",
       "        [0.918823  , 0.06915553, 0.9111188 , 0.92138886, 0.9195606 ],\n",
       "        [0.92389166, 0.07621074, 0.8985309 , 0.90739894, 0.90067977],\n",
       "        [0.9012762 , 0.06316904, 0.917379  , 0.91149   , 0.9088653 ],\n",
       "        [0.9034696 , 0.0835379 , 0.87356895, 0.88790226, 0.87383205],\n",
       "        [0.89123   , 0.05710133, 0.8756069 , 0.8821613 , 0.89024925],\n",
       "        [0.8843203 , 0.06039365, 0.89148253, 0.88450223, 0.8915156 ],\n",
       "        [0.80840516, 0.12060841, 0.85504735, 0.8529664 , 0.81418467],\n",
       "        [0.79060835, 0.21708015, 0.74187976, 0.79177856, 0.7091886 ],\n",
       "        [0.83968043, 0.11895535, 0.79786116, 0.8267701 , 0.7957297 ],\n",
       "        [0.7717204 , 0.12637688, 0.81396204, 0.8180864 , 0.7685712 ],\n",
       "        [0.7640835 , 0.13316837, 0.78451884, 0.7840758 , 0.75582665],\n",
       "        [0.81287146, 0.08728566, 0.7733834 , 0.797787  , 0.7852301 ],\n",
       "        [0.7765163 , 0.07609203, 0.805101  , 0.80013907, 0.7851725 ],\n",
       "        [0.73874056, 0.09738689, 0.7709964 , 0.7773874 , 0.74684674],\n",
       "        [0.7026468 , 0.21481973, 0.7347526 , 0.74143714, 0.6873144 ],\n",
       "        [0.6759515 , 0.29202092, 0.70126736, 0.69616777, 0.61765087],\n",
       "        [0.63623244, 0.16834675, 0.6725448 , 0.68757313, 0.6398704 ],\n",
       "        [0.7619015 , 0.22009362, 0.68113565, 0.7521832 , 0.6817998 ],\n",
       "        [0.7556283 , 0.19734596, 0.7848566 , 0.79650503, 0.75070345],\n",
       "        [0.791472  , 0.11726809, 0.78384334, 0.77939385, 0.7761696 ],\n",
       "        [0.784801  , 0.10848779, 0.7507409 , 0.7708996 , 0.76345956],\n",
       "        [0.80095005, 0.09451811, 0.77786463, 0.7912992 , 0.78406733],\n",
       "        [0.7656518 , 0.102962  , 0.78829074, 0.78543574, 0.7690547 ],\n",
       "        [0.7939836 , 0.1298606 , 0.7359573 , 0.780765  , 0.7460408 ],\n",
       "        [0.7386951 , 0.10730726, 0.76683044, 0.7646013 , 0.7471806 ],\n",
       "        [0.74063843, 0.13888422, 0.72439396, 0.7289298 , 0.7156587 ],\n",
       "        [0.757833  , 0.1279826 , 0.7671683 , 0.7761834 , 0.76646435],\n",
       "        [0.7489232 , 0.09832046, 0.7572375 , 0.7518599 , 0.75352407],\n",
       "        [0.7126817 , 0.10918295, 0.74838763, 0.74095786, 0.7219792 ],\n",
       "        [0.7241826 , 0.12703785, 0.68656266, 0.715854  , 0.6982515 ],\n",
       "        [0.6995443 , 0.10912771, 0.71906835, 0.7139812 , 0.68718773],\n",
       "        [0.69111174, 0.09222081, 0.68953514, 0.6834709 , 0.68273234]],\n",
       "       dtype=float32),\n",
       " 'X_train': array([[[1.83878234e-03, 3.06604862e-01, 6.44033949e-04, 1.86606671e-03,\n",
       "          5.89451403e-04],\n",
       "         [1.82514475e-03, 2.80639857e-01, 2.17305147e-03, 3.07443994e-03,\n",
       "          1.91571750e-03],\n",
       "         [1.40011148e-03, 1.33184150e-01, 1.99515396e-03, 2.07117805e-03,\n",
       "          1.21804629e-03],\n",
       "         ...,\n",
       "         [1.19327661e-03, 5.19727776e-03, 1.06513279e-03, 1.04116299e-03,\n",
       "          1.30784558e-03],\n",
       "         [1.07735803e-03, 2.05359072e-03, 1.00658473e-03, 9.74278373e-04,\n",
       "          1.27100479e-03],\n",
       "         [1.15918275e-03, 2.79347529e-03, 1.01784384e-03, 9.63131315e-04,\n",
       "          1.29403023e-03]],\n",
       " \n",
       "        [[1.82514475e-03, 2.80639857e-01, 2.17305147e-03, 3.07443994e-03,\n",
       "          1.91571750e-03],\n",
       "         [1.40011148e-03, 1.33184150e-01, 1.99515396e-03, 2.07117805e-03,\n",
       "          1.21804629e-03],\n",
       "         [7.72788539e-04, 8.25596079e-02, 1.54478056e-03, 1.44246721e-03,\n",
       "          8.58849438e-04],\n",
       "         ...,\n",
       "         [1.07735803e-03, 2.05359072e-03, 1.00658473e-03, 9.74278373e-04,\n",
       "          1.27100479e-03],\n",
       "         [1.15918275e-03, 2.79347529e-03, 1.01784384e-03, 9.63131315e-04,\n",
       "          1.29403023e-03],\n",
       "         [1.11599790e-03, 4.23707208e-03, 1.09440717e-03, 9.85426013e-04,\n",
       "          1.31475332e-03]],\n",
       " \n",
       "        [[1.40011148e-03, 1.33184150e-01, 1.99515396e-03, 2.07117805e-03,\n",
       "          1.21804629e-03],\n",
       "         [7.72788539e-04, 8.25596079e-02, 1.54478056e-03, 1.44246721e-03,\n",
       "          8.58849438e-04],\n",
       "         [7.04599152e-05, 1.10956378e-01, 8.69220647e-04, 7.51331565e-04,\n",
       "          1.95716158e-04],\n",
       "         ...,\n",
       "         [1.15918275e-03, 2.79347529e-03, 1.01784384e-03, 9.63131315e-04,\n",
       "          1.29403023e-03],\n",
       "         [1.11599790e-03, 4.23707208e-03, 1.09440717e-03, 9.85426013e-04,\n",
       "          1.31475332e-03],\n",
       "         [9.93260648e-04, 4.40806756e-03, 1.03811081e-03, 9.58672143e-04,\n",
       "          1.10061653e-03]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[7.67492875e-02, 1.57684192e-01, 7.66085088e-02, 7.80582130e-02,\n",
       "          7.78030008e-02],\n",
       "         [7.53900856e-02, 1.29663944e-01, 7.33230338e-02, 7.42792636e-02,\n",
       "          7.33521879e-02],\n",
       "         [7.32762814e-02, 7.51114339e-02, 7.56312013e-02, 7.50149935e-02,\n",
       "          7.42386729e-02],\n",
       "         ...,\n",
       "         [6.65893853e-02, 1.83027700e-01, 6.40228242e-02, 6.51830286e-02,\n",
       "          6.52794614e-02],\n",
       "         [6.61916286e-02, 2.04712898e-01, 6.41466752e-02, 6.57537729e-02,\n",
       "          6.42456189e-02],\n",
       "         [6.73712641e-02, 1.17804416e-01, 6.51420057e-02, 6.67659491e-02,\n",
       "          6.64330348e-02]],\n",
       " \n",
       "        [[7.53900856e-02, 1.29663944e-01, 7.33230338e-02, 7.42792636e-02,\n",
       "          7.33521879e-02],\n",
       "         [7.32762814e-02, 7.51114339e-02, 7.56312013e-02, 7.50149935e-02,\n",
       "          7.42386729e-02],\n",
       "         [7.04669654e-02, 6.71502799e-02, 7.16566592e-02, 7.15370178e-02,\n",
       "          7.15101510e-02],\n",
       "         ...,\n",
       "         [6.61916286e-02, 2.04712898e-01, 6.41466752e-02, 6.57537729e-02,\n",
       "          6.42456189e-02],\n",
       "         [6.73712641e-02, 1.17804416e-01, 6.51420057e-02, 6.67659491e-02,\n",
       "          6.64330348e-02],\n",
       "         [6.75258264e-02, 1.18933976e-01, 6.68444112e-02, 6.65875971e-02,\n",
       "          6.60600215e-02]],\n",
       " \n",
       "        [[7.32762814e-02, 7.51114339e-02, 7.56312013e-02, 7.50149935e-02,\n",
       "          7.42386729e-02],\n",
       "         [7.04669654e-02, 6.71502799e-02, 7.16566592e-02, 7.15370178e-02,\n",
       "          7.15101510e-02],\n",
       "         [7.50514194e-02, 1.29456773e-01, 6.95511550e-02, 7.34811202e-02,\n",
       "          7.13835061e-02],\n",
       "         ...,\n",
       "         [6.73712641e-02, 1.17804416e-01, 6.51420057e-02, 6.67659491e-02,\n",
       "          6.64330348e-02],\n",
       "         [6.75258264e-02, 1.18933976e-01, 6.68444112e-02, 6.65875971e-02,\n",
       "          6.60600215e-02],\n",
       "         [6.94487020e-02, 1.08915940e-01, 6.67340755e-02, 6.81794360e-02,\n",
       "          6.84477612e-02]]], dtype=float32),\n",
       " 'y_train': array([0.00092507, 0.00085461, 0.00097735, ..., 0.0663871 , 0.06587796,\n",
       "        0.06517791]),\n",
       " 'X_test': array([[[0.07046697, 0.06715028, 0.07165666, 0.07153702, 0.07151015],\n",
       "         [0.07505142, 0.12945677, 0.06955115, 0.07348112, 0.07138351],\n",
       "         [0.07457865, 0.10259403, 0.07294022, 0.07364609, 0.07380118],\n",
       "         ...,\n",
       "         [0.06752583, 0.11893398, 0.06684441, 0.0665876 , 0.06606002],\n",
       "         [0.0694487 , 0.10891594, 0.06673408, 0.06817944, 0.06844776],\n",
       "         [0.06851   , 0.08089405, 0.0683329 , 0.06858074, 0.06922372]],\n",
       " \n",
       "        [[0.07505142, 0.12945677, 0.06955115, 0.07348112, 0.07138351],\n",
       "         [0.07457865, 0.10259403, 0.07294022, 0.07364609, 0.07380118],\n",
       "         [0.07547645, 0.06591713, 0.07427783, 0.07394038, 0.07534619],\n",
       "         ...,\n",
       "         [0.0694487 , 0.10891594, 0.06673408, 0.06817944, 0.06844776],\n",
       "         [0.06851   , 0.08089405, 0.0683329 , 0.06858074, 0.06922372],\n",
       "         [0.066303  , 0.10526256, 0.06691647, 0.06645382, 0.06631791]],\n",
       " \n",
       "        [[0.07457865, 0.10259403, 0.07294022, 0.07364609, 0.07380118],\n",
       "         [0.07547645, 0.06591713, 0.07427783, 0.07394038, 0.07534619],\n",
       "         [0.07395361, 0.04870413, 0.07450527, 0.07376648, 0.07473372],\n",
       "         ...,\n",
       "         [0.06851   , 0.08089405, 0.0683329 , 0.06858074, 0.06922372],\n",
       "         [0.066303  , 0.10526256, 0.06691647, 0.06645382, 0.06631791],\n",
       "         [0.06591433, 0.09414127, 0.06545952, 0.06483746, 0.06528176]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.7532758 , 0.07339095, 0.74060744, 0.74305356, 0.7506344 ],\n",
       "         [0.78599435, 0.13894539, 0.75299275, 0.7728169 , 0.76601535],\n",
       "         [0.7983703 , 0.16131917, 0.7845076 , 0.79747486, 0.7922183 ],\n",
       "         ...,\n",
       "         [0.7619015 , 0.22009362, 0.68113565, 0.7521832 , 0.6817998 ],\n",
       "         [0.7556283 , 0.19734596, 0.7848566 , 0.79650503, 0.75070345],\n",
       "         [0.791472  , 0.11726809, 0.78384334, 0.77939385, 0.7761696 ]],\n",
       " \n",
       "        [[0.78599435, 0.13894539, 0.75299275, 0.7728169 , 0.76601535],\n",
       "         [0.7983703 , 0.16131917, 0.7845076 , 0.79747486, 0.7922183 ],\n",
       "         [0.8257589 , 0.15799232, 0.80642956, 0.8262016 , 0.822232  ],\n",
       "         ...,\n",
       "         [0.7556283 , 0.19734596, 0.7848566 , 0.79650503, 0.75070345],\n",
       "         [0.791472  , 0.11726809, 0.78384334, 0.77939385, 0.7761696 ],\n",
       "         [0.784801  , 0.10848779, 0.7507409 , 0.7708996 , 0.76345956]],\n",
       " \n",
       "        [[0.7983703 , 0.16131917, 0.7845076 , 0.79747486, 0.7922183 ],\n",
       "         [0.8257589 , 0.15799232, 0.80642956, 0.8262016 , 0.822232  ],\n",
       "         [0.83182746, 0.10408597, 0.8111584 , 0.8221328 , 0.8245461 ],\n",
       "         ...,\n",
       "         [0.791472  , 0.11726809, 0.78384334, 0.77939385, 0.7761696 ],\n",
       "         [0.784801  , 0.10848779, 0.7507409 , 0.7708996 , 0.76345956],\n",
       "         [0.80095005, 0.09451811, 0.77786463, 0.7912992 , 0.78406733]]],\n",
       "       dtype=float32),\n",
       " 'y_test': array([0.0626027 , 0.06339368, 0.06431648, 0.06410964, 0.06794631,\n",
       "        0.06911459, 0.06341186, 0.06126851, 0.0592638 , 0.05919562,\n",
       "        0.05927517, 0.06099121, 0.06253224, 0.06081393, 0.06208675,\n",
       "        0.06231405, 0.05901151, 0.0576614 , 0.05720228, 0.05859557,\n",
       "        0.05869103, 0.05653404, 0.05559988, 0.05727046, 0.05887514,\n",
       "        0.05973657, 0.06001841, 0.06213676, 0.0613867 , 0.06273453,\n",
       "        0.05727274, 0.05890468, 0.05850465, 0.05830237, 0.05915471,\n",
       "        0.0574182 , 0.05725455, 0.05695453, 0.05854102, 0.05805689,\n",
       "        0.05851829, 0.05612946, 0.05639085, 0.05519984, 0.05269283,\n",
       "        0.04985396, 0.05129271, 0.05066085, 0.04959712, 0.05189049,\n",
       "        0.05437478, 0.05444524, 0.05256327, 0.05205868, 0.05140863,\n",
       "        0.0508495 , 0.04800609, 0.04921073, 0.04912891, 0.04830611,\n",
       "        0.04437398, 0.04308524, 0.0430216 , 0.04021456, 0.04084188,\n",
       "        0.03973725, 0.03929858, 0.03956224, 0.03918948, 0.03849397,\n",
       "        0.03708704, 0.04041231, 0.0410919 , 0.04321934, 0.04288978,\n",
       "        0.04479447, 0.04575364, 0.04397168, 0.04502858, 0.04525815,\n",
       "        0.04755605, 0.04749014, 0.04787426, 0.04632641, 0.04683554,\n",
       "        0.04724012, 0.04635823, 0.04624686, 0.04705829, 0.04719921,\n",
       "        0.04804245, 0.04744695, 0.04979941, 0.04939029, 0.04876297,\n",
       "        0.04869933, 0.05071312, 0.05064039, 0.05211323, 0.05402702,\n",
       "        0.05377246, 0.05433614, 0.05403611, 0.05509075, 0.05452252,\n",
       "        0.05554305, 0.05661359, 0.04841749, 0.0482402 , 0.04999716,\n",
       "        0.05147227, 0.05132453, 0.04956076, 0.04967213, 0.04830384,\n",
       "        0.04885616, 0.04946302, 0.0505722 , 0.04982441, 0.04846067,\n",
       "        0.04982214, 0.04632641, 0.04542179, 0.04639914, 0.04796518,\n",
       "        0.04774471, 0.04660143, 0.04690146, 0.04445808, 0.04527633,\n",
       "        0.04506722, 0.04541043, 0.04680145, 0.04768788, 0.04755151,\n",
       "        0.04656734, 0.04859023, 0.0481061 , 0.04909254, 0.04994488,\n",
       "        0.05257236, 0.05229279, 0.05214051, 0.05159728, 0.05204732,\n",
       "        0.05175184, 0.05245872, 0.05109952, 0.05123816, 0.04714238,\n",
       "        0.04839021, 0.05154046, 0.05144273, 0.05115634, 0.05202459,\n",
       "        0.05167002, 0.04937438, 0.04901071, 0.05044037, 0.05096996,\n",
       "        0.05198822, 0.05203596, 0.05275192, 0.05481345, 0.05502483,\n",
       "        0.05544759, 0.05595218, 0.05481118, 0.05402702, 0.05449979,\n",
       "        0.05429523, 0.06452331, 0.07098973, 0.07089427, 0.0682827 ,\n",
       "        0.06800768, 0.06798723, 0.06762128, 0.06856682, 0.06850999,\n",
       "        0.07063744, 0.07267396, 0.07303763, 0.07484458, 0.07594468,\n",
       "        0.07507642, 0.07581285, 0.0764538 , 0.07595831, 0.07812439,\n",
       "        0.07646517, 0.0770584 , 0.07210574, 0.07285579, 0.07116929,\n",
       "        0.07170798, 0.07140113, 0.07252167, 0.07282397, 0.07210346,\n",
       "        0.07149886, 0.07275351, 0.07358085, 0.07569693, 0.07657427,\n",
       "        0.07816076, 0.07786756, 0.08312025, 0.08254974, 0.08576818,\n",
       "        0.08824338, 0.08859568, 0.09169366, 0.09306422, 0.09435751,\n",
       "        0.09423022, 0.0906663 , 0.09149137, 0.09420295, 0.0971009 ,\n",
       "        0.09903969, 0.10302182, 0.1082677 , 0.10581296, 0.1050879 ,\n",
       "        0.11570465, 0.11867307, 0.11425908, 0.11312036, 0.11244076,\n",
       "        0.12078233, 0.12586456, 0.1264646 , 0.12478719, 0.12324161,\n",
       "        0.12525996, 0.12846249, 0.14205903, 0.14427738, 0.17369563,\n",
       "        0.19802939, 0.16339936, 0.16664053, 0.16643823, 0.17171365,\n",
       "        0.17241826, 0.17080675, 0.17915061, 0.17824826, 0.19151522,\n",
       "        0.20492992, 0.20083643, 0.20119781, 0.1859216 , 0.17822098,\n",
       "        0.17342287, 0.15073926, 0.1482368 , 0.16542679, 0.16585638,\n",
       "        0.16676325, 0.16109009, 0.15630334, 0.13460161, 0.14308637,\n",
       "        0.14056345, 0.12381666, 0.1206505 , 0.09756912, 0.09418931,\n",
       "        0.07851079, 0.09360744, 0.09358244, 0.09511893, 0.11119066,\n",
       "        0.11897537, 0.11645472, 0.1133181 , 0.11053834, 0.11550919,\n",
       "        0.10586296, 0.09970565, 0.10551066, 0.11374541, 0.12038457,\n",
       "        0.12115509, 0.12664643, 0.14436375, 0.15776027, 0.16229245,\n",
       "        0.16578819, 0.16776107, 0.16604957, 0.15249394, 0.16281067,\n",
       "        0.15679202, 0.16122873, 0.17795733, 0.17122271, 0.17835737,\n",
       "        0.17412294, 0.1558124 , 0.1694203 , 0.17101587, 0.17428205,\n",
       "        0.17370472, 0.18265544, 0.18080755, 0.18038026, 0.17618674,\n",
       "        0.17899832, 0.17805279, 0.18133942, 0.18006205, 0.18177809,\n",
       "        0.18451468, 0.18207812, 0.18253043, 0.18283954, 0.17956201,\n",
       "        0.18619662, 0.20053867, 0.19677928, 0.19709748, 0.19287444,\n",
       "        0.19771118, 0.21231687, 0.21021445, 0.22939323, 0.21752638,\n",
       "        0.20898934, 0.22163125, 0.21963791, 0.22183355, 0.22459969,\n",
       "        0.22390416, 0.22240859, 0.22410419, 0.21480117, 0.22051299,\n",
       "        0.21454888, 0.22582477, 0.24183969, 0.2508904 , 0.2711261 ,\n",
       "        0.30815633, 0.31231118, 0.30686076, 0.31331581, 0.34749353,\n",
       "        0.33667676, 0.34116347, 0.34780265, 0.33749046, 0.33753593,\n",
       "        0.3698476 , 0.3528826 , 0.35833077, 0.34031571, 0.31847986,\n",
       "        0.34634574, 0.3320014 , 0.33714271, 0.33450158, 0.3216074 ,\n",
       "        0.33393564, 0.33439022, 0.33394019, 0.33497662, 0.32659641,\n",
       "        0.3188367 , 0.308795  , 0.34979145, 0.36484721, 0.3716    ,\n",
       "        0.41363288, 0.425327  , 0.42338139, 0.45140634, 0.4623504 ,\n",
       "        0.45421793, 0.45629537, 0.48580454, 0.50525608, 0.49949425,\n",
       "        0.56272657, 0.53628126, 0.50482423, 0.45894558, 0.47181025,\n",
       "        0.37167727, 0.41266918, 0.41841963, 0.41998794, 0.47328763,\n",
       "        0.50754037, 0.49844874, 0.47761751, 0.49889194, 0.50711989,\n",
       "        0.4785267 , 0.42867043, 0.43711431, 0.45933197, 0.47508324,\n",
       "        0.47266259, 0.48395895, 0.50572203, 0.46813949, 0.48017454,\n",
       "        0.46687805, 0.47974268, 0.48044731, 0.48962984, 0.4990624 ,\n",
       "        0.50400598, 0.52065502, 0.50654028, 0.49607355, 0.48602727,\n",
       "        0.47592421, 0.47671974, 0.48029956, 0.47443546, 0.47403769,\n",
       "        0.47903808, 0.45783185, 0.46329819, 0.43739843, 0.45157001,\n",
       "        0.47815165, 0.47483322, 0.49427793, 0.48502722, 0.47515143,\n",
       "        0.46276405, 0.47045787, 0.46435512, 0.46065026, 0.46018431,\n",
       "        0.49827824, 0.5494528 , 0.56380618, 0.55282803, 0.5894673 ,\n",
       "        0.62757263, 0.6487334 , 0.66209811, 0.64146007, 0.66096166,\n",
       "        0.64284658, 0.67075789, 0.67719019, 0.72573954, 0.73496754,\n",
       "        0.6833725 , 0.70904502, 0.68963437, 0.72354619, 0.7160683 ,\n",
       "        0.70415829, 0.74180901, 0.78624434, 0.73494479, 0.72412579,\n",
       "        0.73053534, 0.74847999, 0.75066196, 0.75327579, 0.78599435,\n",
       "        0.79837028, 0.82575886, 0.83182749, 0.85554528, 0.9238007 ,\n",
       "        0.99651108, 0.91828893, 0.9617583 , 0.96740644, 0.95671244,\n",
       "        0.93530161, 0.95620102, 0.96290612, 0.95670106, 0.95857624,\n",
       "        0.99739748, 1.        , 0.97848686, 0.94583656, 0.89821918,\n",
       "        0.95081424, 0.98829447, 0.96772468, 0.96238333, 0.96492898,\n",
       "        0.9776459 , 0.96178105, 0.91104972, 0.91882303, 0.92389164,\n",
       "        0.90127618, 0.90346959, 0.89122996, 0.8843203 , 0.80840519,\n",
       "        0.79060835, 0.83968043, 0.77172042, 0.76408348, 0.81287145,\n",
       "        0.77651629, 0.73874057, 0.70264678, 0.67595149, 0.63623241,\n",
       "        0.76190151, 0.75562826, 0.791472  , 0.78480102, 0.80095005,\n",
       "        0.7656518 , 0.79398359, 0.73869507, 0.74063843, 0.75783299,\n",
       "        0.74892316, 0.71268169, 0.7241826 , 0.69954429, 0.69111175]),\n",
       " 'test_df':                   Open        High         Low       Close   Adj Close  \\\n",
       " Date                                                                     \n",
       " 2019-02-06   63.917999   64.848000   63.124001   63.444000   63.444000   \n",
       " 2019-02-07   62.660000   62.939999   60.599998   61.501999   61.501999   \n",
       " 2019-02-08   61.366001   61.490002   59.700001   61.160000   61.160000   \n",
       " 2019-02-11   62.320000   63.720001   62.099998   62.568001   62.568001   \n",
       " 2019-02-12   63.240002   63.638000   61.924000   62.362000   62.362000   \n",
       " ...                ...         ...         ...         ...         ...   \n",
       " 2021-03-09  608.179993  678.090027  595.210022  673.580017  673.580017   \n",
       " 2021-03-10  700.299988  717.849976  655.059998  668.059998  668.059998   \n",
       " 2021-03-11  699.400024  702.500000  677.179993  699.599976  699.599976   \n",
       " 2021-03-12  670.000000  694.880005  666.140015  693.729980  693.729980   \n",
       " 2021-03-15  694.090027  713.179993  684.039978  707.940002  707.940002   \n",
       " \n",
       "               Volume  \n",
       " Date                  \n",
       " 2019-02-06  25192500  \n",
       " 2019-02-07  32603000  \n",
       " 2019-02-08  29221000  \n",
       " 2019-02-11  35648500  \n",
       " 2019-02-12  27588000  \n",
       " ...              ...  \n",
       " 2021-03-09  67523300  \n",
       " 2021-03-10  60605700  \n",
       " 2021-03-11  36253900  \n",
       " 2021-03-12  33583800  \n",
       " 2021-03-15  29335600  \n",
       " \n",
       " [530 rows x 6 columns]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"Adj Close\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"Adj Close\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"Adj Close\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"Adj Close\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"Adj Close\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(model, data):\n",
    "    df = get_final_df(model, data)\n",
    "    avg_error = abs(final_df['adjclose_10'] - final_df['true_adjclose_10']).mean()\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"Adj Close\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "           predicted_price = prediction[0][0]\n",
    "    \n",
    "    last_close_price = data['df']['Adj Close'][-1]\n",
    "    strike_price_call = predicted_price - avg_error \n",
    "    strike_price_put = predicted_price + avg_error \n",
    "    \n",
    "    if last_close_price > predicted_price:\n",
    "        recommendation = f\"This model recommends you take a Put because Future price after {LOOKUP_STEP} days is ${predicted_price}. A strike price of ${strike_price_put} is suggested.\"\n",
    "    else: \n",
    "        recommendation = f\"This model recommends you take a Call because Future price after {LOOKUP_STEP} days is ${predicted_price}. A strike price of ${strike_price_call} is suggested.\"\n",
    "    \n",
    "    return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>adjclose_10</th>\n",
       "      <th>true_adjclose_10</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-06</th>\n",
       "      <td>63.917999</td>\n",
       "      <td>64.848000</td>\n",
       "      <td>63.124001</td>\n",
       "      <td>63.444000</td>\n",
       "      <td>63.444000</td>\n",
       "      <td>25192500</td>\n",
       "      <td>59.231255</td>\n",
       "      <td>58.245998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.212746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-07</th>\n",
       "      <td>62.660000</td>\n",
       "      <td>62.939999</td>\n",
       "      <td>60.599998</td>\n",
       "      <td>61.501999</td>\n",
       "      <td>61.501999</td>\n",
       "      <td>32603000</td>\n",
       "      <td>57.550804</td>\n",
       "      <td>58.942001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.951195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-08</th>\n",
       "      <td>61.366001</td>\n",
       "      <td>61.490002</td>\n",
       "      <td>59.700001</td>\n",
       "      <td>61.160000</td>\n",
       "      <td>61.160000</td>\n",
       "      <td>29221000</td>\n",
       "      <td>56.830433</td>\n",
       "      <td>59.754002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.329567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-11</th>\n",
       "      <td>62.320000</td>\n",
       "      <td>63.720001</td>\n",
       "      <td>62.099998</td>\n",
       "      <td>62.568001</td>\n",
       "      <td>62.568001</td>\n",
       "      <td>35648500</td>\n",
       "      <td>58.225998</td>\n",
       "      <td>59.571999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.342003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-12</th>\n",
       "      <td>63.240002</td>\n",
       "      <td>63.638000</td>\n",
       "      <td>61.924000</td>\n",
       "      <td>62.362000</td>\n",
       "      <td>62.362000</td>\n",
       "      <td>27588000</td>\n",
       "      <td>58.352016</td>\n",
       "      <td>62.948002</td>\n",
       "      <td>-4.009983</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <td>608.179993</td>\n",
       "      <td>678.090027</td>\n",
       "      <td>595.210022</td>\n",
       "      <td>673.580017</td>\n",
       "      <td>673.580017</td>\n",
       "      <td>67523300</td>\n",
       "      <td>177.176697</td>\n",
       "      <td>662.159973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>496.403320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-10</th>\n",
       "      <td>700.299988</td>\n",
       "      <td>717.849976</td>\n",
       "      <td>655.059998</td>\n",
       "      <td>668.059998</td>\n",
       "      <td>668.059998</td>\n",
       "      <td>60605700</td>\n",
       "      <td>170.260376</td>\n",
       "      <td>630.270020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>497.799622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11</th>\n",
       "      <td>699.400024</td>\n",
       "      <td>702.500000</td>\n",
       "      <td>677.179993</td>\n",
       "      <td>699.599976</td>\n",
       "      <td>699.599976</td>\n",
       "      <td>36253900</td>\n",
       "      <td>162.356628</td>\n",
       "      <td>640.390015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>537.243347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-12</th>\n",
       "      <td>670.000000</td>\n",
       "      <td>694.880005</td>\n",
       "      <td>666.140015</td>\n",
       "      <td>693.729980</td>\n",
       "      <td>693.729980</td>\n",
       "      <td>33583800</td>\n",
       "      <td>159.973801</td>\n",
       "      <td>618.710022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>533.756180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-15</th>\n",
       "      <td>694.090027</td>\n",
       "      <td>713.179993</td>\n",
       "      <td>684.039978</td>\n",
       "      <td>707.940002</td>\n",
       "      <td>707.940002</td>\n",
       "      <td>29335600</td>\n",
       "      <td>159.440506</td>\n",
       "      <td>611.289978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>548.499496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>530 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2019-02-06   63.917999   64.848000   63.124001   63.444000   63.444000   \n",
       "2019-02-07   62.660000   62.939999   60.599998   61.501999   61.501999   \n",
       "2019-02-08   61.366001   61.490002   59.700001   61.160000   61.160000   \n",
       "2019-02-11   62.320000   63.720001   62.099998   62.568001   62.568001   \n",
       "2019-02-12   63.240002   63.638000   61.924000   62.362000   62.362000   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2021-03-09  608.179993  678.090027  595.210022  673.580017  673.580017   \n",
       "2021-03-10  700.299988  717.849976  655.059998  668.059998  668.059998   \n",
       "2021-03-11  699.400024  702.500000  677.179993  699.599976  699.599976   \n",
       "2021-03-12  670.000000  694.880005  666.140015  693.729980  693.729980   \n",
       "2021-03-15  694.090027  713.179993  684.039978  707.940002  707.940002   \n",
       "\n",
       "              Volume  adjclose_10  true_adjclose_10  buy_profit  sell_profit  \n",
       "Date                                                                          \n",
       "2019-02-06  25192500    59.231255         58.245998    0.000000     4.212746  \n",
       "2019-02-07  32603000    57.550804         58.942001    0.000000     3.951195  \n",
       "2019-02-08  29221000    56.830433         59.754002    0.000000     4.329567  \n",
       "2019-02-11  35648500    58.225998         59.571999    0.000000     4.342003  \n",
       "2019-02-12  27588000    58.352016         62.948002   -4.009983     0.000000  \n",
       "...              ...          ...               ...         ...          ...  \n",
       "2021-03-09  67523300   177.176697        662.159973    0.000000   496.403320  \n",
       "2021-03-10  60605700   170.260376        630.270020    0.000000   497.799622  \n",
       "2021-03-11  36253900   162.356628        640.390015    0.000000   537.243347  \n",
       "2021-03-12  33583800   159.973801        618.710022    0.000000   533.756180  \n",
       "2021-03-15  29335600   159.440506        611.289978    0.000000   548.499496  \n",
       "\n",
       "[530 rows x 10 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(aaplmodel_10day, data)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(aaplmodel_10day, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This model recommends you take a Put because Future price after 10 days is $170.6336212158203. A strike price of $305.1240137280158 is suggested.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get option recomendation from model\n",
    "option_recommendation = recommendation(aaplmodel_10day, data)\n",
    "option_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>adjclose_10</th>\n",
       "      <th>true_adjclose_10</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-06</th>\n",
       "      <td>63.917999</td>\n",
       "      <td>64.848000</td>\n",
       "      <td>63.124001</td>\n",
       "      <td>63.444000</td>\n",
       "      <td>63.444000</td>\n",
       "      <td>25192500</td>\n",
       "      <td>59.231255</td>\n",
       "      <td>58.245998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.212746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-07</th>\n",
       "      <td>62.660000</td>\n",
       "      <td>62.939999</td>\n",
       "      <td>60.599998</td>\n",
       "      <td>61.501999</td>\n",
       "      <td>61.501999</td>\n",
       "      <td>32603000</td>\n",
       "      <td>57.550804</td>\n",
       "      <td>58.942001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.951195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-08</th>\n",
       "      <td>61.366001</td>\n",
       "      <td>61.490002</td>\n",
       "      <td>59.700001</td>\n",
       "      <td>61.160000</td>\n",
       "      <td>61.160000</td>\n",
       "      <td>29221000</td>\n",
       "      <td>56.830433</td>\n",
       "      <td>59.754002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.329567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-11</th>\n",
       "      <td>62.320000</td>\n",
       "      <td>63.720001</td>\n",
       "      <td>62.099998</td>\n",
       "      <td>62.568001</td>\n",
       "      <td>62.568001</td>\n",
       "      <td>35648500</td>\n",
       "      <td>58.225998</td>\n",
       "      <td>59.571999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.342003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-12</th>\n",
       "      <td>63.240002</td>\n",
       "      <td>63.638000</td>\n",
       "      <td>61.924000</td>\n",
       "      <td>62.362000</td>\n",
       "      <td>62.362000</td>\n",
       "      <td>27588000</td>\n",
       "      <td>58.352016</td>\n",
       "      <td>62.948002</td>\n",
       "      <td>-4.009983</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <td>608.179993</td>\n",
       "      <td>678.090027</td>\n",
       "      <td>595.210022</td>\n",
       "      <td>673.580017</td>\n",
       "      <td>673.580017</td>\n",
       "      <td>67523300</td>\n",
       "      <td>177.176697</td>\n",
       "      <td>662.159973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>496.403320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-10</th>\n",
       "      <td>700.299988</td>\n",
       "      <td>717.849976</td>\n",
       "      <td>655.059998</td>\n",
       "      <td>668.059998</td>\n",
       "      <td>668.059998</td>\n",
       "      <td>60605700</td>\n",
       "      <td>170.260376</td>\n",
       "      <td>630.270020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>497.799622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11</th>\n",
       "      <td>699.400024</td>\n",
       "      <td>702.500000</td>\n",
       "      <td>677.179993</td>\n",
       "      <td>699.599976</td>\n",
       "      <td>699.599976</td>\n",
       "      <td>36253900</td>\n",
       "      <td>162.356628</td>\n",
       "      <td>640.390015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>537.243347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-12</th>\n",
       "      <td>670.000000</td>\n",
       "      <td>694.880005</td>\n",
       "      <td>666.140015</td>\n",
       "      <td>693.729980</td>\n",
       "      <td>693.729980</td>\n",
       "      <td>33583800</td>\n",
       "      <td>159.973801</td>\n",
       "      <td>618.710022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>533.756180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-15</th>\n",
       "      <td>694.090027</td>\n",
       "      <td>713.179993</td>\n",
       "      <td>684.039978</td>\n",
       "      <td>707.940002</td>\n",
       "      <td>707.940002</td>\n",
       "      <td>29335600</td>\n",
       "      <td>159.440506</td>\n",
       "      <td>611.289978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>548.499496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>530 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2019-02-06   63.917999   64.848000   63.124001   63.444000   63.444000   \n",
       "2019-02-07   62.660000   62.939999   60.599998   61.501999   61.501999   \n",
       "2019-02-08   61.366001   61.490002   59.700001   61.160000   61.160000   \n",
       "2019-02-11   62.320000   63.720001   62.099998   62.568001   62.568001   \n",
       "2019-02-12   63.240002   63.638000   61.924000   62.362000   62.362000   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2021-03-09  608.179993  678.090027  595.210022  673.580017  673.580017   \n",
       "2021-03-10  700.299988  717.849976  655.059998  668.059998  668.059998   \n",
       "2021-03-11  699.400024  702.500000  677.179993  699.599976  699.599976   \n",
       "2021-03-12  670.000000  694.880005  666.140015  693.729980  693.729980   \n",
       "2021-03-15  694.090027  713.179993  684.039978  707.940002  707.940002   \n",
       "\n",
       "              Volume  adjclose_10  true_adjclose_10  buy_profit  sell_profit  \n",
       "Date                                                                          \n",
       "2019-02-06  25192500    59.231255         58.245998    0.000000     4.212746  \n",
       "2019-02-07  32603000    57.550804         58.942001    0.000000     3.951195  \n",
       "2019-02-08  29221000    56.830433         59.754002    0.000000     4.329567  \n",
       "2019-02-11  35648500    58.225998         59.571999    0.000000     4.342003  \n",
       "2019-02-12  27588000    58.352016         62.948002   -4.009983     0.000000  \n",
       "...              ...          ...               ...         ...          ...  \n",
       "2021-03-09  67523300   177.176697        662.159973    0.000000   496.403320  \n",
       "2021-03-10  60605700   170.260376        630.270020    0.000000   497.799622  \n",
       "2021-03-11  36253900   162.356628        640.390015    0.000000   537.243347  \n",
       "2021-03-12  33583800   159.973801        618.710022    0.000000   533.756180  \n",
       "2021-03-15  29335600   159.440506        611.289978    0.000000   548.499496  \n",
       "\n",
       "[530 rows x 10 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model predicts the Future price after 10 days will be 170.63$\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"This model predicts the Future price after {LOOKUP_STEP} days will be {future_price:.2f}$\")\n",
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
