{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTickerPriceData(tickers,period='7300d', interval='1d'):\n",
    "    #Getting Ticker Price Data (Open,High,Close,etc)\n",
    "    ticker_df = yf.download(tickers=tickers,period=period,interval=interval)\n",
    "    return ticker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getTickerPriceData('SPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=False, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['Adj Close', 'Volume', 'Open', 'High', 'Low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yfinance\n",
    "        df = getTickerPriceData(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['Adj Close'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 10\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = False\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = True\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"Adj Close\", \"Volume\", \"Open\", \"High\", \"Low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "LOSS = \"mae\"\n",
    "# huber loss\n",
    "#LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# AAPL stock market\n",
    "ticker = \"AAPL\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "\n",
    "# load json and create model\n",
    "file_path = Path(\"aaplmodel_10day.json\")\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "aaplmodel_10day = model_from_json(model_json)\n",
    "\n",
    "# load weights into new model\n",
    "file_path = \"aaplmodel_10day.h5\"\n",
    "aaplmodel_10day.load_weights(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df':                   Open        High         Low       Close   Adj Close  \\\n",
       " Date                                                                     \n",
       " 1992-04-03    0.524554    0.529018    0.522321    0.526786    0.434046   \n",
       " 1992-04-06    0.526786    0.544643    0.526786    0.542411    0.446921   \n",
       " 1992-04-07    0.544643    0.546875    0.511161    0.511161    0.421172   \n",
       " 1992-04-08    0.508929    0.508929    0.488839    0.498884    0.411057   \n",
       " 1992-04-09    0.500000    0.520089    0.493304    0.511161    0.421172   \n",
       " ...                ...         ...         ...         ...         ...   \n",
       " 2021-03-23  123.330002  124.239998  122.139999  122.540001  122.540001   \n",
       " 2021-03-24  122.820000  122.900002  120.070000  120.089996  120.089996   \n",
       " 2021-03-25  119.540001  121.660004  119.000000  120.589996  120.589996   \n",
       " 2021-03-26  120.349998  121.480003  118.919998  121.209999  121.209999   \n",
       " 2021-03-29  121.650002  122.580002  120.729897  121.389999  121.389999   \n",
       " \n",
       "                Volume  \n",
       " Date                   \n",
       " 1992-04-03  116457600  \n",
       " 1992-04-06  101987200  \n",
       " 1992-04-07  230216000  \n",
       " 1992-04-08  367024000  \n",
       " 1992-04-09  192136000  \n",
       " ...               ...  \n",
       " 2021-03-23   95467100  \n",
       " 2021-03-24   88530500  \n",
       " 2021-03-25   98844700  \n",
       " 2021-03-26   93958900  \n",
       " 2021-03-29   80819203  \n",
       " \n",
       " [7300 rows x 6 columns],\n",
       " 'column_scaler': {'Adj Close': MinMaxScaler(),\n",
       "  'Volume': MinMaxScaler(),\n",
       "  'Open': MinMaxScaler(),\n",
       "  'High': MinMaxScaler(),\n",
       "  'Low': MinMaxScaler()},\n",
       " 'last_sequence': array([[0.92681414, 0.01303634, 0.93365157, 0.9286068 , 0.93168443],\n",
       "        [0.9038868 , 0.01899184, 0.9297488 , 0.92081213, 0.8965709 ],\n",
       "        [0.9150707 , 0.01284068, 0.89748055, 0.90791315, 0.9083934 ],\n",
       "        [0.8842446 , 0.02058043, 0.8893264 , 0.90315354, 0.8938807 ],\n",
       "        [0.9144417 , 0.0144464 , 0.8937868 , 0.9071543 , 0.9043582 ],\n",
       "        [0.92234045, 0.01385066, 0.9221521 , 0.91405225, 0.9211362 ],\n",
       "        [0.900881  , 0.0132391 , 0.8995714 , 0.89708334, 0.90888894],\n",
       "        [0.89962274, 0.01207054, 0.8947625 , 0.8937724 , 0.89727885],\n",
       "        [0.914232  , 0.01162383, 0.8965745 , 0.9059127 , 0.9088182 ],\n",
       "        [0.90039176, 0.01183746, 0.91079205, 0.90280867, 0.9107295 ],\n",
       "        [0.88801926, 0.01471871, 0.8967139 , 0.8974283 , 0.89826995],\n",
       "        [0.8928424 , 0.01190964, 0.8897446 , 0.8870125 , 0.8978452 ],\n",
       "        [0.9222006 , 0.01373761, 0.89587766, 0.91308653, 0.9092429 ],\n",
       "        [0.95603245, 0.01592247, 0.93170017, 0.9626134 , 0.94492275],\n",
       "        [0.9714107 , 0.01510432, 0.9489842 , 0.9638551 , 0.9550463 ],\n",
       "        [0.9983224 , 0.02092058, 0.99630624, 1.        , 0.9658068 ],\n",
       "        [1.        , 0.01293849, 1.        , 0.9945507 , 1.        ],\n",
       "        [0.99231094, 0.01866053, 0.9988151 , 0.9945507 , 0.9932039 ],\n",
       "        [0.9575704 , 0.01890008, 0.97156495, 0.9786166 , 0.9669395 ],\n",
       "        [0.9217114 , 0.02355817, 0.945848  , 0.9424026 , 0.9209947 ],\n",
       "        [0.9369497 , 0.01399644, 0.93135166, 0.9330215 , 0.9260917 ],\n",
       "        [0.94289124, 0.01090524, 0.94515103, 0.93943644, 0.9521437 ],\n",
       "        [0.9355517 , 0.01179151, 0.94536006, 0.9357116 , 0.94506437],\n",
       "        [0.9596673 , 0.01102354, 0.9491236 , 0.94695514, 0.9520021 ],\n",
       "        [0.9566921 , 0.00985642, 0.95644146, 0.9470931 , 0.9609929 ],\n",
       "        [0.9577422 , 0.00928671, 0.94724184, 0.94392014, 0.9543383 ],\n",
       "        [0.9514417 , 0.01002493, 0.9513537 , 0.9502662 , 0.9609221 ],\n",
       "        [0.9471014 , 0.00952251, 0.95037806, 0.9441271 , 0.950657  ],\n",
       "        [0.9452813 , 0.00832397, 0.9463358 , 0.9399883 , 0.9461971 ],\n",
       "        [0.9469614 , 0.00776797, 0.93553334, 0.9340561 , 0.9456307 ],\n",
       "        [0.93170035, 0.01053739, 0.9434784 , 0.9373671 , 0.9392593 ],\n",
       "        [0.9152491 , 0.01287486, 0.9139283 , 0.91122407, 0.9157559 ],\n",
       "        [0.9073386 , 0.01273174, 0.89964104, 0.89591074, 0.9011725 ],\n",
       "        [0.90845865, 0.01149335, 0.90688926, 0.9008083 , 0.91101277],\n",
       "        [0.8813667 , 0.01368328, 0.89134747, 0.8939793 , 0.8883589 ],\n",
       "        [0.88038665, 0.02100972, 0.8617277 , 0.8732166 , 0.8373169 ],\n",
       "        [0.8768164 , 0.01464342, 0.8699516 , 0.865284  , 0.86450154],\n",
       "        [0.84629416, 0.01965196, 0.8681395 , 0.87149215, 0.85253745],\n",
       "        [0.84818435, 0.02182476, 0.8535735 , 0.86038655, 0.8572098 ],\n",
       "        [0.89389765, 0.01531174, 0.86165804, 0.8816321 , 0.86846596],\n",
       "        [0.8752063 , 0.01342704, 0.8941353 , 0.88708144, 0.8841821 ],\n",
       "        [0.85378474, 0.01483084, 0.86904556, 0.86631876, 0.8617405 ],\n",
       "        [0.84027374, 0.02357093, 0.8477193 , 0.8517642 , 0.83894515],\n",
       "        [0.84930444, 0.02037857, 0.84235287, 0.8403137 , 0.8315118 ],\n",
       "        [0.8138819 , 0.02042281, 0.8420044 , 0.83382964, 0.8218839 ],\n",
       "        [0.8469942 , 0.01708568, 0.8287626 , 0.8411414 , 0.8401486 ],\n",
       "        [0.83922374, 0.01474053, 0.8473011 , 0.84190017, 0.8448209 ],\n",
       "        [0.8530847 , 0.01352655, 0.8532251 , 0.849074  , 0.85763454],\n",
       "        [0.8465742 , 0.01153306, 0.83831066, 0.8350023 , 0.84276795],\n",
       "        [0.8672957 , 0.01213156, 0.8453497 , 0.85452336, 0.8516879 ],\n",
       "        [0.8783565 , 0.01514214, 0.87524825, 0.8767346 , 0.8821291 ],\n",
       "        [0.8726861 , 0.01469701, 0.86374885, 0.86735344, 0.8652802 ],\n",
       "        [0.84307396, 0.01601685, 0.85559464, 0.84886706, 0.85098   ],\n",
       "        [0.83929366, 0.02461523, 0.834826  , 0.83679575, 0.8464492 ],\n",
       "        [0.8630954 , 0.01476101, 0.8378228 , 0.85362667, 0.85055524],\n",
       "        [0.857145  , 0.01254445, 0.8587309 , 0.8561788 , 0.86386436],\n",
       "        [0.8399937 , 0.0116095 , 0.8551765 , 0.8469357 , 0.84921014],\n",
       "        [0.843494  , 0.01299969, 0.832317  , 0.8383823 , 0.8416352 ],\n",
       "        [0.8478343 , 0.01234116, 0.83796215, 0.8371407 , 0.8410689 ],\n",
       "        [0.8490944 , 0.01057013, 0.84702235, 0.84472835, 0.8538818 ]],\n",
       "       dtype=float32),\n",
       " 'X_train': array([[[0.002342  , 0.01537364, 0.00285465, 0.00283306, 0.00289178],\n",
       "         [0.00243213, 0.01342325, 0.0028702 , 0.00294084, 0.00292339],\n",
       "         [0.00225188, 0.03070652, 0.00299465, 0.00295624, 0.00281278],\n",
       "         ...,\n",
       "         [0.00208364, 0.01861624, 0.00254351, 0.00252512, 0.00257575],\n",
       "         [0.00212234, 0.01268507, 0.00259018, 0.00257131, 0.00262315],\n",
       "         [0.00201914, 0.02517691, 0.00255907, 0.00250972, 0.00251253]],\n",
       " \n",
       "        [[0.00243213, 0.01342325, 0.0028702 , 0.00294084, 0.00292339],\n",
       "         [0.00225188, 0.03070652, 0.00299465, 0.00295624, 0.00281278],\n",
       "         [0.00218106, 0.04914614, 0.00274575, 0.00269449, 0.00265475],\n",
       "         ...,\n",
       "         [0.00212234, 0.01268507, 0.00259018, 0.00257131, 0.00262315],\n",
       "         [0.00201914, 0.02517691, 0.00255907, 0.00250972, 0.00251253],\n",
       "         [0.00184497, 0.04892121, 0.00241906, 0.00238655, 0.0022755 ]],\n",
       " \n",
       "        [[0.00225188, 0.03070652, 0.00299465, 0.00295624, 0.00281278],\n",
       "         [0.00218106, 0.04914614, 0.00274575, 0.00269449, 0.00265475],\n",
       "         [0.00225188, 0.02557393, 0.00268352, 0.00277147, 0.00268636],\n",
       "         ...,\n",
       "         [0.00201914, 0.02517691, 0.00255907, 0.00250972, 0.00251253],\n",
       "         [0.00184497, 0.04892121, 0.00241906, 0.00238655, 0.0022755 ],\n",
       "         [0.00175466, 0.0406849 , 0.00224793, 0.00221718, 0.00216489]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.20126562, 0.02507021, 0.21533634, 0.21715754, 0.21865356],\n",
       "         [0.19816516, 0.02236961, 0.21889071, 0.21731274, 0.2192907 ],\n",
       "         [0.19787747, 0.02157751, 0.21667793, 0.21495022, 0.2170607 ],\n",
       "         ...,\n",
       "         [0.20576827, 0.01888473, 0.2248321 , 0.22283107, 0.22637004],\n",
       "         [0.20440418, 0.02807596, 0.22378668, 0.22200333, 0.2236622 ],\n",
       "         [0.20379433, 0.02990936, 0.21995354, 0.22005466, 0.22152069]],\n",
       " \n",
       "        [[0.19816516, 0.02236961, 0.21889071, 0.21731274, 0.2192907 ],\n",
       "         [0.19787747, 0.02157751, 0.21667793, 0.21495022, 0.2170607 ],\n",
       "         [0.19958757, 0.01704804, 0.21704383, 0.21570897, 0.21898983],\n",
       "         ...,\n",
       "         [0.20440418, 0.02807596, 0.22378668, 0.22200333, 0.2236622 ],\n",
       "         [0.20379433, 0.02990936, 0.21995354, 0.22005466, 0.22152069],\n",
       "         [0.20613742, 0.02075042, 0.22207919, 0.22222748, 0.22546741]],\n",
       " \n",
       "        [[0.19787747, 0.02157751, 0.21667793, 0.21495022, 0.2170607 ],\n",
       "         [0.19958757, 0.01704804, 0.21704383, 0.21570897, 0.21898983],\n",
       "         [0.20283182, 0.01972966, 0.21606812, 0.21907172, 0.21923761],\n",
       "         ...,\n",
       "         [0.20379433, 0.02990936, 0.21995354, 0.22005466, 0.22152069],\n",
       "         [0.20613742, 0.02075042, 0.22207919, 0.22222748, 0.22546741],\n",
       "         [0.20567201, 0.01875754, 0.22427453, 0.22367604, 0.22658241]]],\n",
       "       dtype=float32),\n",
       " 'y_train': array([0.00171596, 0.00178046, 0.00183207, ..., 0.20316842, 0.2049017 ,\n",
       "        0.20392272]),\n",
       " 'X_test': array([[[0.19958757, 0.01704804, 0.21704383, 0.21570897, 0.21898983],\n",
       "         [0.20283182, 0.01972966, 0.21606812, 0.21907172, 0.21923761],\n",
       "         [0.20069028, 0.01855343, 0.22159134, 0.22012363, 0.22215784],\n",
       "         ...,\n",
       "         [0.20613742, 0.02075042, 0.22207919, 0.22222748, 0.22546741],\n",
       "         [0.20567201, 0.01875754, 0.22427453, 0.22367604, 0.22658241],\n",
       "         [0.20339312, 0.01956372, 0.22254963, 0.22048578, 0.22415774]],\n",
       " \n",
       "        [[0.20283182, 0.01972966, 0.21606812, 0.21907172, 0.21923761],\n",
       "         [0.20069028, 0.01855343, 0.22159134, 0.22012363, 0.22215784],\n",
       "         [0.20003505, 0.01980256, 0.21847254, 0.21715754, 0.2203703 ],\n",
       "         ...,\n",
       "         [0.20567201, 0.01875754, 0.22427453, 0.22367604, 0.22658241],\n",
       "         [0.20339312, 0.01956372, 0.22254963, 0.22048578, 0.22415774],\n",
       "         [0.20299187, 0.02339306, 0.21890813, 0.2186061 , 0.22167997]],\n",
       " \n",
       "        [[0.20069028, 0.01855343, 0.22159134, 0.22012363, 0.22215784],\n",
       "         [0.20003505, 0.01980256, 0.21847254, 0.21715754, 0.2203703 ],\n",
       "         [0.2015693 , 0.01719032, 0.21847254, 0.21746795, 0.21982166],\n",
       "         ...,\n",
       "         [0.20339312, 0.01956372, 0.22254963, 0.22048578, 0.22415774],\n",
       "         [0.20299187, 0.02339306, 0.21890813, 0.2186061 , 0.22167997],\n",
       "         [0.2040832 , 0.01665663, 0.22052851, 0.21965803, 0.22284807]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.9420524 , 0.01599226, 0.96132   , 0.9565432 , 0.95023227],\n",
       "         [0.93401384, 0.01267721, 0.9441056 , 0.9372292 , 0.94357765],\n",
       "         [0.92681414, 0.01303634, 0.93365157, 0.9286068 , 0.93168443],\n",
       "         ...,\n",
       "         [0.8469942 , 0.01708568, 0.8287626 , 0.8411414 , 0.8401486 ],\n",
       "         [0.83922374, 0.01474053, 0.8473011 , 0.84190017, 0.8448209 ],\n",
       "         [0.8530847 , 0.01352655, 0.8532251 , 0.849074  , 0.85763454]],\n",
       " \n",
       "        [[0.93401384, 0.01267721, 0.9441056 , 0.9372292 , 0.94357765],\n",
       "         [0.92681414, 0.01303634, 0.93365157, 0.9286068 , 0.93168443],\n",
       "         [0.9038868 , 0.01899184, 0.9297488 , 0.92081213, 0.8965709 ],\n",
       "         ...,\n",
       "         [0.83922374, 0.01474053, 0.8473011 , 0.84190017, 0.8448209 ],\n",
       "         [0.8530847 , 0.01352655, 0.8532251 , 0.849074  , 0.85763454],\n",
       "         [0.8465742 , 0.01153306, 0.83831066, 0.8350023 , 0.84276795]],\n",
       " \n",
       "        [[0.92681414, 0.01303634, 0.93365157, 0.9286068 , 0.93168443],\n",
       "         [0.9038868 , 0.01899184, 0.9297488 , 0.92081213, 0.8965709 ],\n",
       "         [0.9150707 , 0.01284068, 0.89748055, 0.90791315, 0.9083934 ],\n",
       "         ...,\n",
       "         [0.8530847 , 0.01352655, 0.8532251 , 0.849074  , 0.85763454],\n",
       "         [0.8465742 , 0.01153306, 0.83831066, 0.8350023 , 0.84276795],\n",
       "         [0.8672957 , 0.01213156, 0.8453497 , 0.85452336, 0.8516879 ]]],\n",
       "       dtype=float32),\n",
       " 'y_test': array([0.20271907, 0.19915628, 0.20060069, ..., 0.84349398, 0.84783431,\n",
       "        0.8490944 ]),\n",
       " 'test_df':                   Open        High         Low       Close   Adj Close  \\\n",
       " Date                                                                     \n",
       " 2015-06-12   32.047501   32.082500   31.777500   31.792500   29.153574   \n",
       " 2015-06-15   31.525000   31.809999   31.427500   31.730000   29.096258   \n",
       " 2015-06-16   31.757500   31.962500   31.592501   31.900000   29.252151   \n",
       " 2015-06-17   31.930000   31.969999   31.684999   31.825001   29.183380   \n",
       " 2015-06-18   31.807501   32.077499   31.805000   31.969999   29.316339   \n",
       " ...                ...         ...         ...         ...         ...   \n",
       " 2021-03-09  119.029999  122.059998  118.790001  121.089996  121.089996   \n",
       " 2021-03-10  121.690002  122.169998  119.449997  119.980003  119.980003   \n",
       " 2021-03-11  122.540001  123.209999  121.260002  121.959999  121.959999   \n",
       " 2021-03-12  120.400002  121.169998  119.160004  121.029999  121.029999   \n",
       " 2021-03-15  121.410004  124.000000  120.419998  123.989998  123.989998   \n",
       " \n",
       "                Volume  \n",
       " Date                   \n",
       " 2015-06-12  147544800  \n",
       " 2015-06-15  175955600  \n",
       " 2015-06-16  125976400  \n",
       " 2015-06-17  131672400  \n",
       " 2015-06-18  141628800  \n",
       " ...               ...  \n",
       " 2021-03-09  129159600  \n",
       " 2021-03-10  111760400  \n",
       " 2021-03-11  102753600  \n",
       " 2021-03-12   87963400  \n",
       " 2021-03-15   92403800  \n",
       " \n",
       " [1449 rows x 6 columns]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"Adj Close\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"Adj Close\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"Adj Close\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"Adj Close\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"Adj Close\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>adjclose_10</th>\n",
       "      <th>true_adjclose_10</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-06-12</th>\n",
       "      <td>32.047501</td>\n",
       "      <td>32.082500</td>\n",
       "      <td>31.777500</td>\n",
       "      <td>31.792500</td>\n",
       "      <td>29.153574</td>\n",
       "      <td>147544800</td>\n",
       "      <td>29.942493</td>\n",
       "      <td>29.057289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.788919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-15</th>\n",
       "      <td>31.525000</td>\n",
       "      <td>31.809999</td>\n",
       "      <td>31.427500</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>29.096258</td>\n",
       "      <td>175955600</td>\n",
       "      <td>29.816599</td>\n",
       "      <td>28.548355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.720341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-16</th>\n",
       "      <td>31.757500</td>\n",
       "      <td>31.962500</td>\n",
       "      <td>31.592501</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>29.252151</td>\n",
       "      <td>125976400</td>\n",
       "      <td>29.941366</td>\n",
       "      <td>28.754684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.689215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-17</th>\n",
       "      <td>31.930000</td>\n",
       "      <td>31.969999</td>\n",
       "      <td>31.684999</td>\n",
       "      <td>31.825001</td>\n",
       "      <td>29.183380</td>\n",
       "      <td>131672400</td>\n",
       "      <td>29.925499</td>\n",
       "      <td>29.022902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.742119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-18</th>\n",
       "      <td>31.807501</td>\n",
       "      <td>32.077499</td>\n",
       "      <td>31.805000</td>\n",
       "      <td>31.969999</td>\n",
       "      <td>29.316339</td>\n",
       "      <td>141628800</td>\n",
       "      <td>30.064116</td>\n",
       "      <td>28.986221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.747776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <td>119.029999</td>\n",
       "      <td>122.059998</td>\n",
       "      <td>118.790001</td>\n",
       "      <td>121.089996</td>\n",
       "      <td>121.089996</td>\n",
       "      <td>129159600</td>\n",
       "      <td>26.488811</td>\n",
       "      <td>122.540001</td>\n",
       "      <td>-94.601185</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-10</th>\n",
       "      <td>121.690002</td>\n",
       "      <td>122.169998</td>\n",
       "      <td>119.449997</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>111760400</td>\n",
       "      <td>26.413969</td>\n",
       "      <td>120.089996</td>\n",
       "      <td>-93.566034</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11</th>\n",
       "      <td>122.540001</td>\n",
       "      <td>123.209999</td>\n",
       "      <td>121.260002</td>\n",
       "      <td>121.959999</td>\n",
       "      <td>121.959999</td>\n",
       "      <td>102753600</td>\n",
       "      <td>26.088951</td>\n",
       "      <td>120.589996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.871048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-12</th>\n",
       "      <td>120.400002</td>\n",
       "      <td>121.169998</td>\n",
       "      <td>119.160004</td>\n",
       "      <td>121.029999</td>\n",
       "      <td>121.029999</td>\n",
       "      <td>87963400</td>\n",
       "      <td>25.981548</td>\n",
       "      <td>121.209999</td>\n",
       "      <td>-95.048450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-15</th>\n",
       "      <td>121.410004</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>120.419998</td>\n",
       "      <td>123.989998</td>\n",
       "      <td>123.989998</td>\n",
       "      <td>92403800</td>\n",
       "      <td>25.997967</td>\n",
       "      <td>121.389999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.992031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1449 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2015-06-12   32.047501   32.082500   31.777500   31.792500   29.153574   \n",
       "2015-06-15   31.525000   31.809999   31.427500   31.730000   29.096258   \n",
       "2015-06-16   31.757500   31.962500   31.592501   31.900000   29.252151   \n",
       "2015-06-17   31.930000   31.969999   31.684999   31.825001   29.183380   \n",
       "2015-06-18   31.807501   32.077499   31.805000   31.969999   29.316339   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2021-03-09  119.029999  122.059998  118.790001  121.089996  121.089996   \n",
       "2021-03-10  121.690002  122.169998  119.449997  119.980003  119.980003   \n",
       "2021-03-11  122.540001  123.209999  121.260002  121.959999  121.959999   \n",
       "2021-03-12  120.400002  121.169998  119.160004  121.029999  121.029999   \n",
       "2021-03-15  121.410004  124.000000  120.419998  123.989998  123.989998   \n",
       "\n",
       "               Volume  adjclose_10  true_adjclose_10  buy_profit  sell_profit  \n",
       "Date                                                                           \n",
       "2015-06-12  147544800    29.942493         29.057289    0.000000    -0.788919  \n",
       "2015-06-15  175955600    29.816599         28.548355    0.000000    -0.720341  \n",
       "2015-06-16  125976400    29.941366         28.754684    0.000000    -0.689215  \n",
       "2015-06-17  131672400    29.925499         29.022902    0.000000    -0.742119  \n",
       "2015-06-18  141628800    30.064116         28.986221    0.000000    -0.747776  \n",
       "...               ...          ...               ...         ...          ...  \n",
       "2021-03-09  129159600    26.488811        122.540001  -94.601185     0.000000  \n",
       "2021-03-10  111760400    26.413969        120.089996  -93.566034     0.000000  \n",
       "2021-03-11  102753600    26.088951        120.589996    0.000000    95.871048  \n",
       "2021-03-12   87963400    25.981548        121.209999  -95.048450     0.000000  \n",
       "2021-03-15   92403800    25.997967        121.389999    0.000000    97.992031  \n",
       "\n",
       "[1449 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(aaplmodel_10day, data)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(aaplmodel_10day, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>adjclose_10</th>\n",
       "      <th>true_adjclose_10</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-06-12</th>\n",
       "      <td>32.047501</td>\n",
       "      <td>32.082500</td>\n",
       "      <td>31.777500</td>\n",
       "      <td>31.792500</td>\n",
       "      <td>29.153574</td>\n",
       "      <td>147544800</td>\n",
       "      <td>29.942493</td>\n",
       "      <td>29.057289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.788919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-15</th>\n",
       "      <td>31.525000</td>\n",
       "      <td>31.809999</td>\n",
       "      <td>31.427500</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>29.096258</td>\n",
       "      <td>175955600</td>\n",
       "      <td>29.816599</td>\n",
       "      <td>28.548355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.720341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-16</th>\n",
       "      <td>31.757500</td>\n",
       "      <td>31.962500</td>\n",
       "      <td>31.592501</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>29.252151</td>\n",
       "      <td>125976400</td>\n",
       "      <td>29.941366</td>\n",
       "      <td>28.754684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.689215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-17</th>\n",
       "      <td>31.930000</td>\n",
       "      <td>31.969999</td>\n",
       "      <td>31.684999</td>\n",
       "      <td>31.825001</td>\n",
       "      <td>29.183380</td>\n",
       "      <td>131672400</td>\n",
       "      <td>29.925499</td>\n",
       "      <td>29.022902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.742119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-18</th>\n",
       "      <td>31.807501</td>\n",
       "      <td>32.077499</td>\n",
       "      <td>31.805000</td>\n",
       "      <td>31.969999</td>\n",
       "      <td>29.316339</td>\n",
       "      <td>141628800</td>\n",
       "      <td>30.064116</td>\n",
       "      <td>28.986221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.747776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-09</th>\n",
       "      <td>119.029999</td>\n",
       "      <td>122.059998</td>\n",
       "      <td>118.790001</td>\n",
       "      <td>121.089996</td>\n",
       "      <td>121.089996</td>\n",
       "      <td>129159600</td>\n",
       "      <td>26.488811</td>\n",
       "      <td>122.540001</td>\n",
       "      <td>-94.601185</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-10</th>\n",
       "      <td>121.690002</td>\n",
       "      <td>122.169998</td>\n",
       "      <td>119.449997</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>111760400</td>\n",
       "      <td>26.413969</td>\n",
       "      <td>120.089996</td>\n",
       "      <td>-93.566034</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-11</th>\n",
       "      <td>122.540001</td>\n",
       "      <td>123.209999</td>\n",
       "      <td>121.260002</td>\n",
       "      <td>121.959999</td>\n",
       "      <td>121.959999</td>\n",
       "      <td>102753600</td>\n",
       "      <td>26.088951</td>\n",
       "      <td>120.589996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.871048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-12</th>\n",
       "      <td>120.400002</td>\n",
       "      <td>121.169998</td>\n",
       "      <td>119.160004</td>\n",
       "      <td>121.029999</td>\n",
       "      <td>121.029999</td>\n",
       "      <td>87963400</td>\n",
       "      <td>25.981548</td>\n",
       "      <td>121.209999</td>\n",
       "      <td>-95.048450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-15</th>\n",
       "      <td>121.410004</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>120.419998</td>\n",
       "      <td>123.989998</td>\n",
       "      <td>123.989998</td>\n",
       "      <td>92403800</td>\n",
       "      <td>25.997967</td>\n",
       "      <td>121.389999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.992031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1449 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2015-06-12   32.047501   32.082500   31.777500   31.792500   29.153574   \n",
       "2015-06-15   31.525000   31.809999   31.427500   31.730000   29.096258   \n",
       "2015-06-16   31.757500   31.962500   31.592501   31.900000   29.252151   \n",
       "2015-06-17   31.930000   31.969999   31.684999   31.825001   29.183380   \n",
       "2015-06-18   31.807501   32.077499   31.805000   31.969999   29.316339   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2021-03-09  119.029999  122.059998  118.790001  121.089996  121.089996   \n",
       "2021-03-10  121.690002  122.169998  119.449997  119.980003  119.980003   \n",
       "2021-03-11  122.540001  123.209999  121.260002  121.959999  121.959999   \n",
       "2021-03-12  120.400002  121.169998  119.160004  121.029999  121.029999   \n",
       "2021-03-15  121.410004  124.000000  120.419998  123.989998  123.989998   \n",
       "\n",
       "               Volume  adjclose_10  true_adjclose_10  buy_profit  sell_profit  \n",
       "Date                                                                           \n",
       "2015-06-12  147544800    29.942493         29.057289    0.000000    -0.788919  \n",
       "2015-06-15  175955600    29.816599         28.548355    0.000000    -0.720341  \n",
       "2015-06-16  125976400    29.941366         28.754684    0.000000    -0.689215  \n",
       "2015-06-17  131672400    29.925499         29.022902    0.000000    -0.742119  \n",
       "2015-06-18  141628800    30.064116         28.986221    0.000000    -0.747776  \n",
       "...               ...          ...               ...         ...          ...  \n",
       "2021-03-09  129159600    26.488811        122.540001  -94.601185     0.000000  \n",
       "2021-03-10  111760400    26.413969        120.089996  -93.566034     0.000000  \n",
       "2021-03-11  102753600    26.088951        120.589996    0.000000    95.871048  \n",
       "2021-03-12   87963400    25.981548        121.209999  -95.048450     0.000000  \n",
       "2021-03-15   92403800    25.997967        121.389999    0.000000    97.992031  \n",
       "\n",
       "[1449 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model predicts the Future price after 10 days will be 26.19$\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"This model predicts the Future price after {LOOKUP_STEP} days will be {future_price:.2f}$\")\n",
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
